{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-emb.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTbCBmuqMG7J"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b2LpgLPMQET"
      },
      "source": [
        "from matplotlib import rcParams, pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings \n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HiKxe5qMauM",
        "outputId": "e36543da-24d8-443c-c8a8-c6ca66ffaba9"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Restrict TensorFlow to only use the first GPU\n",
        "    try:\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "    except RuntimeError as e:\n",
        "        # Visible devices must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "else:\n",
        "    print('No GPU detected')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaSKGWcLMbK1"
      },
      "source": [
        "rcParams['figure.figsize'] = (16, 8)\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('max_columns', 100)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ahUSLlvMbVN"
      },
      "source": [
        "data_dir = Path('/content/drive/MyDrive/dacon/input')\n",
        "feature_dir = Path('../build/feature')\n",
        "val_dir = Path('/content/drive/MyDrive/dacon/build/val')\n",
        "tst_dir = Path('/content/drive/MyDrive/dacon/build/tst')\n",
        "sub_dir = Path('/content/drive/MyDrive/dacon/build/sub')\n",
        "\n",
        "trn_file = data_dir / 'train.csv'\n",
        "tst_file = data_dir / 'test_x.csv'\n",
        "sample_file = data_dir / 'sample_submission.csv'\n",
        "\n",
        "target_col = 'author'\n",
        "n_fold = 5\n",
        "n_class = 5\n",
        "seed = 42"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srh_K431Mbck"
      },
      "source": [
        "algo_name = 'cnn'\n",
        "feature_name = 'emb'\n",
        "model_name = f'{algo_name}_{feature_name}'\n",
        "\n",
        "feature_file = feature_dir / f'{feature_name}.csv'\n",
        "p_val_file = val_dir / f'{model_name}.val.csv'\n",
        "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
        "sub_file = sub_dir / f'{model_name}.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "aZQsfKEYMbjN",
        "outputId": "1cfeb8e7-35a6-4fc5-e977-e898f81c8e03"
      },
      "source": [
        "train = pd.read_csv(trn_file, index_col=0)\n",
        "train.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "0      He was almost choking. There was so much, so m...       3\n",
              "1                 “Your sister asked for it, I suppose?”       2\n",
              "2       She was engaged one day as she walked, in per...       1\n",
              "3      The captain was in the porch, keeping himself ...       4\n",
              "4      “Have mercy, gentlemen!” odin flung up his han...       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "SLWpuaSGMbpz",
        "outputId": "8f7ef082-c520-4c9f-dc94-5a90e28e4f42"
      },
      "source": [
        "test = pd.read_csv(tst_file, index_col=0)\n",
        "test.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Not at all. I think she is one of the most ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As the lady had stated her intention of scream...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“And then suddenly in the silence I heard a so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>His conviction remained unchanged. So far as I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "index                                                   \n",
              "0      “Not at all. I think she is one of the most ch...\n",
              "1      \"No,\" replied he, with sudden consciousness, \"...\n",
              "2      As the lady had stated her intention of scream...\n",
              "3      “And then suddenly in the silence I heard a so...\n",
              "4      His conviction remained unchanged. So far as I..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHWeJJjcMbws"
      },
      "source": [
        "train['text'] = train['text'].str.replace('\\?',' quesmark ')\n",
        "train['text'] = train['text'].str.replace('\\!',' exclmark ')\n",
        "train['text'] = train['text'].str.replace('\\&',' empent ')\n",
        "train['text'] = train['text'].str.replace(\"\\*\",' chstar ')\n",
        "train['text'] = train['text'].str.replace(\";\",' smcolons  ')\n",
        "\n",
        "test['text'] = test['text'].str.replace('\\?',' quesmark ')\n",
        "test['text'] = test['text'].str.replace('\\!',' exclmark ')\n",
        "test['text'] = test['text'].str.replace('\\&',' empent ')\n",
        "test['text'] = test['text'].str.replace(\"\\*\",' chstar ')\n",
        "test['text'] = test['text'].str.replace(\";\",' smcolons  ')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai_2ayvsMb3a"
      },
      "source": [
        "cont_dict={\"ain't\": 'are not',\n",
        " \"aren't\": 'are not',\n",
        " \"can't\": 'can not',\n",
        " \"can't've\": 'can not have',\n",
        " \"'cause\": 'because',\n",
        " \"could've\": 'could have',\n",
        " \"couldn't\": 'could not',\n",
        " \"couldn't've\": 'could not have',\n",
        " \"didn't\": 'did not',\n",
        " \"doesn't\": 'does not',\n",
        " \"don't\": 'do not',\n",
        " \"hadn't\": 'had not',\n",
        " \"hadn't've\": 'had not have',\n",
        " \"hasn't\": 'has not',\n",
        " \"haven't\": 'have not',\n",
        " \"\\'he'd\": 'he would',\n",
        " \"\\'he'd've\": 'he would have',\n",
        " \"\\'he'll\": 'he will',\n",
        " \"\\'he'll've\": 'he will have',\n",
        " \"\\'he's\": 'he is',\n",
        " \"\\'how'd\": 'how did',\n",
        " \"\\'how're\": 'how are',\n",
        " \"\\'how'd'y\": 'how do you',\n",
        " \"\\'how'll\": 'how will',\n",
        " \"\\'how's\": 'how is',\n",
        " \"\\'I'd\": 'I would',\n",
        " \"\\'I'd've\": 'I would have',\n",
        " \"\\'I'll\": 'I will',\n",
        " \"\\'I'll've\": 'I will have',\n",
        " \"\\'I'm\": 'I am',\n",
        " \"\\'I've\": 'I have',\n",
        " \"\\'he'd\": 'he would',\n",
        " \"he'd've\": 'he would have',\n",
        " \"he'll\": 'he will',\n",
        " \"he'll've\": 'he will have',\n",
        " \"he's\": 'he is',\n",
        " \"how'd\": 'how did',\n",
        " \"how're\": 'how are',\n",
        " \"how'd'y\": 'how do you',\n",
        " \"how'll\": 'how will',\n",
        " \"how's\": 'how is',\n",
        " \"I'd\": 'I would',\n",
        " \"I'd've\": 'I would have',\n",
        " \"I'll\": 'I will',\n",
        " \"I'll've\": 'I will have',\n",
        " \"I'm\": 'I am',\n",
        " \"I've\": 'I have',         \n",
        " \"isn't\": 'is not',\n",
        " \"\\'it'd\": 'it would',\n",
        " \"\\'it'd've\": 'it would have',\n",
        " \"\\'it'll\": 'it will',\n",
        " \"\\'it'll've\": 'it will have',\n",
        " \"\\'it's\": 'it is',\n",
        " \"\\'let's\": 'let us',\n",
        " \"it'd\": 'it would',\n",
        " \"it'd've\": 'it would have',\n",
        " \"it'll\": 'it will',\n",
        " \"it'll've\": 'it will have',\n",
        " \"it's\": 'it is',\n",
        " \"let's\": 'let us',\n",
        " \"ma'am\": 'madam',\n",
        " \"mayn't\": 'may not',\n",
        " \"might've\": 'might have',\n",
        " \"mightn't\": 'might not',\n",
        " \"mightn't've\": 'might not have',\n",
        " \"must've\": 'must have',\n",
        " \"mustn't\": 'must not',\n",
        " \"mustn't've\": 'must not have',\n",
        " \"needn't\": 'need not',\n",
        " \"needn't've\": 'need not have',\n",
        " \"o'clock\": 'of the clock',\n",
        " \"oughtn't\": 'ought not',\n",
        " \"oughtn't've\": 'ought not have',\n",
        " \"\\'shan't\": 'shall not',\n",
        " \"\\'sha'n't\": 'shall not',\n",
        " \"\\'shan't've\": 'shall not have',\n",
        " \"\\'she'd\": 'she would',\n",
        " \"\\'she'd've\": 'she would have',\n",
        " \"\\'she'll\": 'she will',\n",
        " \"\\'she'll've\": 'she will have',\n",
        " \"\\'she's\": 'she is',\n",
        " \"\\'should've\": 'should have',\n",
        " \"\\'shouldn't\": 'should not',\n",
        " \"\\'shouldn't've\": 'should not have',\n",
        " \"shan't\": 'shall not',\n",
        " \"sha'n't\": 'shall not',\n",
        " \"shan't've\": 'shall not have',\n",
        " \"she'd\": 'she would',\n",
        " \"she'd've\": 'she would have',\n",
        " \"she'll\": 'she will',\n",
        " \"she'll've\": 'she will have',\n",
        " \"she's\": 'she is',\n",
        " \"should've\": 'should have',\n",
        " \"shouldn't\": 'should not',\n",
        " \"shouldn't've\": 'should not have',         \n",
        " \"so've\": 'so have',\n",
        " \"so's\": 'so is',\n",
        " \"\\'that'd\": 'that would',\n",
        " \"\\'that'd've\": 'that would have',\n",
        " \"\\'that's\": 'that is',\n",
        " \"\\'there'd\": 'there would',\n",
        " \"\\'there'd've\": 'there would have',\n",
        " \"\\'there's\": 'there is',\n",
        " \"\\'they'd\": 'they would',\n",
        " \"\\'they'd've\": 'they would have',\n",
        " \"\\'they'll\": 'they will',\n",
        " \"\\'they'll've\": 'they will have',\n",
        " \"\\'they're\": 'they are',\n",
        " \"\\'they've\": 'they have',\n",
        " \"that'd\": 'that would',\n",
        " \"that'd've\": 'that would have',\n",
        " \"that's\": 'that is',\n",
        " \"there'd\": 'there would',\n",
        " \"there'd've\": 'there would have',\n",
        " \"there's\": 'there is',\n",
        " \"they'd\": 'they would',\n",
        " \"they'd've\": 'they would have',\n",
        " \"they'll\": 'they will',\n",
        " \"they'll've\": 'they will have',\n",
        " \"they're\": 'they are',\n",
        " \"they've\": 'they have',         \n",
        " \"to've\": 'to have',\n",
        " \"wasn't\": 'was not',\n",
        " \"\\'we'd\": 'we would',\n",
        " \"\\'we'd've\": 'we would have',\n",
        " \"\\'we'll\": 'we will',\n",
        " \"\\'we'll've\": 'we will have',\n",
        " \"\\'we're\": 'we are',\n",
        " \"\\'we've\": 'we have',\n",
        " \"we'd\": 'we would',\n",
        " \"we'd've\": 'we would have',\n",
        " \"we'll\": 'we will',\n",
        " \"we'll've\": 'we will have',\n",
        " \"we're\": 'we are',\n",
        " \"we've\": 'we have',\n",
        " \"weren't\": 'were not',\n",
        " \"\\'what'll\": 'what will',\n",
        " \"\\'what'll've\": 'what will have',\n",
        " \"\\'what're\": 'what are',\n",
        " \"\\'what's\": 'what is',\n",
        " \"\\'what've\": 'what have',\n",
        " \"\\'when's\": 'when is',\n",
        " \"\\'when've\": 'when have',\n",
        " \"\\'where'd\": 'where did',\n",
        " \"\\'where's\": 'where is',\n",
        " \"\\'where've\": 'where have',\n",
        " \"\\'who'll\": 'who will',\n",
        " \"\\'who'll've\": 'who will have',\n",
        " \"\\'who's\": 'who is',\n",
        " \"\\'who've\": 'who have',\n",
        " \"\\'why's\": 'why is',\n",
        " \"\\'why've\": 'why have',\n",
        " \"\\'will've\": 'will have',\n",
        " \"\\'won't\": 'will not',\n",
        " \"\\'won't've\": 'will not have',\n",
        " \"\\'would've\": 'would have',\n",
        " \"\\'wouldn't\": 'would not',\n",
        " \"\\'wouldn't've\": 'would not have',\n",
        " \"what'll\": 'what will',\n",
        " \"what'll've\": 'what will have',\n",
        " \"what're\": 'what are',\n",
        " \"what's\": 'what is',\n",
        " \"what've\": 'what have',\n",
        " \"when's\": 'when is',\n",
        " \"when've\": 'when have',\n",
        " \"where'd\": 'where did',\n",
        " \"where's\": 'where is',\n",
        " \"where've\": 'where have',\n",
        " \"who'll\": 'who will',\n",
        " \"who'll've\": 'who will have',\n",
        " \"who's\": 'who is',\n",
        " \"who've\": 'who have',\n",
        " \"why's\": 'why is',\n",
        " \"why've\": 'why have',\n",
        " \"will've\": 'will have',\n",
        " \"won't\": 'will not',\n",
        " \"won't've\": 'will not have',\n",
        " \"would've\": 'would have',\n",
        " \"wouldn't\": 'would not',\n",
        " \"wouldn't've\": 'would not have',\n",
        " \"y'all\": 'you all',\n",
        " \"y'all'd\": 'you all would',\n",
        " \"y'all'd've\": 'you all would have',\n",
        " \"y'all're\": 'you all are',\n",
        " \"y'all've\": 'you all have',\n",
        " \"\\'you'd\": 'you would',\n",
        " \"\\'you'd've\": 'you would have',\n",
        " \"\\'you'll\": 'you will',\n",
        " \"\\'you'll've\": 'you shall have',\n",
        " \"\\'you're\": 'you are',\n",
        " \"\\'you've\": 'you have',\n",
        " \"you'd\": 'you would',\n",
        " \"you'd've\": 'you would have',\n",
        " \"you'll\": 'you will',\n",
        " \"you'll've\": 'you shall have',\n",
        " \"you're\": 'you are',\n",
        " \"you've\": 'you have',\n",
        " 'jan.': 'january',\n",
        " 'feb.': 'february',\n",
        " 'mar.': 'march',\n",
        " 'apr.': 'april',\n",
        " 'jun.': 'june',\n",
        " 'jul.': 'july',\n",
        " 'aug.': 'august',\n",
        " 'sep.': 'september',\n",
        " 'oct.': 'october',\n",
        " 'nov.': 'november',\n",
        " 'dec.': 'december',\n",
        " 'ain’t': 'are not',\n",
        " 'aren’t': 'are not',\n",
        " 'can’t': 'can not',\n",
        " 'can’t’ve': 'can not have',\n",
        " '’cause': 'because',\n",
        " 'could’ve': 'could have',\n",
        " 'couldn’t': 'could not',\n",
        " 'couldn’t’ve': 'could not have',\n",
        " 'didn’t': 'did not',\n",
        " 'doesn’t': 'does not',\n",
        " 'don’t': 'do not',\n",
        " 'hadn’t': 'had not',\n",
        " 'hadn’t’ve': 'had not have',\n",
        " 'hasn’t': 'has not',\n",
        " 'haven’t': 'have not',\n",
        " '\\'he’d': 'he would',\n",
        " '\\'he’d’ve': 'he would have',\n",
        " '\\'he’ll': 'he will',\n",
        " '\\'he’ll’ve': 'he will have',\n",
        " '\\'he’s': 'he is',\n",
        " '\\'how’d': 'how did',\n",
        " '\\'how’re': 'how are',\n",
        " '\\'how’d’y': 'how do you',\n",
        " '\\'how’ll': 'how will',\n",
        " '\\'how’s': 'how is',\n",
        " '\\'I’d': 'I would',\n",
        " '\\'I’d’ve': 'I would have',\n",
        " '\\'I’ll': 'I will',\n",
        " '\\'I’ll’ve': 'I will have',\n",
        " '\\'I’m': 'I am',\n",
        " '\\'I’ve': 'I have',\n",
        " '\\'isn’t': 'is not',\n",
        " '\\'it’d': 'it would',\n",
        " '\\'it’d’ve': 'it would have',\n",
        " '\\'it’ll': 'it will',\n",
        " '\\'it’ll’ve': 'it will have',\n",
        " '\\'it’s': 'it is',\n",
        " '\\'let’s': 'let us',  \n",
        " 'he’d': 'he would',\n",
        " 'he’d’ve': 'he would have',\n",
        " 'she’ll': 'he will',\n",
        " 'he’ll’ve': 'he will have',\n",
        " 'odin’s' : 'odin is',\n",
        " 'joe’s' : 'joe is',\n",
        " 'dora’s' : 'dora is',\n",
        " 'wickfield’s' : 'wickfield is',\n",
        " 'tellson’s' : 'tellson is',\n",
        " 'omer’s' :  'omer is',\n",
        " 'cruncher’s' : 'crucher is', \n",
        " 'pip’s' : 'pip is',\n",
        " 'creakle’s ': 'creakle is',\n",
        " 'jorkins’s ' : 'jorkins is',\n",
        " 'jane’s' : 'jane is',\n",
        " 'elliot’s' : 'elliot is',\n",
        " 'anne’s' : 'anne is',\n",
        " 'tilney’s' : 'tilney is',\n",
        " 'lizzy’s' : 'lizzy is',\n",
        " 'smith’s' : 'smith is',\n",
        " 'walter’s' : 'walter is',\n",
        " 'musgrove’s' : 'musgrove is',\n",
        " 'lucy’s' : 'lucy is',\n",
        " 'nigel’s' : 'nigel is',\n",
        " 'nay’s' : 'nay is',\n",
        " 'chodinger’s' : 'chodinger is',\n",
        " 'humphrey’s' : 'humphrey is',\n",
        " 'jack’s' : 'jack is',\n",
        " 'arthur’s': 'arthur is',\n",
        " 'lana’s': 'lana is',\n",
        " 'sarah’s': 'sarah is',\n",
        " 'garcia’s' : 'garcia is',\n",
        " 'ivan’s' : 'ivan is',\n",
        " 'zossimov’s' : 'zossimov is',\n",
        " 'totski’s' : 'totski is',\n",
        " 'miusov’s' : 'miusov is',\n",
        " 'rodya’s' : 'rodya is',\n",
        " 'odin’s' : 'odin is',\n",
        " 'maman’s' : 'maman is',\n",
        " 'thee’s' : 'thee is',\n",
        " 'ye’s' : 'ye is',\n",
        " 'richard’s' : 'richard is',\n",
        " 'silas’s' : 'silas is',\n",
        " 'von’s': 'von is',\n",
        " 'lanyon’s' : 'lanyon is',\n",
        " 'jack’s' : 'jack is',\n",
        " 'gunn’s' : 'gumn is',\n",
        " 'nay’s' : 'nay is',  \n",
        " 'rankeillor’s': 'rankeillor is',      \n",
        " 'odin\\'s' : 'odin is',\n",
        " 'joe\\'s' : 'joe is',\n",
        " 'dora\\'s' : 'dora is',\n",
        " 'wickfield\\'s' : 'wickfield is',\n",
        " 'tellson\\'s' : 'tellson is',\n",
        " 'omer\\'s' :  'omer is',\n",
        " 'cruncher\\'s' : 'crucher is', \n",
        " 'pip\\'s' : 'pip is',\n",
        " 'creakle\\'s ': 'creakle is',\n",
        " 'jorkins\\'s ' : 'jorkins is',\n",
        " 'jane\\'s' : 'jane is',\n",
        " 'elliot\\'s' : 'elliot is',\n",
        " 'anne\\'s' : 'anne is',\n",
        " 'tilney\\'s' : 'tilney is',\n",
        " 'lizzy\\'s' : 'lizzy is',\n",
        " 'smith\\'s' : 'smith is',\n",
        " 'walter\\'s' : 'walter is',\n",
        " 'musgrove\\'s' : 'musgrove is',\n",
        " 'lucy\\'s' : 'lucy is',\n",
        " 'nigel\\'s' : 'nigel is',\n",
        " 'nay\\'s' : 'nay is',\n",
        " 'chodinger\\'s' : 'chodinger is',\n",
        " 'humphrey\\'s' : 'humphrey is',\n",
        " 'jack\\'s' : 'jack is',\n",
        " 'arthur\\'s': 'arthur is',\n",
        " 'lana\\'s': 'lana is',\n",
        " 'sarah\\'s': 'sarah is',\n",
        " 'garcia\\'s' : 'garcia is',\n",
        " 'ivan\\'s' : 'ivan is',\n",
        " 'zossimov\\'s' : 'zossimov is',\n",
        " 'totski\\'s' : 'totski is',\n",
        " 'miusov\\'s' : 'miusov is',\n",
        " 'rodya\\'s' : 'rodya is',\n",
        " 'odin\\'s' : 'odin is',\n",
        " 'maman\\'s' : 'maman is',\n",
        " 'thee\\'s' : 'thee is',\n",
        " 'ye\\'s' : 'ye is',\n",
        " 'richard\\'s' : 'richard is',\n",
        " 'silas\\'s' : 'silas is',\n",
        " 'von\\'s': 'von is',\n",
        " 'lanyon\\'s' : 'lanyon is',\n",
        " 'jack\\'s' : 'jack is',\n",
        " 'gunn\\'s' : 'gumn is',\n",
        " 'nay\\'s' : 'nay is',  \n",
        " 'rankeillor\\'s': 'rankeillor is',          \n",
        " '\\'odin\\'s' : 'odin is',\n",
        " '\\'joe\\'s' : 'joe is',\n",
        " '\\'dora\\'s' : 'dora is',\n",
        " '\\'wickfield\\'s' : 'wickfield is',\n",
        " '\\'tellson\\'s' : 'tellson is',\n",
        " '\\'omer\\'s' :  'omer is',\n",
        " '\\'cruncher\\'s' : 'crucher is', \n",
        " '\\'pip\\'s' : 'pip is',\n",
        " '\\'creakle\\'s ': 'creakle is',\n",
        " '\\'jorkins\\'s ' : 'jorkins is',\n",
        " '\\'jane\\'s' : 'jane is',\n",
        " '\\'elliot\\'s' : 'elliot is',\n",
        " '\\'anne\\'s' : 'anne is',\n",
        " '\\'tilney\\'s' : 'tilney is',\n",
        " '\\'lizzy\\'s' : 'lizzy is',\n",
        " '\\'smith\\'s' : 'smith is',\n",
        " '\\'walter\\'s' : 'walter is',\n",
        " '\\'musgrove\\'s' : 'musgrove is',\n",
        " '\\'lucy\\'s' : 'lucy is',\n",
        " '\\'nigel\\'s' : 'nigel is',\n",
        " '\\'nay\\'s' : 'nay is',\n",
        " '\\'chodinger\\'s' : 'chodinger is',\n",
        " '\\'humphrey\\'s' : 'humphrey is',\n",
        " '\\'jack\\'s' : 'jack is',\n",
        " '\\'arthur\\'s': 'arthur is',\n",
        " '\\'lana\\'s': 'lana is',\n",
        " '\\'sarah\\'s': 'sarah is',\n",
        " '\\'garcia\\'s' : 'garcia is',\n",
        " '\\'ivan\\'s' : 'ivan is',\n",
        " '\\'zossimov\\'s' : 'zossimov is',\n",
        " '\\'totski\\'s' : 'totski is',\n",
        " '\\'miusov\\'s' : 'miusov is',\n",
        " '\\'rodya\\'s' : 'rodya is',\n",
        " '\\'odin\\'s' : 'odin is',\n",
        " '\\'maman\\'s' : 'maman is',\n",
        " '\\'thee\\'s' : 'thee is',\n",
        " '\\'ye\\'s' : 'ye is',\n",
        " '\\'richard\\'s' : 'richard is',\n",
        " '\\'silas\\'s' : 'silas is',\n",
        " '\\'von\\'s': 'von is',\n",
        " '\\'lanyon\\'s' : 'lanyon is',\n",
        " '\\'jack\\'s' : 'jack is',\n",
        " '\\'gunn\\'s' : 'gumn is',\n",
        " '\\'nay\\'s' : 'nay is',  \n",
        " '\\'rankeillor\\'s': 'rankeillor is',        \n",
        " 'he’s': 'he is',\n",
        " 'how’d': 'how did',\n",
        " 'how’re': 'how are',\n",
        " 'how’d’y': 'how do you',\n",
        " 'how’ll': 'how will',\n",
        " 'how’s': 'how is',\n",
        " 'I’d': 'I would',\n",
        " 'I’d’ve': 'I would have',\n",
        " 'I’ll': 'I will',\n",
        " 'I’ll’ve': 'I will have',\n",
        " 'I’m': 'I am',\n",
        " 'I’ve': 'I have',\n",
        " 'isn’t': 'is not',\n",
        " 'it’d': 'it would',\n",
        " 'it’d’ve': 'it would have',\n",
        " 'it’ll': 'it will',\n",
        " 'it’ll’ve': 'it will have',\n",
        " 'it’s': 'it is',\n",
        " 'let’s': 'let us',          \n",
        " 'ma’am': 'madam',\n",
        " 'mayn’t': 'may not',\n",
        " 'might’ve': 'might have',\n",
        " 'mightn’t': 'might not',\n",
        " 'mightn’t’ve': 'might not have',\n",
        " 'must’ve': 'must have',\n",
        " 'mustn’t': 'must not',\n",
        " 'mustn’t’ve': 'must not have',\n",
        " 'needn’t': 'need not',\n",
        " 'needn’t’ve': 'need not have',\n",
        " 'o’clock': 'of the clock',\n",
        " 'oughtn’t': 'ought not',\n",
        " 'oughtn’t’ve': 'ought not have',\n",
        " 'shan’t': 'shall not',\n",
        " 'sha’n’t': 'shall not',\n",
        " 'shan’t’ve': 'shall not have',\n",
        " '\\'she’d': 'she would',\n",
        " '\\'she’d’ve': 'she would have',\n",
        " '\\'she’ll': 'she will',\n",
        " '\\'she’ll’ve': 'she will have',\n",
        " '\\'she’s': 'she is',\n",
        " '\\'should’ve': 'should have',\n",
        " '\\'shouldn’t': 'should not',\n",
        " '\\'shouldn’t’ve': 'should not have',\n",
        " '\\'so’ve': 'so have',\n",
        " '\\'so’s': 'so is',\n",
        " '\\'that’d': 'that would',\n",
        " '\\'that’d’ve': 'that would have',\n",
        " '\\'that’s': 'that is',\n",
        " '\\'there’d': 'there would',\n",
        " '\\'there’d’ve': 'there would have',\n",
        " '\\'there’s': 'there is',\n",
        " '\\'they’d': 'they would',\n",
        " '\\'they’d’ve': 'they would have',\n",
        " '\\'they’ll': 'they will',\n",
        " '\\'they’ll’ve': 'they will have',\n",
        " '\\'they’re': 'they are',\n",
        " '\\'they’ve': 'they have',\n",
        " 'she’d': 'she would',\n",
        " 'she’d’ve': 'she would have',\n",
        " 'she’ll': 'she will',\n",
        " 'she’ll’ve': 'she will have',\n",
        " 'she’s': 'she is',\n",
        " 'should’ve': 'should have',\n",
        " 'shouldn’t': 'should not',\n",
        " 'shouldn’t’ve': 'should not have',\n",
        " 'so’ve': 'so have',\n",
        " 'so’s': 'so is',\n",
        " 'that’d': 'that would',\n",
        " 'that’d’ve': 'that would have',\n",
        " 'that’s': 'that is',\n",
        " 'there’d': 'there would',\n",
        " 'there’d’ve': 'there would have',\n",
        " 'there’s': 'there is',\n",
        " 'they’d': 'they would',\n",
        " 'they’d’ve': 'they would have',\n",
        " 'they’ll': 'they will',\n",
        " 'they’ll’ve': 'they will have',\n",
        " 'they’re': 'they are',\n",
        " 'they’ve': 'they have',      \n",
        " 'to’ve': 'to have',\n",
        " 'wasn’t': 'was not',\n",
        " '\\'we’d': 'we would',\n",
        " '\\'we’d’ve': 'we would have',\n",
        " '\\'we’ll': 'we will',\n",
        " '\\'we’ll’ve': 'we will have',\n",
        " '\\'we’re': 'we are',\n",
        " '\\'we’ve': 'we have',\n",
        " 'we’d': 'we would',\n",
        " 'we’d’ve': 'we would have',\n",
        " 'we’ll': 'we will',\n",
        " 'we’ll’ve': 'we will have',\n",
        " 'we’re': 'we are',\n",
        " 'we’ve': 'we have',          \n",
        " 'weren’t': 'were not',\n",
        " '\\'what’ll': 'what will',\n",
        " '\\'what’ll’ve': 'what will have',\n",
        " '\\'what’re': 'what are',\n",
        " '\\'what’s': 'what is',\n",
        " '\\'what’ve': 'what have',\n",
        " '\\'when’s': 'when is',\n",
        " '\\'when’ve': 'when have',\n",
        " '\\'where’d': 'where did',\n",
        " '\\'where’s': 'where is',\n",
        " '\\'where’ve': 'where have',\n",
        " '\\'who’ll': 'who will',\n",
        " '\\'who’ll’ve': 'who will have',\n",
        " '\\'who’s': 'who is',\n",
        " '\\'who’ve': 'who have',\n",
        " '\\'why’s': 'why is',\n",
        " '\\'why’ve': 'why have',\n",
        " '\\'will’ve': 'will have',\n",
        " '\\'won’t': 'will not',\n",
        " '\\'won’t’ve': 'will not have',\n",
        " '\\'would’ve': 'would have',\n",
        " '\\'wouldn’t': 'would not',\n",
        " '\\'wouldn’t’ve': 'would not have',\n",
        " 'what’ll': 'what will',\n",
        " 'what’ll’ve': 'what will have',\n",
        " 'what’re': 'what are',\n",
        " 'what’s': 'what is',\n",
        " 'what’ve': 'what have',\n",
        " 'when’s': 'when is',\n",
        " 'when’ve': 'when have',\n",
        " 'where’d': 'where did',\n",
        " 'where’s': 'where is',\n",
        " 'where’ve': 'where have',\n",
        " 'who’ll': 'who will',\n",
        " 'who’ll’ve': 'who will have',\n",
        " 'who’s': 'who is',\n",
        " 'who’ve': 'who have',\n",
        " 'why’s': 'why is',\n",
        " 'why’ve': 'why have',\n",
        " 'will’ve': 'will have',\n",
        " 'won’t': 'will not',\n",
        " 'won’t’ve': 'will not have',\n",
        " 'would’ve': 'would have',\n",
        " 'wouldn’t': 'would not',\n",
        " 'wouldn’t’ve': 'would not have',   \n",
        " 'y’all': 'you all',\n",
        " 'y’all’d': 'you all would',\n",
        " 'y’all’d’ve': 'you all would have',\n",
        " 'y’all’re': 'you all are',\n",
        " 'y’all’ve': 'you all have',\n",
        " '\\'you’d': 'you would',\n",
        " '\\'you’d’ve': 'you would have',\n",
        " '\\'you’ll': 'you will',\n",
        " '\\'you’ll’ve': 'you shall have',\n",
        " '\\'you’re': 'you are',\n",
        " '\\'you’ve': 'you have', \n",
        " 'you’d': 'you would',\n",
        " 'you’d’ve': 'you would have',\n",
        " 'you’ll': 'you will',\n",
        " 'you’ll’ve': 'you shall have',\n",
        " 'you’re': 'you are',\n",
        " 'you’ve': 'you have'\n",
        "}"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuBccnbRMb98"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "def clean_contraction(text):\n",
        "    words = text_to_word_sequence(text)\n",
        "    words=[cont_dict[word] if word in cont_dict else word for word in words]\n",
        "    clean_sent=\" \".join(words)\n",
        "    \n",
        "    return clean_sent\n",
        "\n",
        "train['text'] = train['text'].str.lower().apply(clean_contraction)\n",
        "test['text'] = test['text'].str.lower().apply(clean_contraction)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucknbDiMMcFX"
      },
      "source": [
        "train['text']=train['text'].str.replace('\\'s', '')\n",
        "train['text']=train['text'].str.replace('’s', '')\n",
        "train['text']=train['text'].str.replace(\"\\'\", '')\n",
        "train['text']=train['text'].str.replace(\"’\", '')\n",
        "\n",
        "test['text']=test['text'].str.replace(\"’s\",'')\n",
        "test['text']=test['text'].str.replace(\"\\'s\",'')\n",
        "test['text']=test['text'].str.replace(\"\\'\", '')\n",
        "test['text']=test['text'].str.replace(\"’\", '')\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGcv3tL2McMq"
      },
      "source": [
        "train['text']=train['text'].str.replace('á', '')\n",
        "train['text']=train['text'].str.replace('ä', '')\n",
        "train['text']=train['text'].str.replace('é', '')\n",
        "train['text']=train['text'].str.replace('í', '')\n",
        "train['text']=train['text'].str.replace('ó', '')\n",
        "train['text']=train['text'].str.replace('ú', '')\n",
        "train['text']=train['text'].str.replace('ý', '')\n",
        "train['text']=train['text'].str.replace('ü', ' Umlaut ')\n",
        "\n",
        "test['text']=test['text'].str.replace('ä', '')\n",
        "test['text']=test['text'].str.replace('á', '')\n",
        "test['text']=test['text'].str.replace('é', '')\n",
        "test['text']=test['text'].str.replace('í', '')\n",
        "test['text']=test['text'].str.replace('ó', '')\n",
        "test['text']=test['text'].str.replace('ú', '')\n",
        "test['text']=test['text'].str.replace('ý', '')\n",
        "test['text']=test['text'].str.replace('ü', '')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFnZEIvOMcUE"
      },
      "source": [
        "def alpha_num(text):\n",
        "    return re.sub(r'[0-9]', ' num ', text)\n",
        "\n",
        "def remove_word(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in del_word:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "\n",
        "\n",
        "del_word = ['the', 'and' , 'to' , 'of' , 'a', 'was', 'in' , \"about\", \"above\", \"after\", \"again\", \"against\", \"all\",\"out\", \n",
        "            \"over\", \"own\", \"same\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"for\", \"further\" ,\"between\", \n",
        "            \"might\",\"odin\", \"said\", \"one\", \"i\", \"man\", \"know\", \"see\", \"take\", \"come\", \"get\", \"nothing\" , \"something\",\n",
        "            \"think\", \"find\", \"that\", \"was\", \"are\", \"yourself\", \"himself\" , \"myself\"]\n",
        "\n",
        "train['text'] = train['text'].str.lower().apply(alpha_num).apply(remove_word)\n",
        "test['text'] = test['text'].str.lower().apply(alpha_num).apply(remove_word)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "WtQcN35_Mccp",
        "outputId": "24f9f8e0-770c-422c-b46a-e62e50d63adf"
      },
      "source": [
        "train['text'].str.len().hist()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4030f68940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VimIN9vMclT",
        "outputId": "5f831643-3474-4aa5-a3d0-0f044a741978"
      },
      "source": [
        "X_trn = train['text'].values\n",
        "X_tst = test['text'].values\n",
        "y = train['author'].values\n",
        "print(X_trn.shape, X_tst.shape, y.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879,) (19617,) (54879,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3bdRKHoMcuT"
      },
      "source": [
        "vocab_size = 20000\n",
        "embedding_dim = 64\n",
        "max_length = 330\n",
        "padding_type='post'"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHip4uvHMc2P"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "tokenizer.fit_on_texts(X_trn)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x9C4seTMc-f"
      },
      "source": [
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(X_trn)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_tst)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OThSlL25MdHG",
        "outputId": "f31c8ba4-6841-4b50-d9ea-7f7fc6fb6438"
      },
      "source": [
        "trn = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
        "tst = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n",
        "print(trn.shape, tst.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879, 250) (19617, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92vBhrKgMdOd"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apsqIhOTPPd3"
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "        Dropout(0.2),\n",
        "        Conv1D(256, 3, padding='valid', activation='relu', strides=1),   \n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(n_class, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(learning_rate=.005))\n",
        "    return model"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HmEeZeTPR2l",
        "outputId": "8df15b62-1f9f-492b-8dc7-773e4a84e4b6"
      },
      "source": [
        "p_val = np.zeros((trn.shape[0], n_class))\n",
        "p_tst = np.zeros((tst.shape[0], n_class))\n",
        "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
        "    print(f'training model for CV #{i}')\n",
        "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
        "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "    clf = get_model()    \n",
        "    clf.fit(trn[i_trn], \n",
        "            to_categorical(y[i_trn]),\n",
        "            validation_data=(trn[i_val], to_categorical(y[i_val])),\n",
        "            epochs=10,\n",
        "            batch_size=256,\n",
        "            callbacks=[es])\n",
        "    p_val[i_val, :] = clf.predict(trn[i_val])\n",
        "    p_tst += clf.predict(tst) / n_fold"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model for CV #1\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 6s 34ms/step - loss: 1.0215 - val_loss: 0.7197\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 6s 32ms/step - loss: 0.5669 - val_loss: 0.6721\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 6s 32ms/step - loss: 0.3962 - val_loss: 0.7362\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 6s 32ms/step - loss: 0.3008 - val_loss: 0.8556\n",
            "Epoch 5/10\n",
            "171/172 [============================>.] - ETA: 0s - loss: 0.2574Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 6s 32ms/step - loss: 0.2575 - val_loss: 0.9427\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #2\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 6s 33ms/step - loss: 1.0517 - val_loss: 0.7178\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 6s 32ms/step - loss: 0.5956 - val_loss: 0.6693\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 6s 32ms/step - loss: 0.4168 - val_loss: 0.7115\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 5s 32ms/step - loss: 0.3310 - val_loss: 0.7783\n",
            "Epoch 5/10\n",
            "171/172 [============================>.] - ETA: 0s - loss: 0.2772Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 6s 32ms/step - loss: 0.2774 - val_loss: 0.8664\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #3\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 6s 32ms/step - loss: 1.0516 - val_loss: 0.7215\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 5s 32ms/step - loss: 0.5969 - val_loss: 0.6806\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 5s 32ms/step - loss: 0.4220 - val_loss: 0.7261\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 5s 32ms/step - loss: 0.3218 - val_loss: 0.8038\n",
            "Epoch 5/10\n",
            "171/172 [============================>.] - ETA: 0s - loss: 0.2655Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 5s 32ms/step - loss: 0.2657 - val_loss: 0.8398\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #4\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 6s 33ms/step - loss: 1.0299 - val_loss: 0.7110\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 5s 32ms/step - loss: 0.5764 - val_loss: 0.6640\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 5s 32ms/step - loss: 0.4041 - val_loss: 0.6996\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 6s 32ms/step - loss: 0.3153 - val_loss: 0.8010\n",
            "Epoch 5/10\n",
            "171/172 [============================>.] - ETA: 0s - loss: 0.2638Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 6s 32ms/step - loss: 0.2638 - val_loss: 0.8880\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #5\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 6s 33ms/step - loss: 1.0312 - val_loss: 0.6966\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 5s 32ms/step - loss: 0.5731 - val_loss: 0.6752\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 5s 32ms/step - loss: 0.4046 - val_loss: 0.7169\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 5s 32ms/step - loss: 0.3106 - val_loss: 0.8164\n",
            "Epoch 5/10\n",
            "171/172 [============================>.] - ETA: 0s - loss: 0.2585Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 5s 32ms/step - loss: 0.2586 - val_loss: 0.8390\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NhAmqFqPUPp",
        "outputId": "5e586b7b-73a2-44d1-aa52-719f9b890761"
      },
      "source": [
        "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n",
        "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy (CV):  75.6082%\n",
            "Log Loss (CV):   0.6722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYyiNnrHPjF8"
      },
      "source": [
        "\n",
        "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
        "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "H7exZyfiPle_",
        "outputId": "69521475-19cd-4608-f54d-ded5d9a3d3b9"
      },
      "source": [
        "sub = pd.read_csv(sample_file, index_col=0)\n",
        "print(sub.shape)\n",
        "sub.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19617, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  1  2  3  4\n",
              "index               \n",
              "0      0  0  0  0  0\n",
              "1      0  0  0  0  0\n",
              "2      0  0  0  0  0\n",
              "3      0  0  0  0  0\n",
              "4      0  0  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "61nUSj3xPn6g",
        "outputId": "f44b3251-d971-42b7-efb4-3ef837938ffb"
      },
      "source": [
        "sub[sub.columns] = p_tst\n",
        "sub.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0172</td>\n",
              "      <td>0.3711</td>\n",
              "      <td>5.7228e-01</td>\n",
              "      <td>0.0340</td>\n",
              "      <td>0.0053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1334</td>\n",
              "      <td>0.3667</td>\n",
              "      <td>2.5392e-02</td>\n",
              "      <td>0.2143</td>\n",
              "      <td>0.2602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9903</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>8.8584e-05</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.0007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.1600</td>\n",
              "      <td>0.0146</td>\n",
              "      <td>6.2297e-01</td>\n",
              "      <td>0.0427</td>\n",
              "      <td>0.1597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.5610</td>\n",
              "      <td>0.0317</td>\n",
              "      <td>2.3778e-02</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.1368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0       1           2       3       4\n",
              "index                                            \n",
              "0      0.0172  0.3711  5.7228e-01  0.0340  0.0053\n",
              "1      0.1334  0.3667  2.5392e-02  0.2143  0.2602\n",
              "2      0.9903  0.0084  8.8584e-05  0.0005  0.0007\n",
              "3      0.1600  0.0146  6.2297e-01  0.0427  0.1597\n",
              "4      0.5610  0.0317  2.3778e-02  0.2467  0.1368"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6alb5f5PoFC"
      },
      "source": [
        "sub.to_csv(sub_file)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlNrcWwVQGyV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
