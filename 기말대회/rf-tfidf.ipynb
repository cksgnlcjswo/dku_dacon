{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rf-tfidf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnjCjeHbPzxm"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpqMCRpQP9VT"
      },
      "source": [
        "import lightgbm as lgb\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import word_tokenize\n",
        "import warnings\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOobSAOUP-rU"
      },
      "source": [
        "rcParams['figure.figsize'] = (16, 8)\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('max_columns', 100)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "warnings.simplefilter('ignore')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxmS6V7-QAYV",
        "outputId": "32855a9b-be66-4373-8d80-5159fd3bcfc7"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Restrict TensorFlow to only use the first GPU\n",
        "    try:\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "    except RuntimeError as e:\n",
        "        # Visible devices must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "else:\n",
        "    print('No GPU detected')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU detected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBxBwZ4oQBuD"
      },
      "source": [
        "data_dir = Path('/content/drive/MyDrive/dacon/input')\n",
        "feature_dir = Path('../build/feature')\n",
        "val_dir = Path('/content/drive/MyDrive/dacon/build/val')\n",
        "tst_dir = Path('/content/drive/MyDrive/dacon/build/tst')\n",
        "sub_dir = Path('/content/drive/MyDrive/dacon/build/sub')\n",
        "\n",
        "trn_file = data_dir / 'train.csv'\n",
        "tst_file = data_dir / 'test_x.csv'\n",
        "sample_file = data_dir / 'sample_submission.csv'\n",
        "\n",
        "target_col = 'author'\n",
        "n_fold = 5\n",
        "n_class = 5\n",
        "seed = 42"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUGFiQMQQDas"
      },
      "source": [
        "algo_name = 'rf'\n",
        "feature_name = 'feature'\n",
        "model_name = f'{algo_name}_{feature_name}'\n",
        "\n",
        "feature_file = feature_dir / f'{feature_name}.csv'\n",
        "p_val_file = val_dir / f'{model_name}.val.csv'\n",
        "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
        "sub_file = sub_dir / f'{model_name}.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "aR335TmbQFFZ",
        "outputId": "ec60c1bf-d2d6-4afd-833f-85d40e9c71fa"
      },
      "source": [
        "train = pd.read_csv(trn_file, index_col=0)\n",
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "0      He was almost choking. There was so much, so m...       3\n",
              "1                 “Your sister asked for it, I suppose?”       2\n",
              "2       She was engaged one day as she walked, in per...       1\n",
              "3      The captain was in the porch, keeping himself ...       4\n",
              "4      “Have mercy, gentlemen!” odin flung up his han...       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "2aGf9f5NQGYU",
        "outputId": "362857a4-bb9a-415a-edeb-a80558ba46bf"
      },
      "source": [
        "test = pd.read_csv(tst_file, index_col=0)\n",
        "test.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Not at all. I think she is one of the most ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As the lady had stated her intention of scream...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“And then suddenly in the silence I heard a so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>His conviction remained unchanged. So far as I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "index                                                   \n",
              "0      “Not at all. I think she is one of the most ch...\n",
              "1      \"No,\" replied he, with sudden consciousness, \"...\n",
              "2      As the lady had stated her intention of scream...\n",
              "3      “And then suddenly in the silence I heard a so...\n",
              "4      His conviction remained unchanged. So far as I..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTBAibNOQHwQ"
      },
      "source": [
        "\n",
        "train['text'] = train['text'].str.replace('\\?',' quesmark ')\n",
        "train['text'] = train['text'].str.replace('\\!',' exclmark ')\n",
        "train['text'] = train['text'].str.replace('\\&',' empent ')\n",
        "train['text'] = train['text'].str.replace(\"\\*\",' chstar ')\n",
        "train['text'] = train['text'].str.replace(\";\",' smcolons  ')\n",
        "\n",
        "test['text'] = test['text'].str.replace('\\?',' quesmark ')\n",
        "test['text'] = test['text'].str.replace('\\!',' exclmark ')\n",
        "test['text'] = test['text'].str.replace('\\&',' empent ')\n",
        "test['text'] = test['text'].str.replace(\"\\*\",' chstar ')\n",
        "test['text'] = test['text'].str.replace(\";\",' smcolons  ')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lplYZaRQamd"
      },
      "source": [
        "train['text']=train['text'].str.replace('á', ' Ascenda ')\n",
        "train['text']=train['text'].str.replace('à', ' Descenda ')\n",
        "train['text']=train['text'].str.replace('â', ' Stremama ')\n",
        "train['text']=train['text'].str.replace('ä', ' Doublea ')\n",
        "train['text']=train['text'].str.replace('é', ' Ascende ')\n",
        "train['text']=train['text'].str.replace('í', ' Justi ')\n",
        "train['text']=train['text'].str.replace('ï', ' Doublei ')\n",
        "train['text']=train['text'].str.replace('ó', ' Comao ')\n",
        "train['text']=train['text'].str.replace('ú', ' Ascendu ')\n",
        "train['text']=train['text'].str.replace('ý', ' Ascendy ')\n",
        "train['text']=train['text'].str.replace('ü', ' Umlaut ')\n",
        "train['text']=train['text'].str.replace('è', ' Descende ')\n",
        "train['text']=train['text'].str.replace('£', ' Maludf ')\n",
        "\n",
        "test['text']=test['text'].str.replace('ä', ' Doublea ')\n",
        "test['text']=test['text'].str.replace('â', ' Stremama ')\n",
        "test['text']=test['text'].str.replace('à', ' Descenda ')\n",
        "test['text']=test['text'].str.replace('á', ' Ascenda ')\n",
        "test['text']=test['text'].str.replace('é', ' Ascende ')\n",
        "test['text']=test['text'].str.replace('ï', ' Doublei ')\n",
        "test['text']=test['text'].str.replace('í', ' Justi ')\n",
        "test['text']=test['text'].str.replace('ó', ' Comao  ')\n",
        "test['text']=test['text'].str.replace('ú', ' Ascendu ')\n",
        "test['text']=test['text'].str.replace('ý', ' Ascendy ')\n",
        "test['text']=test['text'].str.replace('ü', ' Umalut ')\n",
        "test['text']=test['text'].str.replace('è', ' Descende ')\n",
        "test['text']=test['text'].str.replace('£', ' Maludf ')\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZb0WO3F_wYC"
      },
      "source": [
        "from collections import Counter\n",
        "cnt = Counter()\n",
        "for text in train[\"text\"].values:\n",
        "    for word in text.split():\n",
        "        cnt[word] += 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGwnP1zo_xsr"
      },
      "source": [
        "n_rare_words = 40\n",
        "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
        "def remove_rarewords(text):\n",
        "    \"\"\"custom function to remove the rare words\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
        "\n",
        "train[\"text\"] = train[\"text\"].str.lower().apply(remove_rarewords)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NcqaLy3Qasy"
      },
      "source": [
        "\n",
        "train['text']=train['text'].str.replace('\\(', ' \\( ')\n",
        "train['text']=train['text'].str.replace('\\{', ' \\{ ')\n",
        "train['text']=train['text'].str.replace('\\[', ' \\[ ')\n",
        "train['text']=train['text'].str.replace('\\)', ' \\) ')\n",
        "train['text']=train['text'].str.replace('\\}', ' \\} ')\n",
        "train['text']=train['text'].str.replace('\\]', ' \\] ')\n",
        "train['text']=train['text'].str.replace('—', '')\n",
        "train['text']=train['text'].str.replace('_', '')\n",
        "train['text']=train['text'].str.replace(':', '')\n",
        "\n",
        "\n",
        "test['text']=test['text'].str.replace('\\(', ' \\( ')\n",
        "test['text']=test['text'].str.replace('\\{', ' \\{ ')\n",
        "test['text']=test['text'].str.replace('\\[', ' \\[ ')\n",
        "test['text']=test['text'].str.replace('\\)', ' \\) ')\n",
        "test['text']=test['text'].str.replace('\\}', ' \\} ')\n",
        "test['text']=test['text'].str.replace('\\]', ' \\] ')\n",
        "test['text']=test['text'].str.replace('—', '')\n",
        "test['text']=test['text'].str.replace('_', '')\n",
        "test['text']=test['text'].str.replace(':', '')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMvKnjmcQazX",
        "outputId": "63b0fcd4-1af2-4adf-d369-39d87e81ac85"
      },
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XLt_HSHQa57"
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer \n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "def lemma_text(text):\n",
        "    tokenizer=TweetTokenizer()\n",
        "    words=tokenizer.tokenize(text)\n",
        "    lem = WordNetLemmatizer()\n",
        "    words=[lem.lemmatize(word, \"v\") for word in words]\n",
        "    \n",
        "    clean_sent=\" \".join(words)\n",
        "    \n",
        "    return clean_sent\n",
        "\n",
        "train['text'] = train['text'].str.lower().apply(lemma_text)\n",
        "test['text'] = test['text'].str.lower().apply(lemma_text)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBw7UcaRQa-5",
        "outputId": "ce7fce80-5f7b-4465-ebe7-74dda96993a5"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "vec = TfidfVectorizer(tokenizer=word_tokenize, stop_words=stopwords.words('english'), ngram_range=(1, 3),max_features=2500 ,min_df=8, \n",
        "                      sublinear_tf=True)\n",
        "X = vec.fit_transform(train['text'])\n",
        "X_tst = vec.transform(test['text'])\n",
        "print(X.shape, X_tst.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879, 2500) (19617, 2500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrGXKddbQMpI",
        "outputId": "4c853bf8-94e8-4932-9915-090faf14800c"
      },
      "source": [
        "y = train.author.values\n",
        "y.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54879,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJgZzdSsQMvd"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-z8DbNbQM1t",
        "outputId": "477c52eb-8234-4877-b6ea-37545cc005fc"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "p_val = np.zeros((X.shape[0], n_class))\n",
        "p_tst = np.zeros((X_tst.shape[0], n_class))\n",
        "for i, (i_trn, i_val) in enumerate(cv.split(X, y), 1):\n",
        "    print(f'training model for CV #{i}')\n",
        "    clf = RandomForestClassifier(n_estimators=1000,\n",
        "                                 min_samples_leaf=5,\n",
        "                                 max_features='auto',\n",
        "                                 max_samples=.4,\n",
        "                                 random_state=seed,\n",
        "                                 n_jobs=-1)\n",
        "    clf.fit(X[i_trn], y[i_trn])\n",
        "    p_val[i_val, :] = clf.predict_proba(X[i_val])\n",
        "    p_tst += clf.predict_proba(X_tst) / n_fold"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model for CV #1\n",
            "training model for CV #2\n",
            "training model for CV #3\n",
            "training model for CV #4\n",
            "training model for CV #5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owc6Hy8PQRk_",
        "outputId": "0c0b1d28-bd73-42f3-fb01-351f2ed4959c"
      },
      "source": [
        "\n",
        "print(f'{accuracy_score(y, np.argmax(p_val, axis=1)) * 100:.4f}%')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64.4163%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSl4ndGHQRsj"
      },
      "source": [
        "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
        "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNDKGhykQRzR"
      },
      "source": [
        "sub = pd.read_csv(sample_file, index_col=0)\n",
        "print(sub.shape)\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ORnzz7CQR6E"
      },
      "source": [
        "sub[sub.columns] = p_tst\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egPQsbl_QXtS"
      },
      "source": [
        "\n",
        "sub.to_csv(sub_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQvkI-ieQX0a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
