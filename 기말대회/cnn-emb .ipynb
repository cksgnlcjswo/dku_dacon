{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-emb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTbCBmuqMG7J"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b2LpgLPMQET"
      },
      "source": [
        "from matplotlib import rcParams, pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings \n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HiKxe5qMauM",
        "outputId": "99f570e7-c635-4796-8bee-8b23ed11ea07"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Restrict TensorFlow to only use the first GPU\n",
        "    try:\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "    except RuntimeError as e:\n",
        "        # Visible devices must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "else:\n",
        "    print('No GPU detected')\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaSKGWcLMbK1"
      },
      "source": [
        "rcParams['figure.figsize'] = (16, 8)\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('max_columns', 100)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ahUSLlvMbVN"
      },
      "source": [
        "data_dir = Path('/content/drive/MyDrive/dacon/input')\n",
        "feature_dir = Path('../build/feature')\n",
        "val_dir = Path('/content/drive/MyDrive/dacon/build/val')\n",
        "tst_dir = Path('/content/drive/MyDrive/dacon/build/tst')\n",
        "sub_dir = Path('/content/drive/MyDrive/dacon/build/sub')\n",
        "\n",
        "trn_file = data_dir / 'train.csv'\n",
        "tst_file = data_dir / 'test_x.csv'\n",
        "sample_file = data_dir / 'sample_submission.csv'\n",
        "\n",
        "target_col = 'author'\n",
        "n_fold = 5\n",
        "n_class = 5\n",
        "seed = 42"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srh_K431Mbck"
      },
      "source": [
        "algo_name = 'cnn'\n",
        "feature_name = 'emb'\n",
        "model_name = f'{algo_name}_{feature_name}'\n",
        "\n",
        "feature_file = feature_dir / f'{feature_name}.csv'\n",
        "p_val_file = val_dir / f'{model_name}.val.csv'\n",
        "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
        "sub_file = sub_dir / f'{model_name}.csv'"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "aZQsfKEYMbjN",
        "outputId": "356d34d7-fc0b-4b9d-8076-91859b6ac8e5"
      },
      "source": [
        "train = pd.read_csv(trn_file, index_col=0)\n",
        "train.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "0      He was almost choking. There was so much, so m...       3\n",
              "1                 “Your sister asked for it, I suppose?”       2\n",
              "2       She was engaged one day as she walked, in per...       1\n",
              "3      The captain was in the porch, keeping himself ...       4\n",
              "4      “Have mercy, gentlemen!” odin flung up his han...       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "SLWpuaSGMbpz",
        "outputId": "1efbf8aa-9486-481e-bfb0-8fde1b9f1b70"
      },
      "source": [
        "test = pd.read_csv(tst_file, index_col=0)\n",
        "test.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Not at all. I think she is one of the most ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As the lady had stated her intention of scream...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“And then suddenly in the silence I heard a so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>His conviction remained unchanged. So far as I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "index                                                   \n",
              "0      “Not at all. I think she is one of the most ch...\n",
              "1      \"No,\" replied he, with sudden consciousness, \"...\n",
              "2      As the lady had stated her intention of scream...\n",
              "3      “And then suddenly in the silence I heard a so...\n",
              "4      His conviction remained unchanged. So far as I..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHWeJJjcMbws"
      },
      "source": [
        "train['text'] = train['text'].str.replace('\\?',' quesmark ')\n",
        "train['text'] = train['text'].str.replace('\\!',' exclmark ')\n",
        "train['text'] = train['text'].str.replace('\\&',' empent ')\n",
        "train['text'] = train['text'].str.replace(\"\\*\",' chstar ')\n",
        "train['text'] = train['text'].str.replace(\";\",' smcolons  ')\n",
        "\n",
        "test['text'] = test['text'].str.replace('\\?',' quesmark ')\n",
        "test['text'] = test['text'].str.replace('\\!',' exclmark ')\n",
        "test['text'] = test['text'].str.replace('\\&',' empent ')\n",
        "test['text'] = test['text'].str.replace(\"\\*\",' chstar ')\n",
        "test['text'] = test['text'].str.replace(\";\",' smcolons  ')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai_2ayvsMb3a"
      },
      "source": [
        "cont_dict={\"ain't\": 'are not',\n",
        " \"aren't\": 'are not',\n",
        " \"can't\": 'can not',\n",
        " \"can't've\": 'can not have',\n",
        " \"'cause\": 'because',\n",
        " \"could've\": 'could have',\n",
        " \"couldn't\": 'could not',\n",
        " \"couldn't've\": 'could not have',\n",
        " \"didn't\": 'did not',\n",
        " \"doesn't\": 'does not',\n",
        " \"don't\": 'do not',\n",
        " \"hadn't\": 'had not',\n",
        " \"hadn't've\": 'had not have',\n",
        " \"hasn't\": 'has not',\n",
        " \"haven't\": 'have not',\n",
        " \"\\'he'd\": 'he would',\n",
        " \"\\'he'd've\": 'he would have',\n",
        " \"\\'he'll\": 'he will',\n",
        " \"\\'he'll've\": 'he will have',\n",
        " \"\\'he's\": 'he is',\n",
        " \"\\'how'd\": 'how did',\n",
        " \"\\'how're\": 'how are',\n",
        " \"\\'how'd'y\": 'how do you',\n",
        " \"\\'how'll\": 'how will',\n",
        " \"\\'how's\": 'how is',\n",
        " \"\\'I'd\": 'I would',\n",
        " \"\\'I'd've\": 'I would have',\n",
        " \"\\'I'll\": 'I will',\n",
        " \"\\'I'll've\": 'I will have',\n",
        " \"\\'I'm\": 'I am',\n",
        " \"\\'I've\": 'I have',\n",
        " \"\\'he'd\": 'he would',\n",
        " \"he'd've\": 'he would have',\n",
        " \"he'll\": 'he will',\n",
        " \"he'll've\": 'he will have',\n",
        " \"he's\": 'he is',\n",
        " \"how'd\": 'how did',\n",
        " \"how're\": 'how are',\n",
        " \"how'd'y\": 'how do you',\n",
        " \"how'll\": 'how will',\n",
        " \"how's\": 'how is',\n",
        " \"I'd\": 'I would',\n",
        " \"I'd've\": 'I would have',\n",
        " \"I'll\": 'I will',\n",
        " \"I'll've\": 'I will have',\n",
        " \"I'm\": 'I am',\n",
        " \"I've\": 'I have',         \n",
        " \"isn't\": 'is not',\n",
        " \"\\'it'd\": 'it would',\n",
        " \"\\'it'd've\": 'it would have',\n",
        " \"\\'it'll\": 'it will',\n",
        " \"\\'it'll've\": 'it will have',\n",
        " \"\\'it's\": 'it is',\n",
        " \"\\'let's\": 'let us',\n",
        " \"it'd\": 'it would',\n",
        " \"it'd've\": 'it would have',\n",
        " \"it'll\": 'it will',\n",
        " \"it'll've\": 'it will have',\n",
        " \"it's\": 'it is',\n",
        " \"let's\": 'let us',\n",
        " \"ma'am\": 'madam',\n",
        " \"mayn't\": 'may not',\n",
        " \"might've\": 'might have',\n",
        " \"mightn't\": 'might not',\n",
        " \"mightn't've\": 'might not have',\n",
        " \"must've\": 'must have',\n",
        " \"mustn't\": 'must not',\n",
        " \"mustn't've\": 'must not have',\n",
        " \"needn't\": 'need not',\n",
        " \"needn't've\": 'need not have',\n",
        " \"o'clock\": 'of the clock',\n",
        " \"oughtn't\": 'ought not',\n",
        " \"oughtn't've\": 'ought not have',\n",
        " \"\\'shan't\": 'shall not',\n",
        " \"\\'sha'n't\": 'shall not',\n",
        " \"\\'shan't've\": 'shall not have',\n",
        " \"\\'she'd\": 'she would',\n",
        " \"\\'she'd've\": 'she would have',\n",
        " \"\\'she'll\": 'she will',\n",
        " \"\\'she'll've\": 'she will have',\n",
        " \"\\'she's\": 'she is',\n",
        " \"\\'should've\": 'should have',\n",
        " \"\\'shouldn't\": 'should not',\n",
        " \"\\'shouldn't've\": 'should not have',\n",
        " \"shan't\": 'shall not',\n",
        " \"sha'n't\": 'shall not',\n",
        " \"shan't've\": 'shall not have',\n",
        " \"she'd\": 'she would',\n",
        " \"she'd've\": 'she would have',\n",
        " \"she'll\": 'she will',\n",
        " \"she'll've\": 'she will have',\n",
        " \"she's\": 'she is',\n",
        " \"should've\": 'should have',\n",
        " \"shouldn't\": 'should not',\n",
        " \"shouldn't've\": 'should not have',         \n",
        " \"so've\": 'so have',\n",
        " \"so's\": 'so is',\n",
        " \"\\'that'd\": 'that would',\n",
        " \"\\'that'd've\": 'that would have',\n",
        " \"\\'that's\": 'that is',\n",
        " \"\\'there'd\": 'there would',\n",
        " \"\\'there'd've\": 'there would have',\n",
        " \"\\'there's\": 'there is',\n",
        " \"\\'they'd\": 'they would',\n",
        " \"\\'they'd've\": 'they would have',\n",
        " \"\\'they'll\": 'they will',\n",
        " \"\\'they'll've\": 'they will have',\n",
        " \"\\'they're\": 'they are',\n",
        " \"\\'they've\": 'they have',\n",
        " \"that'd\": 'that would',\n",
        " \"that'd've\": 'that would have',\n",
        " \"that's\": 'that is',\n",
        " \"there'd\": 'there would',\n",
        " \"there'd've\": 'there would have',\n",
        " \"there's\": 'there is',\n",
        " \"they'd\": 'they would',\n",
        " \"they'd've\": 'they would have',\n",
        " \"they'll\": 'they will',\n",
        " \"they'll've\": 'they will have',\n",
        " \"they're\": 'they are',\n",
        " \"they've\": 'they have',         \n",
        " \"to've\": 'to have',\n",
        " \"wasn't\": 'was not',\n",
        " \"\\'we'd\": 'we would',\n",
        " \"\\'we'd've\": 'we would have',\n",
        " \"\\'we'll\": 'we will',\n",
        " \"\\'we'll've\": 'we will have',\n",
        " \"\\'we're\": 'we are',\n",
        " \"\\'we've\": 'we have',\n",
        " \"we'd\": 'we would',\n",
        " \"we'd've\": 'we would have',\n",
        " \"we'll\": 'we will',\n",
        " \"we'll've\": 'we will have',\n",
        " \"we're\": 'we are',\n",
        " \"we've\": 'we have',\n",
        " \"weren't\": 'were not',\n",
        " \"\\'what'll\": 'what will',\n",
        " \"\\'what'll've\": 'what will have',\n",
        " \"\\'what're\": 'what are',\n",
        " \"\\'what's\": 'what is',\n",
        " \"\\'what've\": 'what have',\n",
        " \"\\'when's\": 'when is',\n",
        " \"\\'when've\": 'when have',\n",
        " \"\\'where'd\": 'where did',\n",
        " \"\\'where's\": 'where is',\n",
        " \"\\'where've\": 'where have',\n",
        " \"\\'who'll\": 'who will',\n",
        " \"\\'who'll've\": 'who will have',\n",
        " \"\\'who's\": 'who is',\n",
        " \"\\'who've\": 'who have',\n",
        " \"\\'why's\": 'why is',\n",
        " \"\\'why've\": 'why have',\n",
        " \"\\'will've\": 'will have',\n",
        " \"\\'won't\": 'will not',\n",
        " \"\\'won't've\": 'will not have',\n",
        " \"\\'would've\": 'would have',\n",
        " \"\\'wouldn't\": 'would not',\n",
        " \"\\'wouldn't've\": 'would not have',\n",
        " \"what'll\": 'what will',\n",
        " \"what'll've\": 'what will have',\n",
        " \"what're\": 'what are',\n",
        " \"what's\": 'what is',\n",
        " \"what've\": 'what have',\n",
        " \"when's\": 'when is',\n",
        " \"when've\": 'when have',\n",
        " \"where'd\": 'where did',\n",
        " \"where's\": 'where is',\n",
        " \"where've\": 'where have',\n",
        " \"who'll\": 'who will',\n",
        " \"who'll've\": 'who will have',\n",
        " \"who's\": 'who is',\n",
        " \"who've\": 'who have',\n",
        " \"why's\": 'why is',\n",
        " \"why've\": 'why have',\n",
        " \"will've\": 'will have',\n",
        " \"won't\": 'will not',\n",
        " \"won't've\": 'will not have',\n",
        " \"would've\": 'would have',\n",
        " \"wouldn't\": 'would not',\n",
        " \"wouldn't've\": 'would not have',\n",
        " \"y'all\": 'you all',\n",
        " \"y'all'd\": 'you all would',\n",
        " \"y'all'd've\": 'you all would have',\n",
        " \"y'all're\": 'you all are',\n",
        " \"y'all've\": 'you all have',\n",
        " \"\\'you'd\": 'you would',\n",
        " \"\\'you'd've\": 'you would have',\n",
        " \"\\'you'll\": 'you will',\n",
        " \"\\'you'll've\": 'you shall have',\n",
        " \"\\'you're\": 'you are',\n",
        " \"\\'you've\": 'you have',\n",
        " \"you'd\": 'you would',\n",
        " \"you'd've\": 'you would have',\n",
        " \"you'll\": 'you will',\n",
        " \"you'll've\": 'you shall have',\n",
        " \"you're\": 'you are',\n",
        " \"you've\": 'you have',\n",
        " 'jan.': 'january',\n",
        " 'feb.': 'february',\n",
        " 'mar.': 'march',\n",
        " 'apr.': 'april',\n",
        " 'jun.': 'june',\n",
        " 'jul.': 'july',\n",
        " 'aug.': 'august',\n",
        " 'sep.': 'september',\n",
        " 'oct.': 'october',\n",
        " 'nov.': 'november',\n",
        " 'dec.': 'december',\n",
        " 'ain’t': 'are not',\n",
        " 'aren’t': 'are not',\n",
        " 'can’t': 'can not',\n",
        " 'can’t’ve': 'can not have',\n",
        " '’cause': 'because',\n",
        " 'could’ve': 'could have',\n",
        " 'couldn’t': 'could not',\n",
        " 'couldn’t’ve': 'could not have',\n",
        " 'didn’t': 'did not',\n",
        " 'doesn’t': 'does not',\n",
        " 'don’t': 'do not',\n",
        " 'hadn’t': 'had not',\n",
        " 'hadn’t’ve': 'had not have',\n",
        " 'hasn’t': 'has not',\n",
        " 'haven’t': 'have not',\n",
        " '\\'he’d': 'he would',\n",
        " '\\'he’d’ve': 'he would have',\n",
        " '\\'he’ll': 'he will',\n",
        " '\\'he’ll’ve': 'he will have',\n",
        " '\\'he’s': 'he is',\n",
        " '\\'how’d': 'how did',\n",
        " '\\'how’re': 'how are',\n",
        " '\\'how’d’y': 'how do you',\n",
        " '\\'how’ll': 'how will',\n",
        " '\\'how’s': 'how is',\n",
        " '\\'I’d': 'I would',\n",
        " '\\'I’d’ve': 'I would have',\n",
        " '\\'I’ll': 'I will',\n",
        " '\\'I’ll’ve': 'I will have',\n",
        " '\\'I’m': 'I am',\n",
        " '\\'I’ve': 'I have',\n",
        " '\\'isn’t': 'is not',\n",
        " '\\'it’d': 'it would',\n",
        " '\\'it’d’ve': 'it would have',\n",
        " '\\'it’ll': 'it will',\n",
        " '\\'it’ll’ve': 'it will have',\n",
        " '\\'it’s': 'it is',\n",
        " '\\'let’s': 'let us',  \n",
        " 'he’d': 'he would',\n",
        " 'he’d’ve': 'he would have',\n",
        " 'she’ll': 'he will',\n",
        " 'he’ll’ve': 'he will have',\n",
        " 'odin’s' : 'odin is',\n",
        " 'joe’s' : 'joe is',\n",
        " 'dora’s' : 'dora is',\n",
        " 'wickfield’s' : 'wickfield is',\n",
        " 'tellson’s' : 'tellson is',\n",
        " 'omer’s' :  'omer is',\n",
        " 'cruncher’s' : 'crucher is', \n",
        " 'pip’s' : 'pip is',\n",
        " 'creakle’s ': 'creakle is',\n",
        " 'jorkins’s ' : 'jorkins is',\n",
        " 'jane’s' : 'jane is',\n",
        " 'elliot’s' : 'elliot is',\n",
        " 'anne’s' : 'anne is',\n",
        " 'tilney’s' : 'tilney is',\n",
        " 'lizzy’s' : 'lizzy is',\n",
        " 'smith’s' : 'smith is',\n",
        " 'walter’s' : 'walter is',\n",
        " 'musgrove’s' : 'musgrove is',\n",
        " 'lucy’s' : 'lucy is',\n",
        " 'nigel’s' : 'nigel is',\n",
        " 'nay’s' : 'nay is',\n",
        " 'chodinger’s' : 'chodinger is',\n",
        " 'humphrey’s' : 'humphrey is',\n",
        " 'jack’s' : 'jack is',\n",
        " 'arthur’s': 'arthur is',\n",
        " 'lana’s': 'lana is',\n",
        " 'sarah’s': 'sarah is',\n",
        " 'garcia’s' : 'garcia is',\n",
        " 'ivan’s' : 'ivan is',\n",
        " 'zossimov’s' : 'zossimov is',\n",
        " 'totski’s' : 'totski is',\n",
        " 'miusov’s' : 'miusov is',\n",
        " 'rodya’s' : 'rodya is',\n",
        " 'odin’s' : 'odin is',\n",
        " 'maman’s' : 'maman is',\n",
        " 'thee’s' : 'thee is',\n",
        " 'ye’s' : 'ye is',\n",
        " 'richard’s' : 'richard is',\n",
        " 'silas’s' : 'silas is',\n",
        " 'von’s': 'von is',\n",
        " 'lanyon’s' : 'lanyon is',\n",
        " 'jack’s' : 'jack is',\n",
        " 'gunn’s' : 'gumn is',\n",
        " 'nay’s' : 'nay is',  \n",
        " 'rankeillor’s': 'rankeillor is',      \n",
        " 'odin\\'s' : 'odin is',\n",
        " 'joe\\'s' : 'joe is',\n",
        " 'dora\\'s' : 'dora is',\n",
        " 'wickfield\\'s' : 'wickfield is',\n",
        " 'tellson\\'s' : 'tellson is',\n",
        " 'omer\\'s' :  'omer is',\n",
        " 'cruncher\\'s' : 'crucher is', \n",
        " 'pip\\'s' : 'pip is',\n",
        " 'creakle\\'s ': 'creakle is',\n",
        " 'jorkins\\'s ' : 'jorkins is',\n",
        " 'jane\\'s' : 'jane is',\n",
        " 'elliot\\'s' : 'elliot is',\n",
        " 'anne\\'s' : 'anne is',\n",
        " 'tilney\\'s' : 'tilney is',\n",
        " 'lizzy\\'s' : 'lizzy is',\n",
        " 'smith\\'s' : 'smith is',\n",
        " 'walter\\'s' : 'walter is',\n",
        " 'musgrove\\'s' : 'musgrove is',\n",
        " 'lucy\\'s' : 'lucy is',\n",
        " 'nigel\\'s' : 'nigel is',\n",
        " 'nay\\'s' : 'nay is',\n",
        " 'chodinger\\'s' : 'chodinger is',\n",
        " 'humphrey\\'s' : 'humphrey is',\n",
        " 'jack\\'s' : 'jack is',\n",
        " 'arthur\\'s': 'arthur is',\n",
        " 'lana\\'s': 'lana is',\n",
        " 'sarah\\'s': 'sarah is',\n",
        " 'garcia\\'s' : 'garcia is',\n",
        " 'ivan\\'s' : 'ivan is',\n",
        " 'zossimov\\'s' : 'zossimov is',\n",
        " 'totski\\'s' : 'totski is',\n",
        " 'miusov\\'s' : 'miusov is',\n",
        " 'rodya\\'s' : 'rodya is',\n",
        " 'odin\\'s' : 'odin is',\n",
        " 'maman\\'s' : 'maman is',\n",
        " 'thee\\'s' : 'thee is',\n",
        " 'ye\\'s' : 'ye is',\n",
        " 'richard\\'s' : 'richard is',\n",
        " 'silas\\'s' : 'silas is',\n",
        " 'von\\'s': 'von is',\n",
        " 'lanyon\\'s' : 'lanyon is',\n",
        " 'jack\\'s' : 'jack is',\n",
        " 'gunn\\'s' : 'gumn is',\n",
        " 'nay\\'s' : 'nay is',  \n",
        " 'rankeillor\\'s': 'rankeillor is',          \n",
        " '\\'odin\\'s' : 'odin is',\n",
        " '\\'joe\\'s' : 'joe is',\n",
        " '\\'dora\\'s' : 'dora is',\n",
        " '\\'wickfield\\'s' : 'wickfield is',\n",
        " '\\'tellson\\'s' : 'tellson is',\n",
        " '\\'omer\\'s' :  'omer is',\n",
        " '\\'cruncher\\'s' : 'crucher is', \n",
        " '\\'pip\\'s' : 'pip is',\n",
        " '\\'creakle\\'s ': 'creakle is',\n",
        " '\\'jorkins\\'s ' : 'jorkins is',\n",
        " '\\'jane\\'s' : 'jane is',\n",
        " '\\'elliot\\'s' : 'elliot is',\n",
        " '\\'anne\\'s' : 'anne is',\n",
        " '\\'tilney\\'s' : 'tilney is',\n",
        " '\\'lizzy\\'s' : 'lizzy is',\n",
        " '\\'smith\\'s' : 'smith is',\n",
        " '\\'walter\\'s' : 'walter is',\n",
        " '\\'musgrove\\'s' : 'musgrove is',\n",
        " '\\'lucy\\'s' : 'lucy is',\n",
        " '\\'nigel\\'s' : 'nigel is',\n",
        " '\\'nay\\'s' : 'nay is',\n",
        " '\\'chodinger\\'s' : 'chodinger is',\n",
        " '\\'humphrey\\'s' : 'humphrey is',\n",
        " '\\'jack\\'s' : 'jack is',\n",
        " '\\'arthur\\'s': 'arthur is',\n",
        " '\\'lana\\'s': 'lana is',\n",
        " '\\'sarah\\'s': 'sarah is',\n",
        " '\\'garcia\\'s' : 'garcia is',\n",
        " '\\'ivan\\'s' : 'ivan is',\n",
        " '\\'zossimov\\'s' : 'zossimov is',\n",
        " '\\'totski\\'s' : 'totski is',\n",
        " '\\'miusov\\'s' : 'miusov is',\n",
        " '\\'rodya\\'s' : 'rodya is',\n",
        " '\\'odin\\'s' : 'odin is',\n",
        " '\\'maman\\'s' : 'maman is',\n",
        " '\\'thee\\'s' : 'thee is',\n",
        " '\\'ye\\'s' : 'ye is',\n",
        " '\\'richard\\'s' : 'richard is',\n",
        " '\\'silas\\'s' : 'silas is',\n",
        " '\\'von\\'s': 'von is',\n",
        " '\\'lanyon\\'s' : 'lanyon is',\n",
        " '\\'jack\\'s' : 'jack is',\n",
        " '\\'gunn\\'s' : 'gumn is',\n",
        " '\\'nay\\'s' : 'nay is',  \n",
        " '\\'rankeillor\\'s': 'rankeillor is',        \n",
        " 'he’s': 'he is',\n",
        " 'how’d': 'how did',\n",
        " 'how’re': 'how are',\n",
        " 'how’d’y': 'how do you',\n",
        " 'how’ll': 'how will',\n",
        " 'how’s': 'how is',\n",
        " 'I’d': 'I would',\n",
        " 'I’d’ve': 'I would have',\n",
        " 'I’ll': 'I will',\n",
        " 'I’ll’ve': 'I will have',\n",
        " 'I’m': 'I am',\n",
        " 'I’ve': 'I have',\n",
        " 'isn’t': 'is not',\n",
        " 'it’d': 'it would',\n",
        " 'it’d’ve': 'it would have',\n",
        " 'it’ll': 'it will',\n",
        " 'it’ll’ve': 'it will have',\n",
        " 'it’s': 'it is',\n",
        " 'let’s': 'let us',          \n",
        " 'ma’am': 'madam',\n",
        " 'mayn’t': 'may not',\n",
        " 'might’ve': 'might have',\n",
        " 'mightn’t': 'might not',\n",
        " 'mightn’t’ve': 'might not have',\n",
        " 'must’ve': 'must have',\n",
        " 'mustn’t': 'must not',\n",
        " 'mustn’t’ve': 'must not have',\n",
        " 'needn’t': 'need not',\n",
        " 'needn’t’ve': 'need not have',\n",
        " 'o’clock': 'of the clock',\n",
        " 'oughtn’t': 'ought not',\n",
        " 'oughtn’t’ve': 'ought not have',\n",
        " 'shan’t': 'shall not',\n",
        " 'sha’n’t': 'shall not',\n",
        " 'shan’t’ve': 'shall not have',\n",
        " '\\'she’d': 'she would',\n",
        " '\\'she’d’ve': 'she would have',\n",
        " '\\'she’ll': 'she will',\n",
        " '\\'she’ll’ve': 'she will have',\n",
        " '\\'she’s': 'she is',\n",
        " '\\'should’ve': 'should have',\n",
        " '\\'shouldn’t': 'should not',\n",
        " '\\'shouldn’t’ve': 'should not have',\n",
        " '\\'so’ve': 'so have',\n",
        " '\\'so’s': 'so is',\n",
        " '\\'that’d': 'that would',\n",
        " '\\'that’d’ve': 'that would have',\n",
        " '\\'that’s': 'that is',\n",
        " '\\'there’d': 'there would',\n",
        " '\\'there’d’ve': 'there would have',\n",
        " '\\'there’s': 'there is',\n",
        " '\\'they’d': 'they would',\n",
        " '\\'they’d’ve': 'they would have',\n",
        " '\\'they’ll': 'they will',\n",
        " '\\'they’ll’ve': 'they will have',\n",
        " '\\'they’re': 'they are',\n",
        " '\\'they’ve': 'they have',\n",
        " 'she’d': 'she would',\n",
        " 'she’d’ve': 'she would have',\n",
        " 'she’ll': 'she will',\n",
        " 'she’ll’ve': 'she will have',\n",
        " 'she’s': 'she is',\n",
        " 'should’ve': 'should have',\n",
        " 'shouldn’t': 'should not',\n",
        " 'shouldn’t’ve': 'should not have',\n",
        " 'so’ve': 'so have',\n",
        " 'so’s': 'so is',\n",
        " 'that’d': 'that would',\n",
        " 'that’d’ve': 'that would have',\n",
        " 'that’s': 'that is',\n",
        " 'there’d': 'there would',\n",
        " 'there’d’ve': 'there would have',\n",
        " 'there’s': 'there is',\n",
        " 'they’d': 'they would',\n",
        " 'they’d’ve': 'they would have',\n",
        " 'they’ll': 'they will',\n",
        " 'they’ll’ve': 'they will have',\n",
        " 'they’re': 'they are',\n",
        " 'they’ve': 'they have',      \n",
        " 'to’ve': 'to have',\n",
        " 'wasn’t': 'was not',\n",
        " '\\'we’d': 'we would',\n",
        " '\\'we’d’ve': 'we would have',\n",
        " '\\'we’ll': 'we will',\n",
        " '\\'we’ll’ve': 'we will have',\n",
        " '\\'we’re': 'we are',\n",
        " '\\'we’ve': 'we have',\n",
        " 'we’d': 'we would',\n",
        " 'we’d’ve': 'we would have',\n",
        " 'we’ll': 'we will',\n",
        " 'we’ll’ve': 'we will have',\n",
        " 'we’re': 'we are',\n",
        " 'we’ve': 'we have',          \n",
        " 'weren’t': 'were not',\n",
        " '\\'what’ll': 'what will',\n",
        " '\\'what’ll’ve': 'what will have',\n",
        " '\\'what’re': 'what are',\n",
        " '\\'what’s': 'what is',\n",
        " '\\'what’ve': 'what have',\n",
        " '\\'when’s': 'when is',\n",
        " '\\'when’ve': 'when have',\n",
        " '\\'where’d': 'where did',\n",
        " '\\'where’s': 'where is',\n",
        " '\\'where’ve': 'where have',\n",
        " '\\'who’ll': 'who will',\n",
        " '\\'who’ll’ve': 'who will have',\n",
        " '\\'who’s': 'who is',\n",
        " '\\'who’ve': 'who have',\n",
        " '\\'why’s': 'why is',\n",
        " '\\'why’ve': 'why have',\n",
        " '\\'will’ve': 'will have',\n",
        " '\\'won’t': 'will not',\n",
        " '\\'won’t’ve': 'will not have',\n",
        " '\\'would’ve': 'would have',\n",
        " '\\'wouldn’t': 'would not',\n",
        " '\\'wouldn’t’ve': 'would not have',\n",
        " 'what’ll': 'what will',\n",
        " 'what’ll’ve': 'what will have',\n",
        " 'what’re': 'what are',\n",
        " 'what’s': 'what is',\n",
        " 'what’ve': 'what have',\n",
        " 'when’s': 'when is',\n",
        " 'when’ve': 'when have',\n",
        " 'where’d': 'where did',\n",
        " 'where’s': 'where is',\n",
        " 'where’ve': 'where have',\n",
        " 'who’ll': 'who will',\n",
        " 'who’ll’ve': 'who will have',\n",
        " 'who’s': 'who is',\n",
        " 'who’ve': 'who have',\n",
        " 'why’s': 'why is',\n",
        " 'why’ve': 'why have',\n",
        " 'will’ve': 'will have',\n",
        " 'won’t': 'will not',\n",
        " 'won’t’ve': 'will not have',\n",
        " 'would’ve': 'would have',\n",
        " 'wouldn’t': 'would not',\n",
        " 'wouldn’t’ve': 'would not have',   \n",
        " 'y’all': 'you all',\n",
        " 'y’all’d': 'you all would',\n",
        " 'y’all’d’ve': 'you all would have',\n",
        " 'y’all’re': 'you all are',\n",
        " 'y’all’ve': 'you all have',\n",
        " '\\'you’d': 'you would',\n",
        " '\\'you’d’ve': 'you would have',\n",
        " '\\'you’ll': 'you will',\n",
        " '\\'you’ll’ve': 'you shall have',\n",
        " '\\'you’re': 'you are',\n",
        " '\\'you’ve': 'you have', \n",
        " 'you’d': 'you would',\n",
        " 'you’d’ve': 'you would have',\n",
        " 'you’ll': 'you will',\n",
        " 'you’ll’ve': 'you shall have',\n",
        " 'you’re': 'you are',\n",
        " 'you’ve': 'you have'\n",
        "}"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuBccnbRMb98"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "def clean_contraction(text):\n",
        "    words = text_to_word_sequence(text)\n",
        "    words=[cont_dict[word] if word in cont_dict else word for word in words]\n",
        "    clean_sent=\" \".join(words)\n",
        "    \n",
        "    return clean_sent\n",
        "\n",
        "train['text'] = train['text'].str.lower().apply(clean_contraction)\n",
        "test['text'] = test['text'].str.lower().apply(clean_contraction)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucknbDiMMcFX"
      },
      "source": [
        "train['text']=train['text'].str.replace('\\'s', '')\n",
        "train['text']=train['text'].str.replace('’s', '')\n",
        "train['text']=train['text'].str.replace(\"\\'\", '')\n",
        "train['text']=train['text'].str.replace(\"’\", '')\n",
        "\n",
        "test['text']=test['text'].str.replace(\"’s\",'')\n",
        "test['text']=test['text'].str.replace(\"\\'s\",'')\n",
        "test['text']=test['text'].str.replace(\"\\'\", '')\n",
        "test['text']=test['text'].str.replace(\"’\", '')\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGcv3tL2McMq"
      },
      "source": [
        "train['text']=train['text'].str.replace('á', '')\n",
        "train['text']=train['text'].str.replace('ä', '')\n",
        "train['text']=train['text'].str.replace('é', '')\n",
        "train['text']=train['text'].str.replace('í', '')\n",
        "train['text']=train['text'].str.replace('ó', '')\n",
        "train['text']=train['text'].str.replace('ú', '')\n",
        "train['text']=train['text'].str.replace('ý', '')\n",
        "train['text']=train['text'].str.replace('ü', ' Umlaut ')\n",
        "\n",
        "test['text']=test['text'].str.replace('ä', '')\n",
        "test['text']=test['text'].str.replace('á', '')\n",
        "test['text']=test['text'].str.replace('é', '')\n",
        "test['text']=test['text'].str.replace('í', '')\n",
        "test['text']=test['text'].str.replace('ó', '')\n",
        "test['text']=test['text'].str.replace('ú', '')\n",
        "test['text']=test['text'].str.replace('ý', '')\n",
        "test['text']=test['text'].str.replace('ü', ' Umlaut ')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "WtQcN35_Mccp",
        "outputId": "6e12ae43-8b08-4587-b80b-a06689fcf1d7"
      },
      "source": [
        "train['text'].str.len().hist()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6eb75cdf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VimIN9vMclT",
        "outputId": "93918cee-4e9c-4c56-cf12-54a48a641a2c"
      },
      "source": [
        "X_trn = train['text'].values\n",
        "X_tst = test['text'].values\n",
        "y = train['author'].values\n",
        "print(X_trn.shape, X_tst.shape, y.shape)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879,) (19617,) (54879,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3bdRKHoMcuT"
      },
      "source": [
        "vocab_size = 21000\n",
        "embedding_dim = 128\n",
        "max_length = 230\n",
        "padding_type='post'"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHip4uvHMc2P"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "tokenizer.fit_on_texts(X_trn)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x9C4seTMc-f"
      },
      "source": [
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(X_trn)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_tst)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OThSlL25MdHG",
        "outputId": "df858b50-04ab-4db0-f6db-751d2a960326"
      },
      "source": [
        "trn = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
        "tst = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n",
        "print(trn.shape, tst.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879, 230) (19617, 230)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92vBhrKgMdOd"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apsqIhOTPPd3"
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "        Dropout(0.2),\n",
        "        Conv1D(256, 3, padding='valid', activation='relu', strides=1),   \n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(n_class, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(learning_rate=.005))\n",
        "    return model"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HmEeZeTPR2l",
        "outputId": "8836911a-0779-4bea-8fe6-1a8f7daba52e"
      },
      "source": [
        "p_val = np.zeros((trn.shape[0], n_class))\n",
        "p_tst = np.zeros((tst.shape[0], n_class))\n",
        "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
        "    print(f'training model for CV #{i}')\n",
        "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
        "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "    clf = get_model()    \n",
        "    clf.fit(trn[i_trn], \n",
        "            to_categorical(y[i_trn]),\n",
        "            validation_data=(trn[i_val], to_categorical(y[i_val])),\n",
        "            epochs=10,\n",
        "            batch_size=256,\n",
        "            callbacks=[es])\n",
        "    p_val[i_val, :] = clf.predict(trn[i_val])\n",
        "    p_tst += clf.predict(tst) / n_fold"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model for CV #1\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 0.9950 - val_loss: 0.6699\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.5493 - val_loss: 0.6406\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 9s 51ms/step - loss: 0.3606 - val_loss: 0.6732\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 9s 51ms/step - loss: 0.2614 - val_loss: 0.7903\n",
            "Epoch 5/10\n",
            "171/172 [============================>.] - ETA: 0s - loss: 0.2134Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 9s 51ms/step - loss: 0.2133 - val_loss: 0.8497\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #2\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.9865 - val_loss: 0.7324\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.5340 - val_loss: 0.6390\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.3490 - val_loss: 0.6412\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.2487 - val_loss: 0.7188\n",
            "Epoch 5/10\n",
            "171/172 [============================>.] - ETA: 0s - loss: 0.1968Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.1966 - val_loss: 0.8850\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #3\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.9953 - val_loss: 0.6982\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 9s 51ms/step - loss: 0.5447 - val_loss: 0.6204\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 9s 51ms/step - loss: 0.3553 - val_loss: 0.6516\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 9s 51ms/step - loss: 0.2589 - val_loss: 0.7561\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.2067Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 9s 51ms/step - loss: 0.2067 - val_loss: 0.8811\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #4\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.9890 - val_loss: 0.6754\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.5240 - val_loss: 0.6149\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.3418 - val_loss: 0.6953\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.2496 - val_loss: 0.7725\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.1977Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.1977 - val_loss: 0.8957\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #5\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.0041 - val_loss: 0.6834\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.5486 - val_loss: 0.6512\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.3629 - val_loss: 0.6641\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 0.2721 - val_loss: 0.7566\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.2091Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 0.2091 - val_loss: 0.8220\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NhAmqFqPUPp",
        "outputId": "14e7d9da-728e-405a-e443-fe205077b6f5"
      },
      "source": [
        "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n",
        "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy (CV):  77.2044%\n",
            "Log Loss (CV):   0.6332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYyiNnrHPjF8"
      },
      "source": [
        "\n",
        "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
        "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "H7exZyfiPle_",
        "outputId": "5a3998dc-b3f2-4f64-d85e-58c11b20dba0"
      },
      "source": [
        "sub = pd.read_csv(sample_file, index_col=0)\n",
        "print(sub.shape)\n",
        "sub.head()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19617, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  1  2  3  4\n",
              "index               \n",
              "0      0  0  0  0  0\n",
              "1      0  0  0  0  0\n",
              "2      0  0  0  0  0\n",
              "3      0  0  0  0  0\n",
              "4      0  0  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "61nUSj3xPn6g",
        "outputId": "0922244f-0c1e-47dc-b570-2187b2b75313"
      },
      "source": [
        "sub[sub.columns] = p_tst\n",
        "sub.head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0253</td>\n",
              "      <td>0.2785</td>\n",
              "      <td>0.5559</td>\n",
              "      <td>0.1345</td>\n",
              "      <td>0.0057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.3911</td>\n",
              "      <td>0.2188</td>\n",
              "      <td>0.1082</td>\n",
              "      <td>0.0605</td>\n",
              "      <td>0.2214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9953</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.0011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.3220</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.3942</td>\n",
              "      <td>0.0087</td>\n",
              "      <td>0.2716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7582</td>\n",
              "      <td>0.0139</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0       1       2       3       4\n",
              "index                                        \n",
              "0      0.0253  0.2785  0.5559  0.1345  0.0057\n",
              "1      0.3911  0.2188  0.1082  0.0605  0.2214\n",
              "2      0.9953  0.0008  0.0022  0.0006  0.0011\n",
              "3      0.3220  0.0035  0.3942  0.0087  0.2716\n",
              "4      0.7582  0.0139  0.1264  0.0187  0.0827"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6alb5f5PoFC"
      },
      "source": [
        "sub.to_csv(sub_file)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlNrcWwVQGyV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
