{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNF92ZSpDaTY"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XU_tg0lDpdZ"
      },
      "source": [
        "\n",
        "import gc\n",
        "from matplotlib import rcParams, pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings \n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2EIiJ3oDr3e"
      },
      "source": [
        "rcParams['figure.figsize'] = (16, 8)\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('max_columns', 100)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNm1lVphDtJ_"
      },
      "source": [
        "data_dir = Path('/content/drive/MyDrive/dacon/input/')\n",
        "feature_dir = Path('../build/feature')\n",
        "val_dir = Path('/content/drive/MyDrive/dacon/build/val')\n",
        "tst_dir = Path('/content/drive/MyDrive/dacon/build/tst')\n",
        "sub_dir = Path('/content/drive/MyDrive/dacon/build/sub')\n",
        "\n",
        "trn_file = data_dir / 'train.csv'\n",
        "tst_file = data_dir / 'test_x.csv'\n",
        "sample_file = data_dir / 'sample_submission.csv'\n",
        "\n",
        "target_col = 'author'\n",
        "n_fold = 5\n",
        "n_class = 5\n",
        "seed = 42"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bANeR5sRDvRu"
      },
      "source": [
        "algo_name = 'mta'\n",
        "feature_name = 'emb'\n",
        "model_name = f'{algo_name}_{feature_name}'\n",
        "\n",
        "feature_file = feature_dir / f'{feature_name}.csv'\n",
        "p_val_file = val_dir / f'{model_name}.val.csv'\n",
        "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
        "sub_file = sub_dir / f'{model_name}.csv'"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "VFY3nJFhDw7T",
        "outputId": "876c3602-5cbf-4b0b-f35f-e343d08be385"
      },
      "source": [
        "train = pd.read_csv(trn_file, index_col=0)\n",
        "train.head()"
      ],
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "0      He was almost choking. There was so much, so m...       3\n",
              "1                 “Your sister asked for it, I suppose?”       2\n",
              "2       She was engaged one day as she walked, in per...       1\n",
              "3      The captain was in the porch, keeping himself ...       4\n",
              "4      “Have mercy, gentlemen!” odin flung up his han...       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "eJAoOzzgDyNp",
        "outputId": "f76e3068-09c4-4f77-d851-1f531f135286"
      },
      "source": [
        "test = pd.read_csv(tst_file, index_col=0)\n",
        "test.head()"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Not at all. I think she is one of the most ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As the lady had stated her intention of scream...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“And then suddenly in the silence I heard a so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>His conviction remained unchanged. So far as I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "index                                                   \n",
              "0      “Not at all. I think she is one of the most ch...\n",
              "1      \"No,\" replied he, with sudden consciousness, \"...\n",
              "2      As the lady had stated her intention of scream...\n",
              "3      “And then suddenly in the silence I heard a so...\n",
              "4      His conviction remained unchanged. So far as I..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScCBrsT4EdyQ"
      },
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output\n",
        "    \n",
        "    \n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "    \n",
        "    \n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilp7KFvXEfyG",
        "outputId": "77571ee5-1455-4856-97dc-e1638ef4ba0f"
      },
      "source": [
        "X_train = train['text'].values\n",
        "X_test = test['text'].values\n",
        "y = train['author'].values\n",
        "print(X_train.shape, X_test.shape, y.shape)"
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879,) (19617,) (54879,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "X_k-iC3rk93V",
        "outputId": "d24c3c96-9e31-4d9e-8d38-090ace03a234"
      },
      "source": [
        "train[train['text'].str.contains(\"’\")]"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>“Indeed she didn’t. By God I swear she didn’t ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>‘Why, the fact is,’ returned odin, ‘Mr. odin h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>“And why are you so dressed up? What a curious...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54841</th>\n",
              "      <td>‘Though harrowing to myself to mention, the al...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54842</th>\n",
              "      <td>“I call it noble,” I cried. “I’m a Whig, or li...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54854</th>\n",
              "      <td>“I’ve been waiting for you for the last hour, ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54862</th>\n",
              "      <td>‘That’s Missis odin,’ said Mr. odin.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54872</th>\n",
              "      <td>‘And the premium, sir,’ I returned, ‘is a thou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13277 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "2       She was engaged one day as she walked, in per...       1\n",
              "4      “Have mercy, gentlemen!” odin flung up his han...       3\n",
              "17     “Indeed she didn’t. By God I swear she didn’t ...       3\n",
              "19     ‘Why, the fact is,’ returned odin, ‘Mr. odin h...       0\n",
              "21     “And why are you so dressed up? What a curious...       3\n",
              "...                                                  ...     ...\n",
              "54841  ‘Though harrowing to myself to mention, the al...       0\n",
              "54842  “I call it noble,” I cried. “I’m a Whig, or li...       4\n",
              "54854  “I’ve been waiting for you for the last hour, ...       3\n",
              "54862               ‘That’s Missis odin,’ said Mr. odin.       0\n",
              "54872  ‘And the premium, sir,’ I returned, ‘is a thou...       0\n",
              "\n",
              "[13277 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJPespo_Ehmd"
      },
      "source": [
        "#기회갇 되면 &포함시켜서 훈련시켜보기\n",
        "# -은 한단어로 표현된 경우도 있으니 놔두기.\n",
        "import string\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    punc=[]\n",
        "    #punc.append('!')\n",
        "    punc.append('.')\n",
        "    punc.append(':')\n",
        "    punc.append(\",\")\n",
        "    punc.append(';')\n",
        "    punc.append('\\\"')\n",
        "    punc.append('“')\n",
        "    punc.append('”')\n",
        "    punc.append(\"’\")\n",
        "    #punc.append(\"?\")\n",
        "    punc.append(\"{\")\n",
        "    punc.append('[')\n",
        "    punc.append(']')\n",
        "    punc.append(\"}\")\n",
        "    punc.append('(')\n",
        "    punc.append(')')\n",
        "    #punc.append('&')\n",
        "    #punc.append('*')\n",
        "    punc.append('+')\n",
        "    for punctuation in punc:\n",
        "        text = text.replace(punctuation, '')\n",
        "    return text\n",
        "\n",
        "train[\"text\"] = train['text'].str.lower().apply(remove_punctuations)\n",
        "test['text'] = test['text'].str.lower().apply(remove_punctuations)"
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXqMGispUeim",
        "outputId": "f8bfb230-69d1-4121-cbcd-099d663229d6"
      },
      "source": [
        "train.iloc[54750]"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text       * * * * *\n",
              "author             4\n",
              "Name: 54750, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbju4Lc9nc_z"
      },
      "source": [
        "train['text'] = train['text'].str.replace('\\?',' quesmark ')\n",
        "train['text'] = train['text'].str.replace('\\!',' exclmark ')\n",
        "train['text'] = train['text'].str.replace('\\&',' empent ')\n",
        "train['text'] = train['text'].str.replace(\"\\*\",' chstar ')\n",
        "test['text'] = test['text'].str.replace('\\?',' quesmark ')\n",
        "test['text'] = test['text'].str.replace('\\!',' exclmark ')\n",
        "test['text'] = test['text'].str.replace('\\&',' empent ')\n",
        "test['text'] = test['text'].str.replace(\"\\*\",' chstar ')"
      ],
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "86exTrFooMGW",
        "outputId": "8f34adce-c281-4690-ffd4-bfc2edfca173"
      },
      "source": [
        "train[train['text'].str.contains(\"chstar\")]"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>chstar   chstar   chstar   chstar   chstar</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2599</th>\n",
              "      <td>mr odin exclmark  cried odin seeming glad of a...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3212</th>\n",
              "      <td>ay said odin and by my troth i wish he was ali...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3367</th>\n",
              "      <td>the limmer exclmark  he cried twelve hunner an...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3493</th>\n",
              "      <td>chstar   chstar   chstar   chstar   chstar</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50963</th>\n",
              "      <td>chstar   chstar   chstar   chstar   chstar</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52675</th>\n",
              "      <td>chstar   chstar   chstar   chstar   chstar</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54376</th>\n",
              "      <td>ay said he now we have a chance and then looki...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54750</th>\n",
              "      <td>chstar   chstar   chstar   chstar   chstar</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54785</th>\n",
              "      <td>five exclmark  cried the captain come that's b...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "1455         chstar   chstar   chstar   chstar   chstar        2\n",
              "2599   mr odin exclmark  cried odin seeming glad of a...       3\n",
              "3212   ay said odin and by my troth i wish he was ali...       4\n",
              "3367   the limmer exclmark  he cried twelve hunner an...       4\n",
              "3493         chstar   chstar   chstar   chstar   chstar        4\n",
              "...                                                  ...     ...\n",
              "50963        chstar   chstar   chstar   chstar   chstar        2\n",
              "52675        chstar   chstar   chstar   chstar   chstar        0\n",
              "54376  ay said he now we have a chance and then looki...       4\n",
              "54750        chstar   chstar   chstar   chstar   chstar        4\n",
              "54785  five exclmark  cried the captain come that's b...       4\n",
              "\n",
              "[89 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erHdpJ_GEjHW"
      },
      "source": [
        "cont_dict={\"ain't\": 'are not',\n",
        " \"aren't\": 'are not',\n",
        " \"can't\": 'can not',\n",
        " \"can't've\": 'can not have',\n",
        " \"'cause\": 'because',\n",
        " \"could've\": 'could have',\n",
        " \"couldn't\": 'could not',\n",
        " \"couldn't've\": 'could not have',\n",
        " \"didn't\": 'did not',\n",
        " \"doesn't\": 'does not',\n",
        " \"don't\": 'do not',\n",
        " \"hadn't\": 'had not',\n",
        " \"hadn't've\": 'had not have',\n",
        " \"hasn't\": 'has not',\n",
        " \"haven't\": 'have not',\n",
        " \"\\'he'd\": 'he would',\n",
        " \"\\'he'd've\": 'he would have',\n",
        " \"\\'he'll\": 'he will',\n",
        " \"\\'he'll've\": 'he will have',\n",
        " \"\\'he's\": 'he is',\n",
        " \"\\'how'd\": 'how did',\n",
        " \"\\'how're\": 'how are',\n",
        " \"\\'how'd'y\": 'how do you',\n",
        " \"\\'how'll\": 'how will',\n",
        " \"\\'how's\": 'how is',\n",
        " \"\\'I'd\": 'I would',\n",
        " \"\\'I'd've\": 'I would have',\n",
        " \"\\'I'll\": 'I will',\n",
        " \"\\'I'll've\": 'I will have',\n",
        " \"\\'I'm\": 'I am',\n",
        " \"\\'I've\": 'I have',\n",
        " \"\\'he'd\": 'he would',\n",
        " \"he'd've\": 'he would have',\n",
        " \"he'll\": 'he will',\n",
        " \"he'll've\": 'he will have',\n",
        " \"he's\": 'he is',\n",
        " \"how'd\": 'how did',\n",
        " \"how're\": 'how are',\n",
        " \"how'd'y\": 'how do you',\n",
        " \"how'll\": 'how will',\n",
        " \"how's\": 'how is',\n",
        " \"I'd\": 'I would',\n",
        " \"I'd've\": 'I would have',\n",
        " \"I'll\": 'I will',\n",
        " \"I'll've\": 'I will have',\n",
        " \"I'm\": 'I am',\n",
        " \"I've\": 'I have',         \n",
        " \"isn't\": 'is not',\n",
        " \"\\'it'd\": 'it would',\n",
        " \"\\'it'd've\": 'it would have',\n",
        " \"\\'it'll\": 'it will',\n",
        " \"\\'it'll've\": 'it will have',\n",
        " \"\\'it's\": 'it is',\n",
        " \"\\'let's\": 'let us',\n",
        " \"it'd\": 'it would',\n",
        " \"it'd've\": 'it would have',\n",
        " \"it'll\": 'it will',\n",
        " \"it'll've\": 'it will have',\n",
        " \"it's\": 'it is',\n",
        " \"let's\": 'let us',\n",
        " \"ma'am\": 'madam',\n",
        " \"mayn't\": 'may not',\n",
        " \"might've\": 'might have',\n",
        " \"mightn't\": 'might not',\n",
        " \"mightn't've\": 'might not have',\n",
        " \"must've\": 'must have',\n",
        " \"mustn't\": 'must not',\n",
        " \"mustn't've\": 'must not have',\n",
        " \"needn't\": 'need not',\n",
        " \"needn't've\": 'need not have',\n",
        " \"o'clock\": 'of the clock',\n",
        " \"oughtn't\": 'ought not',\n",
        " \"oughtn't've\": 'ought not have',\n",
        " \"\\'shan't\": 'shall not',\n",
        " \"\\'sha'n't\": 'shall not',\n",
        " \"\\'shan't've\": 'shall not have',\n",
        " \"\\'she'd\": 'she would',\n",
        " \"\\'she'd've\": 'she would have',\n",
        " \"\\'she'll\": 'she will',\n",
        " \"\\'she'll've\": 'she will have',\n",
        " \"\\'she's\": 'she is',\n",
        " \"\\'should've\": 'should have',\n",
        " \"\\'shouldn't\": 'should not',\n",
        " \"\\'shouldn't've\": 'should not have',\n",
        " \"shan't\": 'shall not',\n",
        " \"sha'n't\": 'shall not',\n",
        " \"shan't've\": 'shall not have',\n",
        " \"she'd\": 'she would',\n",
        " \"she'd've\": 'she would have',\n",
        " \"she'll\": 'she will',\n",
        " \"she'll've\": 'she will have',\n",
        " \"she's\": 'she is',\n",
        " \"should've\": 'should have',\n",
        " \"shouldn't\": 'should not',\n",
        " \"shouldn't've\": 'should not have',         \n",
        " \"so've\": 'so have',\n",
        " \"so's\": 'so is',\n",
        " \"\\'that'd\": 'that would',\n",
        " \"\\'that'd've\": 'that would have',\n",
        " \"\\'that's\": 'that is',\n",
        " \"\\'there'd\": 'there would',\n",
        " \"\\'there'd've\": 'there would have',\n",
        " \"\\'there's\": 'there is',\n",
        " \"\\'they'd\": 'they would',\n",
        " \"\\'they'd've\": 'they would have',\n",
        " \"\\'they'll\": 'they will',\n",
        " \"\\'they'll've\": 'they will have',\n",
        " \"\\'they're\": 'they are',\n",
        " \"\\'they've\": 'they have',\n",
        " \"that'd\": 'that would',\n",
        " \"that'd've\": 'that would have',\n",
        " \"that's\": 'that is',\n",
        " \"there'd\": 'there would',\n",
        " \"there'd've\": 'there would have',\n",
        " \"there's\": 'there is',\n",
        " \"they'd\": 'they would',\n",
        " \"they'd've\": 'they would have',\n",
        " \"they'll\": 'they will',\n",
        " \"they'll've\": 'they will have',\n",
        " \"they're\": 'they are',\n",
        " \"they've\": 'they have',         \n",
        " \"to've\": 'to have',\n",
        " \"wasn't\": 'was not',\n",
        " \"\\'we'd\": 'we would',\n",
        " \"\\'we'd've\": 'we would have',\n",
        " \"\\'we'll\": 'we will',\n",
        " \"\\'we'll've\": 'we will have',\n",
        " \"\\'we're\": 'we are',\n",
        " \"\\'we've\": 'we have',\n",
        " \"we'd\": 'we would',\n",
        " \"we'd've\": 'we would have',\n",
        " \"we'll\": 'we will',\n",
        " \"we'll've\": 'we will have',\n",
        " \"we're\": 'we are',\n",
        " \"we've\": 'we have',\n",
        " \"weren't\": 'were not',\n",
        " \"\\'what'll\": 'what will',\n",
        " \"\\'what'll've\": 'what will have',\n",
        " \"\\'what're\": 'what are',\n",
        " \"\\'what's\": 'what is',\n",
        " \"\\'what've\": 'what have',\n",
        " \"\\'when's\": 'when is',\n",
        " \"\\'when've\": 'when have',\n",
        " \"\\'where'd\": 'where did',\n",
        " \"\\'where's\": 'where is',\n",
        " \"\\'where've\": 'where have',\n",
        " \"\\'who'll\": 'who will',\n",
        " \"\\'who'll've\": 'who will have',\n",
        " \"\\'who's\": 'who is',\n",
        " \"\\'who've\": 'who have',\n",
        " \"\\'why's\": 'why is',\n",
        " \"\\'why've\": 'why have',\n",
        " \"\\'will've\": 'will have',\n",
        " \"\\'won't\": 'will not',\n",
        " \"\\'won't've\": 'will not have',\n",
        " \"\\'would've\": 'would have',\n",
        " \"\\'wouldn't\": 'would not',\n",
        " \"\\'wouldn't've\": 'would not have',\n",
        " \"what'll\": 'what will',\n",
        " \"what'll've\": 'what will have',\n",
        " \"what're\": 'what are',\n",
        " \"what's\": 'what is',\n",
        " \"what've\": 'what have',\n",
        " \"when's\": 'when is',\n",
        " \"when've\": 'when have',\n",
        " \"where'd\": 'where did',\n",
        " \"where's\": 'where is',\n",
        " \"where've\": 'where have',\n",
        " \"who'll\": 'who will',\n",
        " \"who'll've\": 'who will have',\n",
        " \"who's\": 'who is',\n",
        " \"who've\": 'who have',\n",
        " \"why's\": 'why is',\n",
        " \"why've\": 'why have',\n",
        " \"will've\": 'will have',\n",
        " \"won't\": 'will not',\n",
        " \"won't've\": 'will not have',\n",
        " \"would've\": 'would have',\n",
        " \"wouldn't\": 'would not',\n",
        " \"wouldn't've\": 'would not have',\n",
        " \"y'all\": 'you all',\n",
        " \"y'all'd\": 'you all would',\n",
        " \"y'all'd've\": 'you all would have',\n",
        " \"y'all're\": 'you all are',\n",
        " \"y'all've\": 'you all have',\n",
        " \"\\'you'd\": 'you would',\n",
        " \"\\'you'd've\": 'you would have',\n",
        " \"\\'you'll\": 'you will',\n",
        " \"\\'you'll've\": 'you shall have',\n",
        " \"\\'you're\": 'you are',\n",
        " \"\\'you've\": 'you have',\n",
        " \"you'd\": 'you would',\n",
        " \"you'd've\": 'you would have',\n",
        " \"you'll\": 'you will',\n",
        " \"you'll've\": 'you shall have',\n",
        " \"you're\": 'you are',\n",
        " \"you've\": 'you have',\n",
        " 'jan.': 'january',\n",
        " 'feb.': 'february',\n",
        " 'mar.': 'march',\n",
        " 'apr.': 'april',\n",
        " 'jun.': 'june',\n",
        " 'jul.': 'july',\n",
        " 'aug.': 'august',\n",
        " 'sep.': 'september',\n",
        " 'oct.': 'october',\n",
        " 'nov.': 'november',\n",
        " 'dec.': 'december',\n",
        " 'ain’t': 'are not',\n",
        " 'aren’t': 'are not',\n",
        " 'can’t': 'can not',\n",
        " 'can’t’ve': 'can not have',\n",
        " '’cause': 'because',\n",
        " 'could’ve': 'could have',\n",
        " 'couldn’t': 'could not',\n",
        " 'couldn’t’ve': 'could not have',\n",
        " 'didn’t': 'did not',\n",
        " 'doesn’t': 'does not',\n",
        " 'don’t': 'do not',\n",
        " 'hadn’t': 'had not',\n",
        " 'hadn’t’ve': 'had not have',\n",
        " 'hasn’t': 'has not',\n",
        " 'haven’t': 'have not',\n",
        " '\\'he’d': 'he would',\n",
        " '\\'he’d’ve': 'he would have',\n",
        " '\\'he’ll': 'he will',\n",
        " '\\'he’ll’ve': 'he will have',\n",
        " '\\'he’s': 'he is',\n",
        " '\\'how’d': 'how did',\n",
        " '\\'how’re': 'how are',\n",
        " '\\'how’d’y': 'how do you',\n",
        " '\\'how’ll': 'how will',\n",
        " '\\'how’s': 'how is',\n",
        " '\\'I’d': 'I would',\n",
        " '\\'I’d’ve': 'I would have',\n",
        " '\\'I’ll': 'I will',\n",
        " '\\'I’ll’ve': 'I will have',\n",
        " '\\'I’m': 'I am',\n",
        " '\\'I’ve': 'I have',\n",
        " '\\'isn’t': 'is not',\n",
        " '\\'it’d': 'it would',\n",
        " '\\'it’d’ve': 'it would have',\n",
        " '\\'it’ll': 'it will',\n",
        " '\\'it’ll’ve': 'it will have',\n",
        " '\\'it’s': 'it is',\n",
        " '\\'let’s': 'let us',  \n",
        " 'he’d': 'he would',\n",
        " 'he’d’ve': 'he would have',\n",
        " 'she’ll': 'he will',\n",
        " 'he’ll’ve': 'he will have',\n",
        " 'odin’s' : 'odin is',\n",
        " 'joe’s' : 'joe is',\n",
        " 'dora’s' : 'dora is',\n",
        " 'wickfield’s' : 'wickfield is',\n",
        " 'tellson’s' : 'tellson is',\n",
        " 'omer’s' :  'omer is',\n",
        " 'cruncher’s' : 'crucher is', \n",
        " 'pip’s' : 'pip is',\n",
        " 'creakle’s ': 'creakle is',\n",
        " 'jorkins’s ' : 'jorkins is',\n",
        " 'jane’s' : 'jane is',\n",
        " 'elliot’s' : 'elliot is',\n",
        " 'anne’s' : 'anne is',\n",
        " 'tilney’s' : 'tilney is',\n",
        " 'lizzy’s' : 'lizzy is',\n",
        " 'smith’s' : 'smith is',\n",
        " 'walter’s' : 'walter is',\n",
        " 'musgrove’s' : 'musgrove is',\n",
        " 'lucy’s' : 'lucy is',\n",
        " 'nigel’s' : 'nigel is',\n",
        " 'nay’s' : 'nay is',\n",
        " 'chodinger’s' : 'chodinger is',\n",
        " 'humphrey’s' : 'humphrey is',\n",
        " 'jack’s' : 'jack is',\n",
        " 'arthur’s': 'arthur is',\n",
        " 'lana’s': 'lana is',\n",
        " 'sarah’s': 'sarah is',\n",
        " 'garcia’s' : 'garcia is',\n",
        " 'ivan’s' : 'ivan is',\n",
        " 'zossimov’s' : 'zossimov is',\n",
        " 'totski’s' : 'totski is',\n",
        " 'miusov’s' : 'miusov is',\n",
        " 'rodya’s' : 'rodya is',\n",
        " 'odin’s' : 'odin is',\n",
        " 'maman’s' : 'maman is',\n",
        " 'thee’s' : 'thee is',\n",
        " 'ye’s' : 'ye is',\n",
        " 'richard’s' : 'richard is',\n",
        " 'silas’s' : 'silas is',\n",
        " 'von’s': 'von is',\n",
        " 'lanyon’s' : 'lanyon is',\n",
        " 'jack’s' : 'jack is',\n",
        " 'gunn’s' : 'gumn is',\n",
        " 'nay’s' : 'nay is',  \n",
        " 'rankeillor’s': 'rankeillor is',      \n",
        " 'odin\\'s' : 'odin is',\n",
        " 'joe\\'s' : 'joe is',\n",
        " 'dora\\'s' : 'dora is',\n",
        " 'wickfield\\'s' : 'wickfield is',\n",
        " 'tellson\\'s' : 'tellson is',\n",
        " 'omer\\'s' :  'omer is',\n",
        " 'cruncher\\'s' : 'crucher is', \n",
        " 'pip\\'s' : 'pip is',\n",
        " 'creakle\\'s ': 'creakle is',\n",
        " 'jorkins\\'s ' : 'jorkins is',\n",
        " 'jane\\'s' : 'jane is',\n",
        " 'elliot\\'s' : 'elliot is',\n",
        " 'anne\\'s' : 'anne is',\n",
        " 'tilney\\'s' : 'tilney is',\n",
        " 'lizzy\\'s' : 'lizzy is',\n",
        " 'smith\\'s' : 'smith is',\n",
        " 'walter\\'s' : 'walter is',\n",
        " 'musgrove\\'s' : 'musgrove is',\n",
        " 'lucy\\'s' : 'lucy is',\n",
        " 'nigel\\'s' : 'nigel is',\n",
        " 'nay\\'s' : 'nay is',\n",
        " 'chodinger\\'s' : 'chodinger is',\n",
        " 'humphrey\\'s' : 'humphrey is',\n",
        " 'jack\\'s' : 'jack is',\n",
        " 'arthur\\'s': 'arthur is',\n",
        " 'lana\\'s': 'lana is',\n",
        " 'sarah\\'s': 'sarah is',\n",
        " 'garcia\\'s' : 'garcia is',\n",
        " 'ivan\\'s' : 'ivan is',\n",
        " 'zossimov\\'s' : 'zossimov is',\n",
        " 'totski\\'s' : 'totski is',\n",
        " 'miusov\\'s' : 'miusov is',\n",
        " 'rodya\\'s' : 'rodya is',\n",
        " 'odin\\'s' : 'odin is',\n",
        " 'maman\\'s' : 'maman is',\n",
        " 'thee\\'s' : 'thee is',\n",
        " 'ye\\'s' : 'ye is',\n",
        " 'richard\\'s' : 'richard is',\n",
        " 'silas\\'s' : 'silas is',\n",
        " 'von\\'s': 'von is',\n",
        " 'lanyon\\'s' : 'lanyon is',\n",
        " 'jack\\'s' : 'jack is',\n",
        " 'gunn\\'s' : 'gumn is',\n",
        " 'nay\\'s' : 'nay is',  \n",
        " 'rankeillor\\'s': 'rankeillor is',          \n",
        " '\\'odin\\'s' : 'odin is',\n",
        " '\\'joe\\'s' : 'joe is',\n",
        " '\\'dora\\'s' : 'dora is',\n",
        " '\\'wickfield\\'s' : 'wickfield is',\n",
        " '\\'tellson\\'s' : 'tellson is',\n",
        " '\\'omer\\'s' :  'omer is',\n",
        " '\\'cruncher\\'s' : 'crucher is', \n",
        " '\\'pip\\'s' : 'pip is',\n",
        " '\\'creakle\\'s ': 'creakle is',\n",
        " '\\'jorkins\\'s ' : 'jorkins is',\n",
        " '\\'jane\\'s' : 'jane is',\n",
        " '\\'elliot\\'s' : 'elliot is',\n",
        " '\\'anne\\'s' : 'anne is',\n",
        " '\\'tilney\\'s' : 'tilney is',\n",
        " '\\'lizzy\\'s' : 'lizzy is',\n",
        " '\\'smith\\'s' : 'smith is',\n",
        " '\\'walter\\'s' : 'walter is',\n",
        " '\\'musgrove\\'s' : 'musgrove is',\n",
        " '\\'lucy\\'s' : 'lucy is',\n",
        " '\\'nigel\\'s' : 'nigel is',\n",
        " '\\'nay\\'s' : 'nay is',\n",
        " '\\'chodinger\\'s' : 'chodinger is',\n",
        " '\\'humphrey\\'s' : 'humphrey is',\n",
        " '\\'jack\\'s' : 'jack is',\n",
        " '\\'arthur\\'s': 'arthur is',\n",
        " '\\'lana\\'s': 'lana is',\n",
        " '\\'sarah\\'s': 'sarah is',\n",
        " '\\'garcia\\'s' : 'garcia is',\n",
        " '\\'ivan\\'s' : 'ivan is',\n",
        " '\\'zossimov\\'s' : 'zossimov is',\n",
        " '\\'totski\\'s' : 'totski is',\n",
        " '\\'miusov\\'s' : 'miusov is',\n",
        " '\\'rodya\\'s' : 'rodya is',\n",
        " '\\'odin\\'s' : 'odin is',\n",
        " '\\'maman\\'s' : 'maman is',\n",
        " '\\'thee\\'s' : 'thee is',\n",
        " '\\'ye\\'s' : 'ye is',\n",
        " '\\'richard\\'s' : 'richard is',\n",
        " '\\'silas\\'s' : 'silas is',\n",
        " '\\'von\\'s': 'von is',\n",
        " '\\'lanyon\\'s' : 'lanyon is',\n",
        " '\\'jack\\'s' : 'jack is',\n",
        " '\\'gunn\\'s' : 'gumn is',\n",
        " '\\'nay\\'s' : 'nay is',  \n",
        " '\\'rankeillor\\'s': 'rankeillor is',        \n",
        " 'he’s': 'he is',\n",
        " 'how’d': 'how did',\n",
        " 'how’re': 'how are',\n",
        " 'how’d’y': 'how do you',\n",
        " 'how’ll': 'how will',\n",
        " 'how’s': 'how is',\n",
        " 'I’d': 'I would',\n",
        " 'I’d’ve': 'I would have',\n",
        " 'I’ll': 'I will',\n",
        " 'I’ll’ve': 'I will have',\n",
        " 'I’m': 'I am',\n",
        " 'I’ve': 'I have',\n",
        " 'isn’t': 'is not',\n",
        " 'it’d': 'it would',\n",
        " 'it’d’ve': 'it would have',\n",
        " 'it’ll': 'it will',\n",
        " 'it’ll’ve': 'it will have',\n",
        " 'it’s': 'it is',\n",
        " 'let’s': 'let us',          \n",
        " 'ma’am': 'madam',\n",
        " 'mayn’t': 'may not',\n",
        " 'might’ve': 'might have',\n",
        " 'mightn’t': 'might not',\n",
        " 'mightn’t’ve': 'might not have',\n",
        " 'must’ve': 'must have',\n",
        " 'mustn’t': 'must not',\n",
        " 'mustn’t’ve': 'must not have',\n",
        " 'needn’t': 'need not',\n",
        " 'needn’t’ve': 'need not have',\n",
        " 'o’clock': 'of the clock',\n",
        " 'oughtn’t': 'ought not',\n",
        " 'oughtn’t’ve': 'ought not have',\n",
        " 'shan’t': 'shall not',\n",
        " 'sha’n’t': 'shall not',\n",
        " 'shan’t’ve': 'shall not have',\n",
        " '\\'she’d': 'she would',\n",
        " '\\'she’d’ve': 'she would have',\n",
        " '\\'she’ll': 'she will',\n",
        " '\\'she’ll’ve': 'she will have',\n",
        " '\\'she’s': 'she is',\n",
        " '\\'should’ve': 'should have',\n",
        " '\\'shouldn’t': 'should not',\n",
        " '\\'shouldn’t’ve': 'should not have',\n",
        " '\\'so’ve': 'so have',\n",
        " '\\'so’s': 'so is',\n",
        " '\\'that’d': 'that would',\n",
        " '\\'that’d’ve': 'that would have',\n",
        " '\\'that’s': 'that is',\n",
        " '\\'there’d': 'there would',\n",
        " '\\'there’d’ve': 'there would have',\n",
        " '\\'there’s': 'there is',\n",
        " '\\'they’d': 'they would',\n",
        " '\\'they’d’ve': 'they would have',\n",
        " '\\'they’ll': 'they will',\n",
        " '\\'they’ll’ve': 'they will have',\n",
        " '\\'they’re': 'they are',\n",
        " '\\'they’ve': 'they have',\n",
        " 'she’d': 'she would',\n",
        " 'she’d’ve': 'she would have',\n",
        " 'she’ll': 'she will',\n",
        " 'she’ll’ve': 'she will have',\n",
        " 'she’s': 'she is',\n",
        " 'should’ve': 'should have',\n",
        " 'shouldn’t': 'should not',\n",
        " 'shouldn’t’ve': 'should not have',\n",
        " 'so’ve': 'so have',\n",
        " 'so’s': 'so is',\n",
        " 'that’d': 'that would',\n",
        " 'that’d’ve': 'that would have',\n",
        " 'that’s': 'that is',\n",
        " 'there’d': 'there would',\n",
        " 'there’d’ve': 'there would have',\n",
        " 'there’s': 'there is',\n",
        " 'they’d': 'they would',\n",
        " 'they’d’ve': 'they would have',\n",
        " 'they’ll': 'they will',\n",
        " 'they’ll’ve': 'they will have',\n",
        " 'they’re': 'they are',\n",
        " 'they’ve': 'they have',      \n",
        " 'to’ve': 'to have',\n",
        " 'wasn’t': 'was not',\n",
        " '\\'we’d': 'we would',\n",
        " '\\'we’d’ve': 'we would have',\n",
        " '\\'we’ll': 'we will',\n",
        " '\\'we’ll’ve': 'we will have',\n",
        " '\\'we’re': 'we are',\n",
        " '\\'we’ve': 'we have',\n",
        " 'we’d': 'we would',\n",
        " 'we’d’ve': 'we would have',\n",
        " 'we’ll': 'we will',\n",
        " 'we’ll’ve': 'we will have',\n",
        " 'we’re': 'we are',\n",
        " 'we’ve': 'we have',          \n",
        " 'weren’t': 'were not',\n",
        " '\\'what’ll': 'what will',\n",
        " '\\'what’ll’ve': 'what will have',\n",
        " '\\'what’re': 'what are',\n",
        " '\\'what’s': 'what is',\n",
        " '\\'what’ve': 'what have',\n",
        " '\\'when’s': 'when is',\n",
        " '\\'when’ve': 'when have',\n",
        " '\\'where’d': 'where did',\n",
        " '\\'where’s': 'where is',\n",
        " '\\'where’ve': 'where have',\n",
        " '\\'who’ll': 'who will',\n",
        " '\\'who’ll’ve': 'who will have',\n",
        " '\\'who’s': 'who is',\n",
        " '\\'who’ve': 'who have',\n",
        " '\\'why’s': 'why is',\n",
        " '\\'why’ve': 'why have',\n",
        " '\\'will’ve': 'will have',\n",
        " '\\'won’t': 'will not',\n",
        " '\\'won’t’ve': 'will not have',\n",
        " '\\'would’ve': 'would have',\n",
        " '\\'wouldn’t': 'would not',\n",
        " '\\'wouldn’t’ve': 'would not have',\n",
        " 'what’ll': 'what will',\n",
        " 'what’ll’ve': 'what will have',\n",
        " 'what’re': 'what are',\n",
        " 'what’s': 'what is',\n",
        " 'what’ve': 'what have',\n",
        " 'when’s': 'when is',\n",
        " 'when’ve': 'when have',\n",
        " 'where’d': 'where did',\n",
        " 'where’s': 'where is',\n",
        " 'where’ve': 'where have',\n",
        " 'who’ll': 'who will',\n",
        " 'who’ll’ve': 'who will have',\n",
        " 'who’s': 'who is',\n",
        " 'who’ve': 'who have',\n",
        " 'why’s': 'why is',\n",
        " 'why’ve': 'why have',\n",
        " 'will’ve': 'will have',\n",
        " 'won’t': 'will not',\n",
        " 'won’t’ve': 'will not have',\n",
        " 'would’ve': 'would have',\n",
        " 'wouldn’t': 'would not',\n",
        " 'wouldn’t’ve': 'would not have',   \n",
        " 'y’all': 'you all',\n",
        " 'y’all’d': 'you all would',\n",
        " 'y’all’d’ve': 'you all would have',\n",
        " 'y’all’re': 'you all are',\n",
        " 'y’all’ve': 'you all have',\n",
        " '\\'you’d': 'you would',\n",
        " '\\'you’d’ve': 'you would have',\n",
        " '\\'you’ll': 'you will',\n",
        " '\\'you’ll’ve': 'you shall have',\n",
        " '\\'you’re': 'you are',\n",
        " '\\'you’ve': 'you have', \n",
        " 'you’d': 'you would',\n",
        " 'you’d’ve': 'you would have',\n",
        " 'you’ll': 'you will',\n",
        " 'you’ll’ve': 'you shall have',\n",
        " 'you’re': 'you are',\n",
        " 'you’ve': 'you have'\n",
        "}"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC7QQ-cxEk_O"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "def clean_contraction(text):\n",
        "    words = text_to_word_sequence(text)\n",
        "    words=[cont_dict[word] if word in cont_dict else word for word in words]\n",
        "    clean_sent=\" \".join(words)\n",
        "    \n",
        "    return clean_sent\n",
        "\n",
        "train['text'] = train['text'].str.lower().apply(clean_contraction)\n",
        "test['text'] = test['text'].str.lower().apply(clean_contraction)"
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "ftYgdER5U2t-",
        "outputId": "76cdba70-f04f-41d9-d0d8-0691d96e13c3"
      },
      "source": [
        "train[train['text'].str.contains(\"he is\")]"
      ],
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>my dearest odin continued the other without at...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>the news is of him he is among us exclmark</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>she is still the same of course exclmark yes t...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>'and consider ma'am' said odin as the tears fo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>do you mean it quesmark and can it be so quesm...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54734</th>\n",
              "      <td>he is the boy for you my dear' replied the jew...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54768</th>\n",
              "      <td>the question came so suddenly that it was well...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54774</th>\n",
              "      <td>you say he is a faddist what is his particular...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54839</th>\n",
              "      <td>it is unfortunately more than possible it is c...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54851</th>\n",
              "      <td>'he can not live a week the doctor says' pursu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1877 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "53     my dearest odin continued the other without at...       1\n",
              "56            the news is of him he is among us exclmark       0\n",
              "62     she is still the same of course exclmark yes t...       3\n",
              "70     'and consider ma'am' said odin as the tears fo...       0\n",
              "78     do you mean it quesmark and can it be so quesm...       3\n",
              "...                                                  ...     ...\n",
              "54734  he is the boy for you my dear' replied the jew...       0\n",
              "54768  the question came so suddenly that it was well...       2\n",
              "54774  you say he is a faddist what is his particular...       2\n",
              "54839  it is unfortunately more than possible it is c...       2\n",
              "54851  'he can not live a week the doctor says' pursu...       0\n",
              "\n",
              "[1877 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5pZS5f3Eutp"
      },
      "source": [
        "train['text']=train['text'].str.replace('\\'s', '')\n",
        "train['text']=train['text'].str.replace('’s', '')\n",
        "train['text']=train['text'].str.replace(\"\\'\", '')\n",
        "train['text']=train['text'].str.replace(\"’\", '')\n",
        "test['text']=test['text'].str.replace(\"’s\",'')\n",
        "test['text']=test['text'].str.replace(\"\\''\",'')\n",
        "test['text']=test['text'].str.replace(\"\\'\", '')\n",
        "test['text']=test['text'].str.replace(\"’\", '')"
      ],
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsHMfHJbmwPZ",
        "outputId": "4686a173-c1d0-4a0b-e424-0003e4ffa38f"
      },
      "source": [
        "train.iloc[69]"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      you are not the gaoler daughter quesmark\n",
              "author                                           0\n",
              "Name: 69, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcwHqACeQYLW"
      },
      "source": [
        "train['text']=train['text'].str.replace('á', '')\n",
        "train['text']=train['text'].str.replace('ä', '')\n",
        "train['text']=train['text'].str.replace('é', '')\n",
        "train['text']=train['text'].str.replace('í', '')\n",
        "train['text']=train['text'].str.replace('ó', '')\n",
        "train['text']=train['text'].str.replace('ú', '')\n",
        "train['text']=train['text'].str.replace('ý', '')\n",
        "train['text']=train['text'].str.replace('ü', ' Umlaut ')\n",
        "\n",
        "test['text']=test['text'].str.replace('ä', '')\n",
        "test['text']=test['text'].str.replace('á', '')\n",
        "test['text']=test['text'].str.replace('é', '')\n",
        "test['text']=test['text'].str.replace('í', '')\n",
        "test['text']=test['text'].str.replace('ó', '')\n",
        "test['text']=test['text'].str.replace('ú', '')\n",
        "test['text']=test['text'].str.replace('ý', '')\n",
        "test['text']=test['text'].str.replace('ü', '')"
      ],
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOTdyzc7E9Nm"
      },
      "source": [
        "def alpha_num(text):\n",
        "    return re.sub(r'[0-9]', ' num ', text)\n",
        "\n",
        "def remove_word(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in del_word:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "\n",
        "\n",
        "del_word = ['the', 'and' , 'to' , 'of' , 'a', 'was', 'in' , \"about\", \"above\", \"after\", \"again\", \"against\", \"all\",\"out\", \n",
        "            \"over\", \"own\", \"same\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"for\", \"further\" ,\"between\", \n",
        "            \"might\",\"odin\", \"said\", \"one\", \"i\", \"man\", \"know\", \"see\", \"take\", \"come\", \"get\", \"nothing\" , \"something\",\n",
        "            \"think\", \"find\", \"that\", \"was\", \"are\", \"yourself\", \"himself\" , \"myself\"]\n",
        "\n",
        "train['text'] = train['text'].str.lower().apply(alpha_num).apply(remove_word)\n",
        "test['text'] = test['text'].str.lower().apply(alpha_num).apply(remove_word)"
      ],
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "5k8hQhaJiQ9s",
        "outputId": "a4eaed0f-d66e-4c24-cd5c-ffcbc4211359"
      },
      "source": [
        "train[train['text'].str.contains(\"num\")]"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>‘anybody supplying any information whereabouts...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>thus day followed day as sure as morning came ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>it went down at an acute angle some fifty feet...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>moved lamp we both bent sheet paper which show...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>crossed corner found dirty dark staircase hear...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54381</th>\n",
              "      <td>now word as my household mr wish you thoroughl...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54481</th>\n",
              "      <td>‘dear miss hunter—miss stoper has very kindly ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54591</th>\n",
              "      <td>then name lodge num num num welcome you its pr...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54645</th>\n",
              "      <td>when my brother left us yesterday he imagined ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54695</th>\n",
              "      <td>mr bland accompanied by inspector senior detec...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>653 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "29     ‘anybody supplying any information whereabouts...       2\n",
              "32     thus day followed day as sure as morning came ...       1\n",
              "229    it went down at an acute angle some fifty feet...       2\n",
              "250    moved lamp we both bent sheet paper which show...       2\n",
              "445    crossed corner found dirty dark staircase hear...       3\n",
              "...                                                  ...     ...\n",
              "54381  now word as my household mr wish you thoroughl...       2\n",
              "54481  ‘dear miss hunter—miss stoper has very kindly ...       2\n",
              "54591  then name lodge num num num welcome you its pr...       2\n",
              "54645  when my brother left us yesterday he imagined ...       1\n",
              "54695  mr bland accompanied by inspector senior detec...       2\n",
              "\n",
              "[653 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lwZOsZ6FIhR"
      },
      "source": [
        "vocab_size = 20000\n",
        "maxlen = 230\n",
        "embed_dim = 128\n",
        "num_heads = 4  # Number of attention heads\n",
        "padding_type='post'"
      ],
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8lvoASmFLTy"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlghouxPFMZ2"
      },
      "source": [
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-ZXhHb4FNnm",
        "outputId": "56a0501e-d4bd-4636-8289-432dea869cc9"
      },
      "source": [
        "trn = keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=maxlen)\n",
        "tst = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=maxlen)\n",
        "print(trn.shape, tst.shape)"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879, 230) (19617, 230)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW_LeJ4lFO2y"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
      ],
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-dQeTDQFQ-x"
      },
      "source": [
        "def get_model():\n",
        "    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "    inputs = layers.Input(shape=(maxlen,))\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "    x = transformer_block(x)\n",
        "    x = transformer_block(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.Dense(20, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    outputs = layers.Dense(n_class, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=.001))\n",
        "    return model"
      ],
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDHSxUrzFSSR",
        "outputId": "5b72c4ac-e78f-45ca-d552-8d27752e04f5"
      },
      "source": [
        "p_val = np.zeros((trn.shape[0], n_class))\n",
        "p_tst = np.zeros((tst.shape[0], n_class))\n",
        "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
        "    print(f'training model for CV #{i}')\n",
        "    clf = get_model()\n",
        "    \n",
        "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
        "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "    clf.fit(trn[i_trn], \n",
        "            to_categorical(y[i_trn]),\n",
        "            validation_data=(trn[i_val], to_categorical(y[i_val])),\n",
        "            epochs=10,\n",
        "            batch_size=128,\n",
        "            callbacks=[es])\n",
        "    p_val[i_val, :] = clf.predict(trn[i_val])\n",
        "    p_tst += clf.predict(tst) / n_fold\n",
        "    \n",
        "    clear_session()\n",
        "    gc.collect()\n"
      ],
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model for CV #1\n",
            "Epoch 1/10\n",
            "343/343 [==============================] - 53s 155ms/step - loss: 1.2089 - val_loss: 0.7870\n",
            "Epoch 2/10\n",
            "343/343 [==============================] - 54s 156ms/step - loss: 0.6387 - val_loss: 0.6853\n",
            "Epoch 3/10\n",
            "343/343 [==============================] - 53s 155ms/step - loss: 0.4205 - val_loss: 0.7554\n",
            "Epoch 4/10\n",
            "343/343 [==============================] - 53s 155ms/step - loss: 0.3107 - val_loss: 0.8046\n",
            "Epoch 5/10\n",
            "343/343 [==============================] - ETA: 0s - loss: 0.2442Restoring model weights from the end of the best epoch.\n",
            "343/343 [==============================] - 53s 155ms/step - loss: 0.2442 - val_loss: 0.8864\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #2\n",
            "Epoch 1/10\n",
            "343/343 [==============================] - 53s 156ms/step - loss: 1.1698 - val_loss: 0.7878\n",
            "Epoch 2/10\n",
            "343/343 [==============================] - 53s 154ms/step - loss: 0.6355 - val_loss: 0.6854\n",
            "Epoch 3/10\n",
            "343/343 [==============================] - 53s 154ms/step - loss: 0.4197 - val_loss: 0.7269\n",
            "Epoch 4/10\n",
            "343/343 [==============================] - 53s 155ms/step - loss: 0.3114 - val_loss: 0.8692\n",
            "Epoch 5/10\n",
            "343/343 [==============================] - ETA: 0s - loss: 0.2389Restoring model weights from the end of the best epoch.\n",
            "343/343 [==============================] - 53s 155ms/step - loss: 0.2389 - val_loss: 0.9267\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #3\n",
            "Epoch 1/10\n",
            "343/343 [==============================] - 53s 155ms/step - loss: 1.2332 - val_loss: 0.8103\n",
            "Epoch 2/10\n",
            "343/343 [==============================] - 53s 153ms/step - loss: 0.6620 - val_loss: 0.6815\n",
            "Epoch 3/10\n",
            "343/343 [==============================] - 53s 155ms/step - loss: 0.4354 - val_loss: 0.7215\n",
            "Epoch 4/10\n",
            "343/343 [==============================] - 53s 154ms/step - loss: 0.3238 - val_loss: 0.8369\n",
            "Epoch 5/10\n",
            "343/343 [==============================] - ETA: 0s - loss: 0.2456Restoring model weights from the end of the best epoch.\n",
            "343/343 [==============================] - 53s 154ms/step - loss: 0.2456 - val_loss: 0.9005\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #4\n",
            "Epoch 1/10\n",
            "343/343 [==============================] - 53s 156ms/step - loss: 1.2281 - val_loss: 0.8917\n",
            "Epoch 2/10\n",
            "343/343 [==============================] - 52s 153ms/step - loss: 0.6682 - val_loss: 0.6859\n",
            "Epoch 3/10\n",
            "343/343 [==============================] - 53s 154ms/step - loss: 0.4402 - val_loss: 0.7510\n",
            "Epoch 4/10\n",
            "343/343 [==============================] - 53s 154ms/step - loss: 0.3243 - val_loss: 0.9176\n",
            "Epoch 5/10\n",
            "343/343 [==============================] - ETA: 0s - loss: 0.2568Restoring model weights from the end of the best epoch.\n",
            "343/343 [==============================] - 53s 155ms/step - loss: 0.2568 - val_loss: 0.9382\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #5\n",
            "Epoch 1/10\n",
            "343/343 [==============================] - 51s 150ms/step - loss: 1.2048 - val_loss: 0.8021\n",
            "Epoch 2/10\n",
            "343/343 [==============================] - 50s 146ms/step - loss: 0.6669 - val_loss: 0.6836\n",
            "Epoch 3/10\n",
            "343/343 [==============================] - 50s 147ms/step - loss: 0.4379 - val_loss: 0.7715\n",
            "Epoch 4/10\n",
            "343/343 [==============================] - 50s 147ms/step - loss: 0.3159 - val_loss: 0.8133\n",
            "Epoch 5/10\n",
            "343/343 [==============================] - ETA: 0s - loss: 0.2418Restoring model weights from the end of the best epoch.\n",
            "343/343 [==============================] - 50s 147ms/step - loss: 0.2418 - val_loss: 1.0052\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OOmE9QfFTqA",
        "outputId": "9f20830c-7b83-43a3-e8dc-546a8b2b2e2e"
      },
      "source": [
        "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n",
        "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"
      ],
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy (CV):  75.0178%\n",
            "Log Loss (CV):   0.6843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMQUgYQyKi3f"
      },
      "source": [
        "#     max_length        vocab_size                accuracy              등수\n",
        "       \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMYR94SJH3Bm"
      },
      "source": [
        "\n",
        "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
        "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "-MgO00YBH68K",
        "outputId": "12ec2d59-c7e0-4955-c303-a21f445655bd"
      },
      "source": [
        "sub = pd.read_csv(sample_file, index_col=0)\n",
        "print(sub.shape)\n",
        "sub.head()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19617, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  1  2  3  4\n",
              "index               \n",
              "0      0  0  0  0  0\n",
              "1      0  0  0  0  0\n",
              "2      0  0  0  0  0\n",
              "3      0  0  0  0  0\n",
              "4      0  0  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "v_3lQZktH8fy",
        "outputId": "21b965d9-761c-4fbf-dd0b-e618096392d8"
      },
      "source": [
        "sub[sub.columns] = p_tst\n",
        "sub.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0673</td>\n",
              "      <td>0.2147</td>\n",
              "      <td>0.5294</td>\n",
              "      <td>0.1841</td>\n",
              "      <td>0.0044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.3407</td>\n",
              "      <td>0.5239</td>\n",
              "      <td>0.0697</td>\n",
              "      <td>0.0331</td>\n",
              "      <td>0.0326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9638</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0430</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.7701</td>\n",
              "      <td>0.0134</td>\n",
              "      <td>0.1691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6288</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0520</td>\n",
              "      <td>0.2565</td>\n",
              "      <td>0.0432</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0       1       2       3       4\n",
              "index                                        \n",
              "0      0.0673  0.2147  0.5294  0.1841  0.0044\n",
              "1      0.3407  0.5239  0.0697  0.0331  0.0326\n",
              "2      0.9638  0.0207  0.0039  0.0012  0.0103\n",
              "3      0.0430  0.0044  0.7701  0.0134  0.1691\n",
              "4      0.6288  0.0195  0.0520  0.2565  0.0432"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIah69A_H-B1"
      },
      "source": [
        "sub.to_csv(sub_file)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGQy7iItH_MC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}