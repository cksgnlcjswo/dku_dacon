{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNF92ZSpDaTY"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XU_tg0lDpdZ"
      },
      "source": [
        "\n",
        "import gc\n",
        "from matplotlib import rcParams, pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings \n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2EIiJ3oDr3e"
      },
      "source": [
        "rcParams['figure.figsize'] = (16, 8)\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('max_columns', 100)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNm1lVphDtJ_"
      },
      "source": [
        "data_dir = Path('/content/drive/MyDrive/dacon/input/')\n",
        "feature_dir = Path('../build/feature')\n",
        "val_dir = Path('/content/drive/MyDrive/dacon/build/val')\n",
        "tst_dir = Path('/content/drive/MyDrive/dacon/build/tst')\n",
        "sub_dir = Path('/content/drive/MyDrive/dacon/build/sub')\n",
        "\n",
        "trn_file = data_dir / 'train.csv'\n",
        "tst_file = data_dir / 'test_x.csv'\n",
        "sample_file = data_dir / 'sample_submission.csv'\n",
        "\n",
        "target_col = 'author'\n",
        "n_fold = 5\n",
        "n_class = 5\n",
        "seed = 42"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bANeR5sRDvRu"
      },
      "source": [
        "algo_name = 'mta'\n",
        "feature_name = 'emb'\n",
        "model_name = f'{algo_name}_{feature_name}'\n",
        "\n",
        "feature_file = feature_dir / f'{feature_name}.csv'\n",
        "p_val_file = val_dir / f'{model_name}.val.csv'\n",
        "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
        "sub_file = sub_dir / f'{model_name}.csv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "VFY3nJFhDw7T",
        "outputId": "85aff5bf-5071-4cc7-db61-c4b6398ba7b1"
      },
      "source": [
        "train = pd.read_csv(trn_file, index_col=0)\n",
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "0      He was almost choking. There was so much, so m...       3\n",
              "1                 “Your sister asked for it, I suppose?”       2\n",
              "2       She was engaged one day as she walked, in per...       1\n",
              "3      The captain was in the porch, keeping himself ...       4\n",
              "4      “Have mercy, gentlemen!” odin flung up his han...       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "eJAoOzzgDyNp",
        "outputId": "9fd7a1ba-6f4d-4774-bbd6-c9b04bf6a01c"
      },
      "source": [
        "test = pd.read_csv(tst_file, index_col=0)\n",
        "test.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Not at all. I think she is one of the most ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As the lady had stated her intention of scream...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“And then suddenly in the silence I heard a so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>His conviction remained unchanged. So far as I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "index                                                   \n",
              "0      “Not at all. I think she is one of the most ch...\n",
              "1      \"No,\" replied he, with sudden consciousness, \"...\n",
              "2      As the lady had stated her intention of scream...\n",
              "3      “And then suddenly in the silence I heard a so...\n",
              "4      His conviction remained unchanged. So far as I..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScCBrsT4EdyQ"
      },
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output\n",
        "    \n",
        "    \n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "    \n",
        "    \n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilp7KFvXEfyG",
        "outputId": "e03cbd0b-2461-4bde-c33b-b2c1c97cbb67"
      },
      "source": [
        "X_train = train['text'].values\n",
        "X_test = test['text'].values\n",
        "y = train['author'].values\n",
        "print(X_train.shape, X_test.shape, y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879,) (19617,) (54879,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "X_k-iC3rk93V",
        "outputId": "e1361b6f-5245-41a8-fb3e-53dc3c4a56d5"
      },
      "source": [
        "train[train['text'].str.contains(\"semicolons\")]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [text, author]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJPespo_Ehmd"
      },
      "source": [
        "#기회갇 되면 &포함시켜서 훈련시켜보기\n",
        "# -은 한단어로 표현된 경우도 있으니 놔두기.\n",
        "import string\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    punc=[]\n",
        "    #punc.append('!')\n",
        "    punc.append('.')\n",
        "    punc.append(':')\n",
        "    punc.append(\",\")\n",
        "    punc.append(';')\n",
        "    punc.append('\\\"')\n",
        "    punc.append('“')\n",
        "    punc.append('”')\n",
        "    punc.append(\"’\")\n",
        "    #punc.append(\"?\")\n",
        "    punc.append(\"{\")\n",
        "    punc.append('[')\n",
        "    punc.append(']')\n",
        "    punc.append(\"}\")\n",
        "    punc.append('(')\n",
        "    punc.append(')')\n",
        "    #punc.append('&')\n",
        "    #punc.append('*')\n",
        "    punc.append('+')\n",
        "    for punctuation in punc:\n",
        "        text = text.replace(punctuation, '')\n",
        "    return text\n",
        "\n",
        "train[\"text\"] = train['text'].str.lower().apply(remove_punctuations)\n",
        "test['text'] = test['text'].str.lower().apply(remove_punctuations)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXqMGispUeim",
        "outputId": "cb54f085-b8f1-436f-c11c-06d99830ce3d"
      },
      "source": [
        "train.iloc[54750]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text       * * * * *\n",
              "author             4\n",
              "Name: 54750, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbju4Lc9nc_z"
      },
      "source": [
        "train['text'] = train['text'].str.replace('\\?',' quesmark ')\n",
        "train['text'] = train['text'].str.replace('\\!',' exclmark ')\n",
        "train['text'] = train['text'].str.replace('\\&',' empent ')\n",
        "train['text'] = train['text'].str.replace(\"\\*\",' chstar ')\n",
        "\n",
        "test['text'] = test['text'].str.replace('\\?',' quesmark ')\n",
        "test['text'] = test['text'].str.replace('\\!',' exclmark ')\n",
        "test['text'] = test['text'].str.replace('\\&',' empent ')\n",
        "test['text'] = test['text'].str.replace(\"\\*\",' chstar ')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "86exTrFooMGW",
        "outputId": "1a2718d7-ce60-42cb-d7f4-facb923cd64e"
      },
      "source": [
        "train[train['text'].str.contains(\"colons\")]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [text, author]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erHdpJ_GEjHW"
      },
      "source": [
        "cont_dict={\"ain't\": 'are not',\n",
        " \"aren't\": 'are not',\n",
        " \"can't\": 'can not',\n",
        " \"can't've\": 'can not have',\n",
        " \"'cause\": 'because',\n",
        " \"could've\": 'could have',\n",
        " \"couldn't\": 'could not',\n",
        " \"couldn't've\": 'could not have',\n",
        " \"didn't\": 'did not',\n",
        " \"doesn't\": 'does not',\n",
        " \"don't\": 'do not',\n",
        " \"hadn't\": 'had not',\n",
        " \"hadn't've\": 'had not have',\n",
        " \"hasn't\": 'has not',\n",
        " \"haven't\": 'have not',\n",
        " \"\\'he'd\": 'he would',\n",
        " \"\\'he'd've\": 'he would have',\n",
        " \"\\'he'll\": 'he will',\n",
        " \"\\'he'll've\": 'he will have',\n",
        " \"\\'he's\": 'he is',\n",
        " \"\\'how'd\": 'how did',\n",
        " \"\\'how're\": 'how are',\n",
        " \"\\'how'd'y\": 'how do you',\n",
        " \"\\'how'll\": 'how will',\n",
        " \"\\'how's\": 'how is',\n",
        " \"\\'I'd\": 'I would',\n",
        " \"\\'I'd've\": 'I would have',\n",
        " \"\\'I'll\": 'I will',\n",
        " \"\\'I'll've\": 'I will have',\n",
        " \"\\'I'm\": 'I am',\n",
        " \"\\'I've\": 'I have',\n",
        " \"\\'he'd\": 'he would',\n",
        " \"he'd've\": 'he would have',\n",
        " \"he'll\": 'he will',\n",
        " \"he'll've\": 'he will have',\n",
        " \"he's\": 'he is',\n",
        " \"how'd\": 'how did',\n",
        " \"how're\": 'how are',\n",
        " \"how'd'y\": 'how do you',\n",
        " \"how'll\": 'how will',\n",
        " \"how's\": 'how is',\n",
        " \"I'd\": 'I would',\n",
        " \"I'd've\": 'I would have',\n",
        " \"I'll\": 'I will',\n",
        " \"I'll've\": 'I will have',\n",
        " \"I'm\": 'I am',\n",
        " \"I've\": 'I have',         \n",
        " \"isn't\": 'is not',\n",
        " \"\\'it'd\": 'it would',\n",
        " \"\\'it'd've\": 'it would have',\n",
        " \"\\'it'll\": 'it will',\n",
        " \"\\'it'll've\": 'it will have',\n",
        " \"\\'it's\": 'it is',\n",
        " \"\\'let's\": 'let us',\n",
        " \"it'd\": 'it would',\n",
        " \"it'd've\": 'it would have',\n",
        " \"it'll\": 'it will',\n",
        " \"it'll've\": 'it will have',\n",
        " \"it's\": 'it is',\n",
        " \"let's\": 'let us',\n",
        " \"ma'am\": 'madam',\n",
        " \"mayn't\": 'may not',\n",
        " \"might've\": 'might have',\n",
        " \"mightn't\": 'might not',\n",
        " \"mightn't've\": 'might not have',\n",
        " \"must've\": 'must have',\n",
        " \"mustn't\": 'must not',\n",
        " \"mustn't've\": 'must not have',\n",
        " \"needn't\": 'need not',\n",
        " \"needn't've\": 'need not have',\n",
        " \"o'clock\": 'of the clock',\n",
        " \"oughtn't\": 'ought not',\n",
        " \"oughtn't've\": 'ought not have',\n",
        " \"\\'shan't\": 'shall not',\n",
        " \"\\'sha'n't\": 'shall not',\n",
        " \"\\'shan't've\": 'shall not have',\n",
        " \"\\'she'd\": 'she would',\n",
        " \"\\'she'd've\": 'she would have',\n",
        " \"\\'she'll\": 'she will',\n",
        " \"\\'she'll've\": 'she will have',\n",
        " \"\\'she's\": 'she is',\n",
        " \"\\'should've\": 'should have',\n",
        " \"\\'shouldn't\": 'should not',\n",
        " \"\\'shouldn't've\": 'should not have',\n",
        " \"shan't\": 'shall not',\n",
        " \"sha'n't\": 'shall not',\n",
        " \"shan't've\": 'shall not have',\n",
        " \"she'd\": 'she would',\n",
        " \"she'd've\": 'she would have',\n",
        " \"she'll\": 'she will',\n",
        " \"she'll've\": 'she will have',\n",
        " \"she's\": 'she is',\n",
        " \"should've\": 'should have',\n",
        " \"shouldn't\": 'should not',\n",
        " \"shouldn't've\": 'should not have',         \n",
        " \"so've\": 'so have',\n",
        " \"so's\": 'so is',\n",
        " \"\\'that'd\": 'that would',\n",
        " \"\\'that'd've\": 'that would have',\n",
        " \"\\'that's\": 'that is',\n",
        " \"\\'there'd\": 'there would',\n",
        " \"\\'there'd've\": 'there would have',\n",
        " \"\\'there's\": 'there is',\n",
        " \"\\'they'd\": 'they would',\n",
        " \"\\'they'd've\": 'they would have',\n",
        " \"\\'they'll\": 'they will',\n",
        " \"\\'they'll've\": 'they will have',\n",
        " \"\\'they're\": 'they are',\n",
        " \"\\'they've\": 'they have',\n",
        " \"that'd\": 'that would',\n",
        " \"that'd've\": 'that would have',\n",
        " \"that's\": 'that is',\n",
        " \"there'd\": 'there would',\n",
        " \"there'd've\": 'there would have',\n",
        " \"there's\": 'there is',\n",
        " \"they'd\": 'they would',\n",
        " \"they'd've\": 'they would have',\n",
        " \"they'll\": 'they will',\n",
        " \"they'll've\": 'they will have',\n",
        " \"they're\": 'they are',\n",
        " \"they've\": 'they have',         \n",
        " \"to've\": 'to have',\n",
        " \"wasn't\": 'was not',\n",
        " \"\\'we'd\": 'we would',\n",
        " \"\\'we'd've\": 'we would have',\n",
        " \"\\'we'll\": 'we will',\n",
        " \"\\'we'll've\": 'we will have',\n",
        " \"\\'we're\": 'we are',\n",
        " \"\\'we've\": 'we have',\n",
        " \"we'd\": 'we would',\n",
        " \"we'd've\": 'we would have',\n",
        " \"we'll\": 'we will',\n",
        " \"we'll've\": 'we will have',\n",
        " \"we're\": 'we are',\n",
        " \"we've\": 'we have',\n",
        " \"weren't\": 'were not',\n",
        " \"\\'what'll\": 'what will',\n",
        " \"\\'what'll've\": 'what will have',\n",
        " \"\\'what're\": 'what are',\n",
        " \"\\'what's\": 'what is',\n",
        " \"\\'what've\": 'what have',\n",
        " \"\\'when's\": 'when is',\n",
        " \"\\'when've\": 'when have',\n",
        " \"\\'where'd\": 'where did',\n",
        " \"\\'where's\": 'where is',\n",
        " \"\\'where've\": 'where have',\n",
        " \"\\'who'll\": 'who will',\n",
        " \"\\'who'll've\": 'who will have',\n",
        " \"\\'who's\": 'who is',\n",
        " \"\\'who've\": 'who have',\n",
        " \"\\'why's\": 'why is',\n",
        " \"\\'why've\": 'why have',\n",
        " \"\\'will've\": 'will have',\n",
        " \"\\'won't\": 'will not',\n",
        " \"\\'won't've\": 'will not have',\n",
        " \"\\'would've\": 'would have',\n",
        " \"\\'wouldn't\": 'would not',\n",
        " \"\\'wouldn't've\": 'would not have',\n",
        " \"what'll\": 'what will',\n",
        " \"what'll've\": 'what will have',\n",
        " \"what're\": 'what are',\n",
        " \"what's\": 'what is',\n",
        " \"what've\": 'what have',\n",
        " \"when's\": 'when is',\n",
        " \"when've\": 'when have',\n",
        " \"where'd\": 'where did',\n",
        " \"where's\": 'where is',\n",
        " \"where've\": 'where have',\n",
        " \"who'll\": 'who will',\n",
        " \"who'll've\": 'who will have',\n",
        " \"who's\": 'who is',\n",
        " \"who've\": 'who have',\n",
        " \"why's\": 'why is',\n",
        " \"why've\": 'why have',\n",
        " \"will've\": 'will have',\n",
        " \"won't\": 'will not',\n",
        " \"won't've\": 'will not have',\n",
        " \"would've\": 'would have',\n",
        " \"wouldn't\": 'would not',\n",
        " \"wouldn't've\": 'would not have',\n",
        " \"y'all\": 'you all',\n",
        " \"y'all'd\": 'you all would',\n",
        " \"y'all'd've\": 'you all would have',\n",
        " \"y'all're\": 'you all are',\n",
        " \"y'all've\": 'you all have',\n",
        " \"\\'you'd\": 'you would',\n",
        " \"\\'you'd've\": 'you would have',\n",
        " \"\\'you'll\": 'you will',\n",
        " \"\\'you'll've\": 'you shall have',\n",
        " \"\\'you're\": 'you are',\n",
        " \"\\'you've\": 'you have',\n",
        " \"you'd\": 'you would',\n",
        " \"you'd've\": 'you would have',\n",
        " \"you'll\": 'you will',\n",
        " \"you'll've\": 'you shall have',\n",
        " \"you're\": 'you are',\n",
        " \"you've\": 'you have',\n",
        " 'jan.': 'january',\n",
        " 'feb.': 'february',\n",
        " 'mar.': 'march',\n",
        " 'apr.': 'april',\n",
        " 'jun.': 'june',\n",
        " 'jul.': 'july',\n",
        " 'aug.': 'august',\n",
        " 'sep.': 'september',\n",
        " 'oct.': 'october',\n",
        " 'nov.': 'november',\n",
        " 'dec.': 'december',\n",
        " 'ain’t': 'are not',\n",
        " 'aren’t': 'are not',\n",
        " 'can’t': 'can not',\n",
        " 'can’t’ve': 'can not have',\n",
        " '’cause': 'because',\n",
        " 'could’ve': 'could have',\n",
        " 'couldn’t': 'could not',\n",
        " 'couldn’t’ve': 'could not have',\n",
        " 'didn’t': 'did not',\n",
        " 'doesn’t': 'does not',\n",
        " 'don’t': 'do not',\n",
        " 'hadn’t': 'had not',\n",
        " 'hadn’t’ve': 'had not have',\n",
        " 'hasn’t': 'has not',\n",
        " 'haven’t': 'have not',\n",
        " '\\'he’d': 'he would',\n",
        " '\\'he’d’ve': 'he would have',\n",
        " '\\'he’ll': 'he will',\n",
        " '\\'he’ll’ve': 'he will have',\n",
        " '\\'he’s': 'he is',\n",
        " '\\'how’d': 'how did',\n",
        " '\\'how’re': 'how are',\n",
        " '\\'how’d’y': 'how do you',\n",
        " '\\'how’ll': 'how will',\n",
        " '\\'how’s': 'how is',\n",
        " '\\'I’d': 'I would',\n",
        " '\\'I’d’ve': 'I would have',\n",
        " '\\'I’ll': 'I will',\n",
        " '\\'I’ll’ve': 'I will have',\n",
        " '\\'I’m': 'I am',\n",
        " '\\'I’ve': 'I have',\n",
        " '\\'isn’t': 'is not',\n",
        " '\\'it’d': 'it would',\n",
        " '\\'it’d’ve': 'it would have',\n",
        " '\\'it’ll': 'it will',\n",
        " '\\'it’ll’ve': 'it will have',\n",
        " '\\'it’s': 'it is',\n",
        " '\\'let’s': 'let us',  \n",
        " 'he’d': 'he would',\n",
        " 'he’d’ve': 'he would have',\n",
        " 'she’ll': 'he will',\n",
        " 'he’ll’ve': 'he will have',\n",
        " 'odin’s' : 'odin is',\n",
        " 'joe’s' : 'joe is',\n",
        " 'dora’s' : 'dora is',\n",
        " 'wickfield’s' : 'wickfield is',\n",
        " 'tellson’s' : 'tellson is',\n",
        " 'omer’s' :  'omer is',\n",
        " 'cruncher’s' : 'crucher is', \n",
        " 'pip’s' : 'pip is',\n",
        " 'creakle’s ': 'creakle is',\n",
        " 'jorkins’s ' : 'jorkins is',\n",
        " 'jane’s' : 'jane is',\n",
        " 'elliot’s' : 'elliot is',\n",
        " 'anne’s' : 'anne is',\n",
        " 'tilney’s' : 'tilney is',\n",
        " 'lizzy’s' : 'lizzy is',\n",
        " 'smith’s' : 'smith is',\n",
        " 'walter’s' : 'walter is',\n",
        " 'musgrove’s' : 'musgrove is',\n",
        " 'lucy’s' : 'lucy is',\n",
        " 'nigel’s' : 'nigel is',\n",
        " 'nay’s' : 'nay is',\n",
        " 'chodinger’s' : 'chodinger is',\n",
        " 'humphrey’s' : 'humphrey is',\n",
        " 'jack’s' : 'jack is',\n",
        " 'arthur’s': 'arthur is',\n",
        " 'lana’s': 'lana is',\n",
        " 'sarah’s': 'sarah is',\n",
        " 'garcia’s' : 'garcia is',\n",
        " 'ivan’s' : 'ivan is',\n",
        " 'zossimov’s' : 'zossimov is',\n",
        " 'totski’s' : 'totski is',\n",
        " 'miusov’s' : 'miusov is',\n",
        " 'rodya’s' : 'rodya is',\n",
        " 'odin’s' : 'odin is',\n",
        " 'maman’s' : 'maman is',\n",
        " 'thee’s' : 'thee is',\n",
        " 'ye’s' : 'ye is',\n",
        " 'richard’s' : 'richard is',\n",
        " 'silas’s' : 'silas is',\n",
        " 'von’s': 'von is',\n",
        " 'lanyon’s' : 'lanyon is',\n",
        " 'jack’s' : 'jack is',\n",
        " 'gunn’s' : 'gumn is',\n",
        " 'nay’s' : 'nay is',  \n",
        " 'rankeillor’s': 'rankeillor is',      \n",
        " 'odin\\'s' : 'odin is',\n",
        " 'joe\\'s' : 'joe is',\n",
        " 'dora\\'s' : 'dora is',\n",
        " 'wickfield\\'s' : 'wickfield is',\n",
        " 'tellson\\'s' : 'tellson is',\n",
        " 'omer\\'s' :  'omer is',\n",
        " 'cruncher\\'s' : 'crucher is', \n",
        " 'pip\\'s' : 'pip is',\n",
        " 'creakle\\'s ': 'creakle is',\n",
        " 'jorkins\\'s ' : 'jorkins is',\n",
        " 'jane\\'s' : 'jane is',\n",
        " 'elliot\\'s' : 'elliot is',\n",
        " 'anne\\'s' : 'anne is',\n",
        " 'tilney\\'s' : 'tilney is',\n",
        " 'lizzy\\'s' : 'lizzy is',\n",
        " 'smith\\'s' : 'smith is',\n",
        " 'walter\\'s' : 'walter is',\n",
        " 'musgrove\\'s' : 'musgrove is',\n",
        " 'lucy\\'s' : 'lucy is',\n",
        " 'nigel\\'s' : 'nigel is',\n",
        " 'nay\\'s' : 'nay is',\n",
        " 'chodinger\\'s' : 'chodinger is',\n",
        " 'humphrey\\'s' : 'humphrey is',\n",
        " 'jack\\'s' : 'jack is',\n",
        " 'arthur\\'s': 'arthur is',\n",
        " 'lana\\'s': 'lana is',\n",
        " 'sarah\\'s': 'sarah is',\n",
        " 'garcia\\'s' : 'garcia is',\n",
        " 'ivan\\'s' : 'ivan is',\n",
        " 'zossimov\\'s' : 'zossimov is',\n",
        " 'totski\\'s' : 'totski is',\n",
        " 'miusov\\'s' : 'miusov is',\n",
        " 'rodya\\'s' : 'rodya is',\n",
        " 'odin\\'s' : 'odin is',\n",
        " 'maman\\'s' : 'maman is',\n",
        " 'thee\\'s' : 'thee is',\n",
        " 'ye\\'s' : 'ye is',\n",
        " 'richard\\'s' : 'richard is',\n",
        " 'silas\\'s' : 'silas is',\n",
        " 'von\\'s': 'von is',\n",
        " 'lanyon\\'s' : 'lanyon is',\n",
        " 'jack\\'s' : 'jack is',\n",
        " 'gunn\\'s' : 'gumn is',\n",
        " 'nay\\'s' : 'nay is',  \n",
        " 'rankeillor\\'s': 'rankeillor is',          \n",
        " '\\'odin\\'s' : 'odin is',\n",
        " '\\'joe\\'s' : 'joe is',\n",
        " '\\'dora\\'s' : 'dora is',\n",
        " '\\'wickfield\\'s' : 'wickfield is',\n",
        " '\\'tellson\\'s' : 'tellson is',\n",
        " '\\'omer\\'s' :  'omer is',\n",
        " '\\'cruncher\\'s' : 'crucher is', \n",
        " '\\'pip\\'s' : 'pip is',\n",
        " '\\'creakle\\'s ': 'creakle is',\n",
        " '\\'jorkins\\'s ' : 'jorkins is',\n",
        " '\\'jane\\'s' : 'jane is',\n",
        " '\\'elliot\\'s' : 'elliot is',\n",
        " '\\'anne\\'s' : 'anne is',\n",
        " '\\'tilney\\'s' : 'tilney is',\n",
        " '\\'lizzy\\'s' : 'lizzy is',\n",
        " '\\'smith\\'s' : 'smith is',\n",
        " '\\'walter\\'s' : 'walter is',\n",
        " '\\'musgrove\\'s' : 'musgrove is',\n",
        " '\\'lucy\\'s' : 'lucy is',\n",
        " '\\'nigel\\'s' : 'nigel is',\n",
        " '\\'nay\\'s' : 'nay is',\n",
        " '\\'chodinger\\'s' : 'chodinger is',\n",
        " '\\'humphrey\\'s' : 'humphrey is',\n",
        " '\\'jack\\'s' : 'jack is',\n",
        " '\\'arthur\\'s': 'arthur is',\n",
        " '\\'lana\\'s': 'lana is',\n",
        " '\\'sarah\\'s': 'sarah is',\n",
        " '\\'garcia\\'s' : 'garcia is',\n",
        " '\\'ivan\\'s' : 'ivan is',\n",
        " '\\'zossimov\\'s' : 'zossimov is',\n",
        " '\\'totski\\'s' : 'totski is',\n",
        " '\\'miusov\\'s' : 'miusov is',\n",
        " '\\'rodya\\'s' : 'rodya is',\n",
        " '\\'odin\\'s' : 'odin is',\n",
        " '\\'maman\\'s' : 'maman is',\n",
        " '\\'thee\\'s' : 'thee is',\n",
        " '\\'ye\\'s' : 'ye is',\n",
        " '\\'richard\\'s' : 'richard is',\n",
        " '\\'silas\\'s' : 'silas is',\n",
        " '\\'von\\'s': 'von is',\n",
        " '\\'lanyon\\'s' : 'lanyon is',\n",
        " '\\'jack\\'s' : 'jack is',\n",
        " '\\'gunn\\'s' : 'gumn is',\n",
        " '\\'nay\\'s' : 'nay is',  \n",
        " '\\'rankeillor\\'s': 'rankeillor is',        \n",
        " 'he’s': 'he is',\n",
        " 'how’d': 'how did',\n",
        " 'how’re': 'how are',\n",
        " 'how’d’y': 'how do you',\n",
        " 'how’ll': 'how will',\n",
        " 'how’s': 'how is',\n",
        " 'I’d': 'I would',\n",
        " 'I’d’ve': 'I would have',\n",
        " 'I’ll': 'I will',\n",
        " 'I’ll’ve': 'I will have',\n",
        " 'I’m': 'I am',\n",
        " 'I’ve': 'I have',\n",
        " 'isn’t': 'is not',\n",
        " 'it’d': 'it would',\n",
        " 'it’d’ve': 'it would have',\n",
        " 'it’ll': 'it will',\n",
        " 'it’ll’ve': 'it will have',\n",
        " 'it’s': 'it is',\n",
        " 'let’s': 'let us',          \n",
        " 'ma’am': 'madam',\n",
        " 'mayn’t': 'may not',\n",
        " 'might’ve': 'might have',\n",
        " 'mightn’t': 'might not',\n",
        " 'mightn’t’ve': 'might not have',\n",
        " 'must’ve': 'must have',\n",
        " 'mustn’t': 'must not',\n",
        " 'mustn’t’ve': 'must not have',\n",
        " 'needn’t': 'need not',\n",
        " 'needn’t’ve': 'need not have',\n",
        " 'o’clock': 'of the clock',\n",
        " 'oughtn’t': 'ought not',\n",
        " 'oughtn’t’ve': 'ought not have',\n",
        " 'shan’t': 'shall not',\n",
        " 'sha’n’t': 'shall not',\n",
        " 'shan’t’ve': 'shall not have',\n",
        " '\\'she’d': 'she would',\n",
        " '\\'she’d’ve': 'she would have',\n",
        " '\\'she’ll': 'she will',\n",
        " '\\'she’ll’ve': 'she will have',\n",
        " '\\'she’s': 'she is',\n",
        " '\\'should’ve': 'should have',\n",
        " '\\'shouldn’t': 'should not',\n",
        " '\\'shouldn’t’ve': 'should not have',\n",
        " '\\'so’ve': 'so have',\n",
        " '\\'so’s': 'so is',\n",
        " '\\'that’d': 'that would',\n",
        " '\\'that’d’ve': 'that would have',\n",
        " '\\'that’s': 'that is',\n",
        " '\\'there’d': 'there would',\n",
        " '\\'there’d’ve': 'there would have',\n",
        " '\\'there’s': 'there is',\n",
        " '\\'they’d': 'they would',\n",
        " '\\'they’d’ve': 'they would have',\n",
        " '\\'they’ll': 'they will',\n",
        " '\\'they’ll’ve': 'they will have',\n",
        " '\\'they’re': 'they are',\n",
        " '\\'they’ve': 'they have',\n",
        " 'she’d': 'she would',\n",
        " 'she’d’ve': 'she would have',\n",
        " 'she’ll': 'she will',\n",
        " 'she’ll’ve': 'she will have',\n",
        " 'she’s': 'she is',\n",
        " 'should’ve': 'should have',\n",
        " 'shouldn’t': 'should not',\n",
        " 'shouldn’t’ve': 'should not have',\n",
        " 'so’ve': 'so have',\n",
        " 'so’s': 'so is',\n",
        " 'that’d': 'that would',\n",
        " 'that’d’ve': 'that would have',\n",
        " 'that’s': 'that is',\n",
        " 'there’d': 'there would',\n",
        " 'there’d’ve': 'there would have',\n",
        " 'there’s': 'there is',\n",
        " 'they’d': 'they would',\n",
        " 'they’d’ve': 'they would have',\n",
        " 'they’ll': 'they will',\n",
        " 'they’ll’ve': 'they will have',\n",
        " 'they’re': 'they are',\n",
        " 'they’ve': 'they have',      \n",
        " 'to’ve': 'to have',\n",
        " 'wasn’t': 'was not',\n",
        " '\\'we’d': 'we would',\n",
        " '\\'we’d’ve': 'we would have',\n",
        " '\\'we’ll': 'we will',\n",
        " '\\'we’ll’ve': 'we will have',\n",
        " '\\'we’re': 'we are',\n",
        " '\\'we’ve': 'we have',\n",
        " 'we’d': 'we would',\n",
        " 'we’d’ve': 'we would have',\n",
        " 'we’ll': 'we will',\n",
        " 'we’ll’ve': 'we will have',\n",
        " 'we’re': 'we are',\n",
        " 'we’ve': 'we have',          \n",
        " 'weren’t': 'were not',\n",
        " '\\'what’ll': 'what will',\n",
        " '\\'what’ll’ve': 'what will have',\n",
        " '\\'what’re': 'what are',\n",
        " '\\'what’s': 'what is',\n",
        " '\\'what’ve': 'what have',\n",
        " '\\'when’s': 'when is',\n",
        " '\\'when’ve': 'when have',\n",
        " '\\'where’d': 'where did',\n",
        " '\\'where’s': 'where is',\n",
        " '\\'where’ve': 'where have',\n",
        " '\\'who’ll': 'who will',\n",
        " '\\'who’ll’ve': 'who will have',\n",
        " '\\'who’s': 'who is',\n",
        " '\\'who’ve': 'who have',\n",
        " '\\'why’s': 'why is',\n",
        " '\\'why’ve': 'why have',\n",
        " '\\'will’ve': 'will have',\n",
        " '\\'won’t': 'will not',\n",
        " '\\'won’t’ve': 'will not have',\n",
        " '\\'would’ve': 'would have',\n",
        " '\\'wouldn’t': 'would not',\n",
        " '\\'wouldn’t’ve': 'would not have',\n",
        " 'what’ll': 'what will',\n",
        " 'what’ll’ve': 'what will have',\n",
        " 'what’re': 'what are',\n",
        " 'what’s': 'what is',\n",
        " 'what’ve': 'what have',\n",
        " 'when’s': 'when is',\n",
        " 'when’ve': 'when have',\n",
        " 'where’d': 'where did',\n",
        " 'where’s': 'where is',\n",
        " 'where’ve': 'where have',\n",
        " 'who’ll': 'who will',\n",
        " 'who’ll’ve': 'who will have',\n",
        " 'who’s': 'who is',\n",
        " 'who’ve': 'who have',\n",
        " 'why’s': 'why is',\n",
        " 'why’ve': 'why have',\n",
        " 'will’ve': 'will have',\n",
        " 'won’t': 'will not',\n",
        " 'won’t’ve': 'will not have',\n",
        " 'would’ve': 'would have',\n",
        " 'wouldn’t': 'would not',\n",
        " 'wouldn’t’ve': 'would not have',   \n",
        " 'y’all': 'you all',\n",
        " 'y’all’d': 'you all would',\n",
        " 'y’all’d’ve': 'you all would have',\n",
        " 'y’all’re': 'you all are',\n",
        " 'y’all’ve': 'you all have',\n",
        " '\\'you’d': 'you would',\n",
        " '\\'you’d’ve': 'you would have',\n",
        " '\\'you’ll': 'you will',\n",
        " '\\'you’ll’ve': 'you shall have',\n",
        " '\\'you’re': 'you are',\n",
        " '\\'you’ve': 'you have', \n",
        " 'you’d': 'you would',\n",
        " 'you’d’ve': 'you would have',\n",
        " 'you’ll': 'you will',\n",
        " 'you’ll’ve': 'you shall have',\n",
        " 'you’re': 'you are',\n",
        " 'you’ve': 'you have'\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC7QQ-cxEk_O"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "def clean_contraction(text):\n",
        "    words = text_to_word_sequence(text)\n",
        "    words=[cont_dict[word] if word in cont_dict else word for word in words]\n",
        "    clean_sent=\" \".join(words)\n",
        "    \n",
        "    return clean_sent\n",
        "\n",
        "train['text'] = train['text'].str.lower().apply(clean_contraction)\n",
        "test['text'] = test['text'].str.lower().apply(clean_contraction)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "ftYgdER5U2t-",
        "outputId": "0ae46d6c-7d71-40a9-98dc-3aba3b02637e"
      },
      "source": [
        "train[train['text'].str.contains(\"'\")]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the captain was in the porch keeping himself c...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>'you were not here last sunday night' he said</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>'isn't there any help for it quesmark ' asked ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>'do you know that house quesmark ' i inquired ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>my dearest odin continued the other without at...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54850</th>\n",
              "      <td>'but not for two ma'am' rejoined mr odin in so...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54851</th>\n",
              "      <td>'he can not live a week the doctor says' pursu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54867</th>\n",
              "      <td>my dear odin you are talking quite idly pray w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54869</th>\n",
              "      <td>'you are afraid brittles' said mr odin</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54873</th>\n",
              "      <td>he looked back over his shoulder and beckoned ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5941 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "3      the captain was in the porch keeping himself c...       4\n",
              "8          'you were not here last sunday night' he said       0\n",
              "31     'isn't there any help for it quesmark ' asked ...       0\n",
              "35     'do you know that house quesmark ' i inquired ...       4\n",
              "53     my dearest odin continued the other without at...       1\n",
              "...                                                  ...     ...\n",
              "54850  'but not for two ma'am' rejoined mr odin in so...       0\n",
              "54851  'he can not live a week the doctor says' pursu...       0\n",
              "54867  my dear odin you are talking quite idly pray w...       1\n",
              "54869             'you are afraid brittles' said mr odin       0\n",
              "54873  he looked back over his shoulder and beckoned ...       0\n",
              "\n",
              "[5941 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5pZS5f3Eutp"
      },
      "source": [
        "train['text']=train['text'].str.replace('\\'s', '')\n",
        "train['text']=train['text'].str.replace('’s', '')\n",
        "train['text']=train['text'].str.replace(\"\\'\", '')\n",
        "train['text']=train['text'].str.replace(\"’\", '')\n",
        "\n",
        "test['text']=test['text'].str.replace(\"’s\",'')\n",
        "test['text']=test['text'].str.replace(\"\\'s\",'')\n",
        "test['text']=test['text'].str.replace(\"\\'\", '')\n",
        "test['text']=test['text'].str.replace(\"’\", '')\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcwHqACeQYLW"
      },
      "source": [
        "train['text']=train['text'].str.replace('á', '')\n",
        "train['text']=train['text'].str.replace('ä', '')\n",
        "train['text']=train['text'].str.replace('é', '')\n",
        "train['text']=train['text'].str.replace('í', '')\n",
        "train['text']=train['text'].str.replace('ó', '')\n",
        "train['text']=train['text'].str.replace('ú', '')\n",
        "train['text']=train['text'].str.replace('ý', '')\n",
        "train['text']=train['text'].str.replace('ü', ' Umlaut ')\n",
        "\n",
        "test['text']=test['text'].str.replace('ä', '')\n",
        "test['text']=test['text'].str.replace('á', '')\n",
        "test['text']=test['text'].str.replace('é', '')\n",
        "test['text']=test['text'].str.replace('í', '')\n",
        "test['text']=test['text'].str.replace('ó', '')\n",
        "test['text']=test['text'].str.replace('ú', '')\n",
        "test['text']=test['text'].str.replace('ý', '')\n",
        "test['text']=test['text'].str.replace('ü', ' Umlaut ')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No5kYgUtSV1S"
      },
      "source": [
        "def alpha_num(text):\n",
        "    return re.sub(r'[0-9]', ' num ', text)\n",
        "\n",
        "def remove_word(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in del_word:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "\n",
        "\n",
        "del_word = ['the', 'and' , 'to' , 'of' , 'a']\n",
        "\n",
        "train['text'] = train['text'].str.lower().apply(alpha_num).apply(remove_word)\n",
        "test['text'] = test['text'].str.lower().apply(alpha_num).apply(remove_word)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lwZOsZ6FIhR"
      },
      "source": [
        "vocab_size = 20000\n",
        "maxlen = 230\n",
        "embed_dim = 64\n",
        "num_heads = 4  # Number of attention heads\n",
        "padding_type='post'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8lvoASmFLTy"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlghouxPFMZ2"
      },
      "source": [
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-ZXhHb4FNnm",
        "outputId": "07e05ada-eb72-460a-debf-c65ea51edddc"
      },
      "source": [
        "trn = keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=maxlen)\n",
        "tst = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=maxlen)\n",
        "print(trn.shape, tst.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879, 230) (19617, 230)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW_LeJ4lFO2y"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-dQeTDQFQ-x"
      },
      "source": [
        "def get_model():\n",
        "    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "    inputs = layers.Input(shape=(maxlen,))\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "    x = transformer_block(x)\n",
        "    x = transformer_block(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.Dense(20, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    outputs = layers.Dense(n_class, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=.001))\n",
        "    return model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDHSxUrzFSSR",
        "outputId": "4426a08e-1942-40c1-a143-ebd5e35b01af"
      },
      "source": [
        "p_val = np.zeros((trn.shape[0], n_class))\n",
        "p_tst = np.zeros((tst.shape[0], n_class))\n",
        "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
        "    print(f'training model for CV #{i}')\n",
        "    clf = get_model()\n",
        "    \n",
        "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
        "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "    clf.fit(trn[i_trn], \n",
        "            to_categorical(y[i_trn]),\n",
        "            validation_data=(trn[i_val], to_categorical(y[i_val])),\n",
        "            epochs=10,\n",
        "            batch_size=128,\n",
        "            callbacks=[es])\n",
        "    p_val[i_val, :] = clf.predict(trn[i_val])\n",
        "    p_tst += clf.predict(tst) / n_fold\n",
        "    \n",
        "    clear_session()\n",
        "    gc.collect()\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model for CV #1\n",
            "Epoch 1/10\n",
            "343/343 [==============================] - 25s 74ms/step - loss: 1.2433 - val_loss: 0.8138\n",
            "Epoch 2/10\n",
            "343/343 [==============================] - 25s 73ms/step - loss: 0.6666 - val_loss: 0.6758\n",
            "Epoch 3/10\n",
            "343/343 [==============================] - 25s 73ms/step - loss: 0.4386 - val_loss: 0.7561\n",
            "Epoch 4/10\n",
            "343/343 [==============================] - 25s 74ms/step - loss: 0.3312 - val_loss: 0.8177\n",
            "Epoch 5/10\n",
            "343/343 [==============================] - ETA: 0s - loss: 0.2644Restoring model weights from the end of the best epoch.\n",
            "343/343 [==============================] - 25s 73ms/step - loss: 0.2644 - val_loss: 0.9337\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #2\n",
            "Epoch 1/10\n",
            "343/343 [==============================] - 26s 75ms/step - loss: 1.1392 - val_loss: 0.8171\n",
            "Epoch 2/10\n",
            "343/343 [==============================] - 25s 74ms/step - loss: 0.6098 - val_loss: 0.6878\n",
            "Epoch 3/10\n",
            "343/343 [==============================] - 25s 73ms/step - loss: 0.4210 - val_loss: 0.7585\n",
            "Epoch 4/10\n",
            "343/343 [==============================] - 25s 73ms/step - loss: 0.3226 - val_loss: 0.7985\n",
            "Epoch 5/10\n",
            "343/343 [==============================] - ETA: 0s - loss: 0.2656Restoring model weights from the end of the best epoch.\n",
            "343/343 [==============================] - 25s 73ms/step - loss: 0.2656 - val_loss: 0.8901\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #3\n",
            "Epoch 1/10\n",
            "343/343 [==============================] - 25s 74ms/step - loss: 1.1853 - val_loss: 0.7753\n",
            "Epoch 2/10\n",
            "343/343 [==============================] - 25s 72ms/step - loss: 0.6306 - val_loss: 0.6887\n",
            "Epoch 3/10\n",
            "343/343 [==============================] - 25s 73ms/step - loss: 0.4221 - val_loss: 0.7205\n",
            "Epoch 4/10\n",
            "343/343 [==============================] - 25s 72ms/step - loss: 0.3202 - val_loss: 0.8054\n",
            "Epoch 5/10\n",
            "343/343 [==============================] - ETA: 0s - loss: 0.2601Restoring model weights from the end of the best epoch.\n",
            "343/343 [==============================] - 25s 73ms/step - loss: 0.2601 - val_loss: 0.8661\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #4\n",
            "Epoch 1/10\n",
            "343/343 [==============================] - 25s 74ms/step - loss: 1.2009 - val_loss: 0.8264\n",
            "Epoch 2/10\n",
            "343/343 [==============================] - 25s 73ms/step - loss: 0.6500 - val_loss: 0.7212\n",
            "Epoch 3/10\n",
            "343/343 [==============================] - 25s 72ms/step - loss: 0.4393 - val_loss: 0.7360\n",
            "Epoch 4/10\n",
            "343/343 [==============================] - 25s 73ms/step - loss: 0.3257 - val_loss: 0.7453\n",
            "Epoch 5/10\n",
            "343/343 [==============================] - ETA: 0s - loss: 0.2641Restoring model weights from the end of the best epoch.\n",
            "343/343 [==============================] - 25s 73ms/step - loss: 0.2641 - val_loss: 0.9386\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #5\n",
            "Epoch 1/10\n",
            "343/343 [==============================] - 24s 70ms/step - loss: 1.2439 - val_loss: 0.8837\n",
            "Epoch 2/10\n",
            "343/343 [==============================] - 24s 69ms/step - loss: 0.6918 - val_loss: 0.7117\n",
            "Epoch 3/10\n",
            "343/343 [==============================] - 24s 69ms/step - loss: 0.4750 - val_loss: 0.7006\n",
            "Epoch 4/10\n",
            "343/343 [==============================] - 24s 69ms/step - loss: 0.3633 - val_loss: 0.7730\n",
            "Epoch 5/10\n",
            "343/343 [==============================] - 24s 69ms/step - loss: 0.2838 - val_loss: 0.8675\n",
            "Epoch 6/10\n",
            "343/343 [==============================] - ETA: 0s - loss: 0.2400Restoring model weights from the end of the best epoch.\n",
            "343/343 [==============================] - 24s 69ms/step - loss: 0.2400 - val_loss: 0.8769\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OOmE9QfFTqA",
        "outputId": "e79b14bf-c7a1-4fee-bce3-c522a337e838"
      },
      "source": [
        "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n",
        "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy (CV):  75.2492%\n",
            "Log Loss (CV):   0.6948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMQUgYQyKi3f"
      },
      "source": [
        "#     max_length        vocab_size       num_heads         accuracy             \n",
        "       \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMYR94SJH3Bm"
      },
      "source": [
        "\n",
        "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
        "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "-MgO00YBH68K",
        "outputId": "996bf989-f879-49c6-fd50-40ec730a6486"
      },
      "source": [
        "sub = pd.read_csv(sample_file, index_col=0)\n",
        "print(sub.shape)\n",
        "sub.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19617, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  1  2  3  4\n",
              "index               \n",
              "0      0  0  0  0  0\n",
              "1      0  0  0  0  0\n",
              "2      0  0  0  0  0\n",
              "3      0  0  0  0  0\n",
              "4      0  0  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "v_3lQZktH8fy",
        "outputId": "0871c20f-b297-400d-da6a-f02c3c7d1690"
      },
      "source": [
        "sub[sub.columns] = p_tst\n",
        "sub.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.2144</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.0389</td>\n",
              "      <td>0.0058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.2250</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.0601</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.5224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9830</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0671</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>0.8657</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.0640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.8831</td>\n",
              "      <td>0.0239</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.0768</td>\n",
              "      <td>0.0083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0       1       2       3       4\n",
              "index                                        \n",
              "0      0.0146  0.2144  0.7262  0.0389  0.0058\n",
              "1      0.2250  0.1587  0.0601  0.0338  0.5224\n",
              "2      0.9830  0.0062  0.0042  0.0002  0.0064\n",
              "3      0.0671  0.0019  0.8657  0.0013  0.0640\n",
              "4      0.8831  0.0239  0.0079  0.0768  0.0083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIah69A_H-B1"
      },
      "source": [
        "sub.to_csv(sub_file)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGQy7iItH_MC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
