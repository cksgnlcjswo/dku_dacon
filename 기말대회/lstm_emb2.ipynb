{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm-emb2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCVLM1zGlDyT"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKXkJxtElNnC"
      },
      "source": [
        "from matplotlib import rcParams, pyplot as plt\n",
        "import numpy as np\n",
        "import string\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM,GRU, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional, concatenate\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings \n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBuoAKLAlPtX",
        "outputId": "17acc50a-6d98-4236-e0b6-61a04f268ba6"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Restrict TensorFlow to only use the first GPU\n",
        "    try:\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "    except RuntimeError as e:\n",
        "        # Visible devices must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "else:\n",
        "    print('No GPU detected')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jjkmCowlUDE"
      },
      "source": [
        "rcParams['figure.figsize'] = (16, 8)\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('max_columns', 100)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozqcZT2llXxW"
      },
      "source": [
        "data_dir = Path('/content/drive/MyDrive/dacon/input')\n",
        "feature_dir = Path('../build/feature')\n",
        "val_dir = Path('/content/drive/MyDrive/dacon/build/val')\n",
        "tst_dir = Path('/content/drive/MyDrive/dacon/build/tst')\n",
        "sub_dir = Path('/content/drive/MyDrive/dacon/build/sub')\n",
        "\n",
        "trn_file = data_dir / 'train.csv'\n",
        "tst_file = data_dir / 'test_x.csv'\n",
        "sample_file = data_dir / 'sample_submission.csv'\n",
        "\n",
        "target_col = 'author'\n",
        "n_fold = 5\n",
        "n_class = 5\n",
        "seed = 42"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wedaBd8lZWp"
      },
      "source": [
        "algo_name = 'lstm'\n",
        "feature_name = 'emb'\n",
        "model_name = f'{algo_name}_{feature_name}'\n",
        "\n",
        "feature_file = feature_dir / f'{feature_name}.csv'\n",
        "p_val_file = val_dir / f'{model_name}.val.csv'\n",
        "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
        "sub_file = sub_dir / f'{model_name}.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "q_ytTVt1lbmr",
        "outputId": "eab75259-3e1b-48f3-8a42-0d26ffe759e4"
      },
      "source": [
        "train = pd.read_csv(trn_file, index_col=0)\n",
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "0      He was almost choking. There was so much, so m...       3\n",
              "1                 “Your sister asked for it, I suppose?”       2\n",
              "2       She was engaged one day as she walked, in per...       1\n",
              "3      The captain was in the porch, keeping himself ...       4\n",
              "4      “Have mercy, gentlemen!” odin flung up his han...       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wT6B7qc9ldzb",
        "outputId": "dc3e5767-3268-4580-e033-b2ac09c52538"
      },
      "source": [
        "test = pd.read_csv(tst_file, index_col=0)\n",
        "test.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Not at all. I think she is one of the most ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As the lady had stated her intention of scream...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“And then suddenly in the silence I heard a so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>His conviction remained unchanged. So far as I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "index                                                   \n",
              "0      “Not at all. I think she is one of the most ch...\n",
              "1      \"No,\" replied he, with sudden consciousness, \"...\n",
              "2      As the lady had stated her intention of scream...\n",
              "3      “And then suddenly in the silence I heard a so...\n",
              "4      His conviction remained unchanged. So far as I..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "QON0HVz9OTTb",
        "outputId": "1e068625-886e-4538-b55f-ed337d72b3a0"
      },
      "source": [
        "train[train['text'].str.contains(\"makin'\")]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47126</th>\n",
              "      <td>'We fand her in odin Bay, Rorie an' me, and a'...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "47126  'We fand her in odin Bay, Rorie an' me, and a'...       4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fynb2UDyG_5c",
        "outputId": "2b03ec46-13fe-4997-c916-2f392c5fb79d"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']',\n",
        "          '>', '%', '=', '#', '*', '+', '\\\\', '•', '~', '@', '£', '·', '_', '{', '}', '©', '^',\n",
        "          '®', '`', '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â', '█',\n",
        "          '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶',\n",
        "          '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼',\n",
        "          '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
        "          'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪',\n",
        "          '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
        "result=set()\n",
        "\n",
        "def find_puncts(text):\n",
        "    global result\n",
        "    words = text_to_word_sequence(text)\n",
        "    for word in words :\n",
        "      for character in word :\n",
        "        if character in puncts : result.add(character)\n",
        "\n",
        "    return\n",
        "\n",
        "train['text'].str.lower().apply(find_puncts)\n",
        "result"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"'\", '£', 'à', 'â', 'è', 'é', 'ï', '—', '‘', '’', '“', '”'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdXtBAEjljkq"
      },
      "source": [
        "train['text'] = train['text'].str.lower()\n",
        "test['text'] = test['text'].str.lower()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWkpSqqLTJIW"
      },
      "source": [
        "train['text'] = train['text'].str.replace('\\?',' quesmark ')\n",
        "train['text'] = train['text'].str.replace('\\!',' exclmark ')\n",
        "train['text'] = train['text'].str.replace('\\&',' empent ')\n",
        "train['text'] = train['text'].str.replace(\"\\*\",' chstar ')\n",
        "train['text'] = train['text'].str.replace(\";\",' smcolons  ')\n",
        "\n",
        "test['text'] = test['text'].str.replace('\\?',' quesmark ')\n",
        "test['text'] = test['text'].str.replace('\\!',' exclmark ')\n",
        "test['text'] = test['text'].str.replace('\\&',' empent ')\n",
        "test['text'] = test['text'].str.replace(\"\\*\",' chstar ')\n",
        "test['text'] = test['text'].str.replace(\";\",' smcolons  ')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgt31x-UOv_s",
        "outputId": "cd6238e7-0599-485d-db12-8036c693e192"
      },
      "source": [
        "\n",
        "contraction = set()\n",
        "\n",
        "def find_contraction(text):\n",
        "    global contraction\n",
        "    words = text_to_word_sequence(text)\n",
        "    for word in words :\n",
        "      if \"\\'\" in word or \"’\" in word : contraction.add(word)       \n",
        "    return \n",
        "\n",
        "train['text'].str.lower().apply(find_contraction)\n",
        "contraction    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'—don’t',\n",
              " \"'odin's\",\n",
              " \"'so\",\n",
              " \"sheep's\",\n",
              " \"clerk's\",\n",
              " 'napoleon’s',\n",
              " 'father’',\n",
              " '“‘it’s',\n",
              " '‘’tis',\n",
              " \"'dun\",\n",
              " \"there's\",\n",
              " \"dame's\",\n",
              " \"darling's\",\n",
              " \"'unless\",\n",
              " 'j’aime',\n",
              " 'g’s',\n",
              " \"grays'\",\n",
              " 'fellow’',\n",
              " \"assemblin'\",\n",
              " '“lor’',\n",
              " 'murger’s',\n",
              " 'boat’s',\n",
              " \"pheasants'\",\n",
              " '‘i’ll',\n",
              " 'animal’s',\n",
              " 'mountain’s',\n",
              " 'he’ll',\n",
              " '‘fraud’',\n",
              " 'nobility’',\n",
              " \"graham's\",\n",
              " \"'show\",\n",
              " \"d'honneur\",\n",
              " '“let’s',\n",
              " 'man—there’s',\n",
              " 'wretch’',\n",
              " \"'had\",\n",
              " \"m'en\",\n",
              " 'peter’s',\n",
              " 'stick’s',\n",
              " \"“bill's\",\n",
              " \"'eight\",\n",
              " \"'what\",\n",
              " \"price's\",\n",
              " \"on'y\",\n",
              " 'clem’s',\n",
              " \"'mouton\",\n",
              " 'prussian’',\n",
              " \"for't\",\n",
              " 'side—don’t',\n",
              " \"'decidedly\",\n",
              " \"nieces'\",\n",
              " \"“it's\",\n",
              " 'memory’s',\n",
              " 'dominick’s',\n",
              " 'babushkin’s',\n",
              " \"himsel'\",\n",
              " \"odin'\",\n",
              " 'lizzy’s',\n",
              " 'princess’s',\n",
              " \"helmsman's\",\n",
              " \"'i'd\",\n",
              " 'you—jem’s',\n",
              " \"gorgon's\",\n",
              " \"'come\",\n",
              " \"aaron's\",\n",
              " 'that’ll',\n",
              " \"reg'lar\",\n",
              " \"'is\",\n",
              " 'boys’',\n",
              " 'flopson’s',\n",
              " 'pensete’s',\n",
              " \"'yon\",\n",
              " \"'ah\",\n",
              " 'hedgehog’s',\n",
              " \"'congratulate'\",\n",
              " 'odinevna’s',\n",
              " \"ignaty's\",\n",
              " 'to—odin—’',\n",
              " 'clackin’',\n",
              " 'trevor’s',\n",
              " \"“we'd\",\n",
              " 'p’raps',\n",
              " 'son’',\n",
              " 'hopkins’',\n",
              " 'fit’',\n",
              " 'thank’ee',\n",
              " \"of'\",\n",
              " \"'brittles\",\n",
              " \"martyr's\",\n",
              " \"gunn's\",\n",
              " \"pross's\",\n",
              " \"sportin'\",\n",
              " \"shirley's\",\n",
              " \"'thank\",\n",
              " \"rider's\",\n",
              " 'qu’ils',\n",
              " 'browner’s',\n",
              " \"'denial\",\n",
              " 'angel’s',\n",
              " \"stay'\",\n",
              " 'em’ly',\n",
              " 'brothers’',\n",
              " 'debtor’s',\n",
              " \"'darling\",\n",
              " \"latter's\",\n",
              " 'you—d’you',\n",
              " 'drinker’s',\n",
              " \"“odin's\",\n",
              " 'murderer’s',\n",
              " 'her’',\n",
              " \"'keeps\",\n",
              " 'auntie’s',\n",
              " 'paper’',\n",
              " 'mayn’t',\n",
              " 'miller’s',\n",
              " \"he'd\",\n",
              " 'comfort’ble',\n",
              " \"randall's\",\n",
              " '“‘i’m',\n",
              " \"'heart\",\n",
              " \"all's\",\n",
              " 'ladder’s',\n",
              " \"'sapristi\",\n",
              " 'captain’s',\n",
              " \"governesses'\",\n",
              " \"ain't\",\n",
              " 'you’re',\n",
              " 'officer’s',\n",
              " \"“that's\",\n",
              " 'tain’t',\n",
              " \"un's\",\n",
              " \"missin'\",\n",
              " 'yoursel’',\n",
              " \"student's\",\n",
              " '“i—i’ll',\n",
              " \"comin'\",\n",
              " \"'morning\",\n",
              " \"home's\",\n",
              " 's’en',\n",
              " 'dunstan’s',\n",
              " 'blackboy’',\n",
              " \"'shame\",\n",
              " \"'boy'\",\n",
              " \"white's\",\n",
              " 'lavinia’s',\n",
              " 'odin’—that’s',\n",
              " '‘i’ve',\n",
              " \"'strangers\",\n",
              " 'wollop’em',\n",
              " \"jeweller's\",\n",
              " 'quincey’s',\n",
              " 'clergyman’s',\n",
              " \"sultan's\",\n",
              " \"moulton's\",\n",
              " \"merivale's\",\n",
              " \"'dooty\",\n",
              " 'justice’s',\n",
              " 'stairs’',\n",
              " 'serious’',\n",
              " 'lad’ll',\n",
              " \"'surely\",\n",
              " 'bork’s',\n",
              " 'o’t',\n",
              " 'herself’',\n",
              " 'nobody’s',\n",
              " 'too’',\n",
              " 'pushkin’s',\n",
              " '—i’d',\n",
              " 'monastery—it’s',\n",
              " '“god’s',\n",
              " 'anne’s',\n",
              " 'priest’s',\n",
              " \"o'brien\",\n",
              " \"'recalled\",\n",
              " 'clara’s',\n",
              " 'brute’s',\n",
              " 'assistant’s',\n",
              " \"'tall\",\n",
              " \"bleedin'\",\n",
              " 'devil’s',\n",
              " 'mademoiselle’s',\n",
              " 'husband’s',\n",
              " 'hersel’',\n",
              " 'lord’s',\n",
              " 'mowcher’s',\n",
              " \"'close\",\n",
              " \"mischief's\",\n",
              " \"cur'osity\",\n",
              " '‘they’ve',\n",
              " \"silver's\",\n",
              " \"paul's\",\n",
              " \"'frob\",\n",
              " \"artful's\",\n",
              " \"they'll\",\n",
              " '“didn’t',\n",
              " \"“here's\",\n",
              " \"filipov's\",\n",
              " '’xcepting',\n",
              " 'said’',\n",
              " 'hart’',\n",
              " \"parent's\",\n",
              " 'abraham’s',\n",
              " \"'loves\",\n",
              " 'dursn’t',\n",
              " \"cat's\",\n",
              " 'jenkinson’s',\n",
              " 'flickerin’',\n",
              " \"'beautiful\",\n",
              " 'can’t',\n",
              " 'tenants’',\n",
              " 'schoolfellows’',\n",
              " 'maria’s',\n",
              " \"benefactor's\",\n",
              " \"laundress's\",\n",
              " 'for’ard',\n",
              " \"'man\",\n",
              " \"this'll\",\n",
              " 'secretary’s',\n",
              " 'wedding’',\n",
              " '—wouldn’t',\n",
              " 'lackey’s',\n",
              " '‘tidd’s',\n",
              " \"marshal's\",\n",
              " 'horse’s',\n",
              " \"farthing's\",\n",
              " \"torment'\",\n",
              " 'bor’',\n",
              " 'l’esprit',\n",
              " \"gabart's\",\n",
              " \"'home\",\n",
              " '“odin’s',\n",
              " '‘theer’s',\n",
              " 'pleasure’s',\n",
              " \"marquise'\",\n",
              " 'ainslie’s',\n",
              " \"'ooman\",\n",
              " \"'does\",\n",
              " '“we’d',\n",
              " 'demon—‘i’ll',\n",
              " \"an'\",\n",
              " '’prentices',\n",
              " \"'ye'll\",\n",
              " 'moscow’s',\n",
              " 'goldini’s',\n",
              " \"ava'\",\n",
              " \"'though\",\n",
              " \"skipper's\",\n",
              " '“he’d',\n",
              " \"year's\",\n",
              " 'does’',\n",
              " \"grandmother's\",\n",
              " \"wretch's\",\n",
              " \"king's\",\n",
              " \"'like\",\n",
              " 'babe’s',\n",
              " '“who’s',\n",
              " 'lawyers’',\n",
              " 'neezing’',\n",
              " \"glo'ster\",\n",
              " 'omer’s',\n",
              " \"i's\",\n",
              " '“here’s',\n",
              " \"'wery\",\n",
              " \"'two\",\n",
              " \"monk's\",\n",
              " 'd’you',\n",
              " \"'civil\",\n",
              " \"'before\",\n",
              " '‘now’s',\n",
              " 'word—i’ll',\n",
              " '“they’ll',\n",
              " '‘ain’t',\n",
              " 'rajah’s',\n",
              " \"'lection\",\n",
              " 'him’',\n",
              " \"'something\",\n",
              " \"'leathers\",\n",
              " 'instant’s',\n",
              " \"saints'\",\n",
              " 'parent’s',\n",
              " 'hole’s',\n",
              " 'l’inventer',\n",
              " \"they'd\",\n",
              " 'drawing—’',\n",
              " 'that—’',\n",
              " \"'scottish\",\n",
              " 'lobbs’s',\n",
              " \"'bull's\",\n",
              " \"dustman's\",\n",
              " \"emp'y\",\n",
              " \"statue's\",\n",
              " \"her's\",\n",
              " 'statue’s',\n",
              " 'knight’s',\n",
              " \"qu'il\",\n",
              " \"'change\",\n",
              " 'jade’s',\n",
              " '‘go’',\n",
              " \"'about\",\n",
              " 'hoff’s',\n",
              " '“it’ll',\n",
              " 'compensation—they’ve',\n",
              " \"what's\",\n",
              " \"“you're\",\n",
              " \"hatch's\",\n",
              " \"'stay\",\n",
              " \"gardener's\",\n",
              " '‘blabbed’',\n",
              " 'seaman’s',\n",
              " \"power'\",\n",
              " 'beauty’s',\n",
              " \"'stupid\",\n",
              " 'afanasy’s',\n",
              " \"engagement's\",\n",
              " \"'tis\",\n",
              " \"verhishins'\",\n",
              " 'sport’',\n",
              " \"'lauk\",\n",
              " \"jacob's\",\n",
              " 'children’s',\n",
              " 'excellency’s',\n",
              " \"bowyer's\",\n",
              " \"'carry\",\n",
              " 'p’s',\n",
              " \"'twill\",\n",
              " 'giv’',\n",
              " 'night’s',\n",
              " \"assailant's\",\n",
              " \"'god's\",\n",
              " \"day's\",\n",
              " 'spectators’',\n",
              " \"postman's\",\n",
              " \"countryman's\",\n",
              " 'translator’s',\n",
              " \"'by\",\n",
              " \"again'\",\n",
              " \"m'a\",\n",
              " 'duke’s',\n",
              " \"chodinger's\",\n",
              " 'them’',\n",
              " \"d'angle\",\n",
              " \"'vyek\",\n",
              " 'functionary’s',\n",
              " 'it—you’re',\n",
              " \"sucklings'\",\n",
              " 'bootmaker’s',\n",
              " \"mare's\",\n",
              " \"cutler's\",\n",
              " 'dog’s',\n",
              " '’66',\n",
              " 'pip’s',\n",
              " \"'ha'e\",\n",
              " \"'bring\",\n",
              " '“h’m',\n",
              " \"“'a\",\n",
              " 'doubt—’',\n",
              " 'really’',\n",
              " \"'humph\",\n",
              " \"smith's\",\n",
              " 'it’s—”',\n",
              " \"cutchull'ns\",\n",
              " 'neighbour’s',\n",
              " \"'damn\",\n",
              " \"speaker's\",\n",
              " \"housebreaker's\",\n",
              " \"week's\",\n",
              " \"musgroves'\",\n",
              " \"lana's\",\n",
              " \"jacks'\",\n",
              " \"sevastyanov's\",\n",
              " \"'were\",\n",
              " \"stirrin'\",\n",
              " 'shipley’s',\n",
              " 'sittin’',\n",
              " \"ladyship's\",\n",
              " \"'wanted\",\n",
              " \"marie's\",\n",
              " \"doctor's\",\n",
              " \"scamp'\",\n",
              " \"'him\",\n",
              " '‘we’',\n",
              " 'licence’',\n",
              " \"simon's\",\n",
              " 'strong’',\n",
              " 'odinitch’s',\n",
              " 'harris’s',\n",
              " 'oughtn’t',\n",
              " \"betty's\",\n",
              " '“ain’t',\n",
              " \"'we've\",\n",
              " \"lacquey's\",\n",
              " 'profession’',\n",
              " 'friends—’',\n",
              " \"laurentina's\",\n",
              " '‘who’s',\n",
              " 'lodgers’',\n",
              " 'darling’s',\n",
              " 'anybody’s',\n",
              " '—that’s',\n",
              " 'spree—that’s',\n",
              " 'other’s',\n",
              " \"'will\",\n",
              " 'rascal’s',\n",
              " 'wantin’',\n",
              " 'mysel’',\n",
              " 'orlick’s',\n",
              " \"'hours'\",\n",
              " 'cyclist’s',\n",
              " \"'his\",\n",
              " 'it’—with',\n",
              " \"animal's\",\n",
              " \"'address\",\n",
              " 'affection’s',\n",
              " \"'wo\",\n",
              " \"'it'll\",\n",
              " \"'obstinate\",\n",
              " \"'whew\",\n",
              " 'banker’s',\n",
              " '‘samovar’',\n",
              " 'friend’',\n",
              " \"'well\",\n",
              " \"“'god\",\n",
              " 'dacre’s',\n",
              " 'minute—i’ve',\n",
              " 'l’homme',\n",
              " \"warn't\",\n",
              " 'scoundrel’',\n",
              " \"'lasses\",\n",
              " \"“can't\",\n",
              " 'matheson’s',\n",
              " \"day'\",\n",
              " \"fellow's\",\n",
              " 'character—that’s',\n",
              " '“this’ll',\n",
              " \"you'\",\n",
              " 'chieftain’s',\n",
              " 'purposes’',\n",
              " '‘suffolk’s',\n",
              " 'chillip’s',\n",
              " \"odinet's\",\n",
              " 'generosity’s',\n",
              " \"sittin'\",\n",
              " \"agin'\",\n",
              " 'pole’s',\n",
              " \"crossin'\",\n",
              " 'holy’',\n",
              " 'evening’s',\n",
              " 'bankers’',\n",
              " 'known—’',\n",
              " '“there’s',\n",
              " \"bartlett's\",\n",
              " 'mas’r',\n",
              " 'bees’',\n",
              " 'luther’s',\n",
              " \"patient's\",\n",
              " 'enfield’s',\n",
              " \"'won't\",\n",
              " 'pursuer’s',\n",
              " 'sufferer’s',\n",
              " '‘problem’',\n",
              " 'matthew’s',\n",
              " 'plotnikov’s',\n",
              " \"duke's\",\n",
              " \"'barsad'\",\n",
              " 'joe’s',\n",
              " \"expedition's\",\n",
              " \"sister's\",\n",
              " 'aside’',\n",
              " \"d'\",\n",
              " '‘learn’',\n",
              " \"'sir\",\n",
              " \"coachmaker's\",\n",
              " \"'fry\",\n",
              " 'béranger’s',\n",
              " \"him's\",\n",
              " \"porgy'd\",\n",
              " 'podincutor’s',\n",
              " \"'family\",\n",
              " \"'ten\",\n",
              " \"'pale\",\n",
              " 'girl’s',\n",
              " '’us',\n",
              " 'shouldn’t',\n",
              " 'trabb’s',\n",
              " \"findin'\",\n",
              " \"'toor\",\n",
              " \"irony'\",\n",
              " \"'couldn't\",\n",
              " 'lieutenant’s',\n",
              " 'recorder’s',\n",
              " 'blessington’s',\n",
              " 'charpentier’s',\n",
              " '‘umble’',\n",
              " \"'cept\",\n",
              " \"myasnitchiha's\",\n",
              " 'chicken’',\n",
              " \"l'accident\",\n",
              " \"'devil'\",\n",
              " \"'cunning\",\n",
              " \"'hah\",\n",
              " \"rogue's\",\n",
              " 'doctor’s—general',\n",
              " 'cutler’s',\n",
              " \"enemy's\",\n",
              " \"'are\",\n",
              " 'turtle’',\n",
              " '“d’ye',\n",
              " 'they’re',\n",
              " 'lawyers—it’s',\n",
              " \"anybody's\",\n",
              " 'jester’s',\n",
              " \"sp'iled\",\n",
              " '“there’ll',\n",
              " 'side’',\n",
              " \"'can't\",\n",
              " 'readers’',\n",
              " \"thing's\",\n",
              " 'hours’',\n",
              " \"foeman's\",\n",
              " 'hadn’t',\n",
              " \"'i'b\",\n",
              " '‘wi’',\n",
              " \"'ay'\",\n",
              " \"'i'll\",\n",
              " 'bally’s',\n",
              " \"life'\",\n",
              " 'd’état',\n",
              " \"landlady's\",\n",
              " 'trainer’s',\n",
              " 'daren’t',\n",
              " 'yon’s',\n",
              " \"man's\",\n",
              " \"englishman's\",\n",
              " \"laughin'\",\n",
              " \"'shan't\",\n",
              " \"'whatten\",\n",
              " \"'\",\n",
              " \"'mealy\",\n",
              " \"'have\",\n",
              " \"'wherever\",\n",
              " '‘creature’',\n",
              " \"'d\",\n",
              " \"'policeman\",\n",
              " 'duck’s',\n",
              " 'again—that’s',\n",
              " \"'you\",\n",
              " 'tipp’s',\n",
              " \"me's\",\n",
              " \"days'\",\n",
              " \"'seen\",\n",
              " \"ravin'\",\n",
              " \"wanderin's\",\n",
              " '‘ma’am',\n",
              " 'london’',\n",
              " \"'leaves\",\n",
              " '“c’est',\n",
              " 'generation’',\n",
              " \"hussars'\",\n",
              " 'acton’s',\n",
              " \"heart's\",\n",
              " 'landlord’s',\n",
              " '‘doen’t',\n",
              " \"'juries\",\n",
              " \"'listen\",\n",
              " '“ye’ve',\n",
              " 'moment’s',\n",
              " \"'trois\",\n",
              " 'mithers’s',\n",
              " \"'aros\",\n",
              " \"'cut\",\n",
              " 'months’',\n",
              " 'gridyenko’s',\n",
              " \"'that'll\",\n",
              " \"“aren't\",\n",
              " '“shouldn’t',\n",
              " \"'dot'\",\n",
              " 'what’',\n",
              " \"'pooh\",\n",
              " \"friars'\",\n",
              " 'russia’s',\n",
              " 'sort’s',\n",
              " \"dogger's\",\n",
              " \"we've\",\n",
              " 'o’rooke',\n",
              " 'you—’',\n",
              " \"'we're\",\n",
              " 'true’',\n",
              " \"brothers'\",\n",
              " \"uncle's\",\n",
              " 'creatures’',\n",
              " 'wittles—that’s',\n",
              " '‘sign’',\n",
              " '‘business’',\n",
              " \"robinson's\",\n",
              " '‘dreams’',\n",
              " '—couldn’t',\n",
              " \"'egad\",\n",
              " \"'sudden\",\n",
              " 'dear—that’s',\n",
              " \"die'll\",\n",
              " 'publishers’',\n",
              " 'shlessinger’s',\n",
              " \"'cannot\",\n",
              " \"excellency's\",\n",
              " 'seat’',\n",
              " \"janet's\",\n",
              " \"rival's\",\n",
              " 'prisoner’s',\n",
              " \"mother's\",\n",
              " '‘that’',\n",
              " 'chopin’s',\n",
              " \"sun's\",\n",
              " \"“there's\",\n",
              " \"'clever\",\n",
              " \"'special\",\n",
              " \"“'what\",\n",
              " \"'hours\",\n",
              " \"weren't\",\n",
              " \"interestin'\",\n",
              " 'days’',\n",
              " \"friendship's\",\n",
              " 'breakers’',\n",
              " 'enemy’s',\n",
              " \"suitor's\",\n",
              " 'carrier’s',\n",
              " '“that’s',\n",
              " \"haven't\",\n",
              " \"himself'\",\n",
              " \"odinlins'\",\n",
              " 'doran’s',\n",
              " \"fagid's\",\n",
              " \"harry's\",\n",
              " \"wa's\",\n",
              " \"'happy\",\n",
              " \"so's\",\n",
              " \"'ladies\",\n",
              " 'he’s—a',\n",
              " \"'reflections\",\n",
              " \"knave's\",\n",
              " '‘i’m',\n",
              " \"'hanging\",\n",
              " 'hucksters’',\n",
              " \"fishmonger's\",\n",
              " 'gen’l’m’n’s',\n",
              " \"“let's\",\n",
              " '“‘“i’m',\n",
              " 'auctioneer’s',\n",
              " \"'un\",\n",
              " \"d'errien\",\n",
              " 'wickfield’s',\n",
              " \"mind's\",\n",
              " '‘yes’',\n",
              " \"'lend\",\n",
              " \"makin'\",\n",
              " 'undertaker’s',\n",
              " 'mightn’t',\n",
              " 'george’s',\n",
              " \"owner's\",\n",
              " 'folk’s',\n",
              " \"calf's\",\n",
              " '’em”',\n",
              " 'forrester’s',\n",
              " \"cliff's\",\n",
              " '“look’ee',\n",
              " \"wits'\",\n",
              " \"you're\",\n",
              " '‘we’ve',\n",
              " 'trevelyan’s',\n",
              " 'clair’s',\n",
              " \"gipsies'\",\n",
              " 'sixteenth—jacobson’s—i',\n",
              " \"boy'\",\n",
              " \"singin'\",\n",
              " \"sisters's\",\n",
              " 'coster’s',\n",
              " \"'set\",\n",
              " 'cluny’s',\n",
              " 'goin’',\n",
              " \"qu'est\",\n",
              " \"sailors'\",\n",
              " 'grandfather’s',\n",
              " 'conceit—that’s',\n",
              " 'odin—that’s',\n",
              " 'cuthen’th',\n",
              " \"'mockery'\",\n",
              " '‘told’',\n",
              " '‘mas’r',\n",
              " \"instant's\",\n",
              " 'canary’s',\n",
              " 'robin’s',\n",
              " \"tchurkin's\",\n",
              " 'tom’s',\n",
              " 'hastie’s',\n",
              " \"'hush\",\n",
              " \"'send\",\n",
              " \"shame's\",\n",
              " 'lover’s',\n",
              " \"nobody's\",\n",
              " \"'has\",\n",
              " \"party's\",\n",
              " \"poulterer's\",\n",
              " 'thieves’',\n",
              " 'minute’s',\n",
              " 'em’ly’s',\n",
              " 'colleague’s',\n",
              " 'surgeon’s',\n",
              " '‘young’',\n",
              " \"aunt's\",\n",
              " 'near’',\n",
              " \"a'terwards\",\n",
              " \"''cause\",\n",
              " \"'make\",\n",
              " \"'officer\",\n",
              " \"smallridge's\",\n",
              " \"cheek's\",\n",
              " 'hand—that’s',\n",
              " \"huntin'\",\n",
              " \"blum's\",\n",
              " '‘arrangements’',\n",
              " \"'le\",\n",
              " 'roy’s',\n",
              " \"ladies'\",\n",
              " 'trees’',\n",
              " \"“'cause\",\n",
              " \"sailin's\",\n",
              " 'blood—odin’s',\n",
              " \"'stand\",\n",
              " '“‘i’ll',\n",
              " 'water’s',\n",
              " \"drozdov's\",\n",
              " \"cavalier's\",\n",
              " \"country's\",\n",
              " \"'meat\",\n",
              " \"partic'lar\",\n",
              " 'payment’',\n",
              " 'travellers’',\n",
              " 'knight’',\n",
              " \"they've\",\n",
              " \"everyone's\",\n",
              " \"singer's\",\n",
              " \"macnamara's\",\n",
              " '“‘that’s',\n",
              " \"sandy's\",\n",
              " \"hangin'\",\n",
              " '“‘d’you',\n",
              " 'man’',\n",
              " \"fearin'\",\n",
              " 'didn’t',\n",
              " \"'i\",\n",
              " \"'father\",\n",
              " '‘p’raps',\n",
              " 'wearer’s',\n",
              " \"prince's\",\n",
              " 'an’',\n",
              " \"harville's\",\n",
              " \"andrew's\",\n",
              " 'maw’s',\n",
              " 'your’n',\n",
              " \"'drat\",\n",
              " 'gen’leman',\n",
              " 'perhotin’s',\n",
              " 'shilling’s',\n",
              " \"daughters'\",\n",
              " \"damsel's\",\n",
              " \"'tush\",\n",
              " 'bottle’s',\n",
              " 'hain’t',\n",
              " 'paul’s',\n",
              " 'sitter’s',\n",
              " 'metropolis’',\n",
              " '“whaur’s',\n",
              " \"“d'ye\",\n",
              " \"'be\",\n",
              " \"newyear's\",\n",
              " 'bishop’s',\n",
              " '‘to’',\n",
              " \"butcher's\",\n",
              " \"“respectin'\",\n",
              " 'host’s',\n",
              " \"boars'\",\n",
              " 'idiot—that’s',\n",
              " \"'beauty\",\n",
              " \"'run\",\n",
              " \"bad's\",\n",
              " \"owners'\",\n",
              " \"'queer\",\n",
              " \"is't\",\n",
              " 'hunter’s',\n",
              " 'man—’',\n",
              " 'fuller’s',\n",
              " 'nothing’s',\n",
              " 'madonna’s',\n",
              " \"“thinkin'\",\n",
              " \"mann's\",\n",
              " \"ryliev's\",\n",
              " 'conjuror’s',\n",
              " \"oughn't\",\n",
              " \"maria's\",\n",
              " '‘drove’',\n",
              " \"mistress's\",\n",
              " 'lodger’s',\n",
              " 'many’s',\n",
              " 'game’s',\n",
              " 'right’s',\n",
              " \"brackley's\",\n",
              " \"februar'\",\n",
              " 'air’s',\n",
              " \"eye's\",\n",
              " \"'worse\",\n",
              " 'beggar’s',\n",
              " 'dartle’s',\n",
              " '“she’ll',\n",
              " \"bull's\",\n",
              " \"glowerin'\",\n",
              " 'arm’s',\n",
              " \"scrieghin'\",\n",
              " \"barney's\",\n",
              " \"who've\",\n",
              " \"'stop\",\n",
              " 'ingratitude—’',\n",
              " 'rodya’s',\n",
              " '‘wouldn’t',\n",
              " \"solomon's\",\n",
              " \"soul's\",\n",
              " 'voice—it’s',\n",
              " \"'blowed\",\n",
              " \"mumblin'\",\n",
              " \"'must\",\n",
              " 'ones’',\n",
              " \"'ow\",\n",
              " \"'our\",\n",
              " 'ye’ve',\n",
              " 'joy’—a',\n",
              " \"'bayton\",\n",
              " \"bearing'\",\n",
              " \"'that's\",\n",
              " '‘journey’',\n",
              " 'france’s',\n",
              " \"'nowhere\",\n",
              " 'lloyd’s”—in',\n",
              " \"c'est\",\n",
              " 'bakaleyev’s',\n",
              " \"'half\",\n",
              " 'brook’s',\n",
              " \"laugh's\",\n",
              " \"corbeaux'\",\n",
              " \"'forgive\",\n",
              " \"'we'll\",\n",
              " \"'lady\",\n",
              " 'n’t',\n",
              " \"'dictment\",\n",
              " '‘devil’',\n",
              " \"squire's\",\n",
              " 'qu’un',\n",
              " 'then——’',\n",
              " 'person’s',\n",
              " \"'stone\",\n",
              " '“isn’t',\n",
              " \"'gold\",\n",
              " \"shoemaker's\",\n",
              " \"'drive\",\n",
              " \"peasant's\",\n",
              " 'murcher’s',\n",
              " \"bill's\",\n",
              " 'highness’s',\n",
              " 'builder’s',\n",
              " \"'try\",\n",
              " \"'heaven's\",\n",
              " \"“who'll\",\n",
              " \"'follow\",\n",
              " 'servant’s',\n",
              " 'aggravatin’',\n",
              " \"v'yage\",\n",
              " \"doin'\",\n",
              " 'odin’',\n",
              " \"'moments'\",\n",
              " 'hands—i’ve',\n",
              " \"'know\",\n",
              " \"d'esprit\",\n",
              " \"'blathers\",\n",
              " \"'perhaps\",\n",
              " \"seepin'\",\n",
              " \"priest's\",\n",
              " 'ne’er',\n",
              " \"horse's\",\n",
              " \"'yours\",\n",
              " \"'open\",\n",
              " \"peacock's\",\n",
              " \"'raise\",\n",
              " \"d'ici\",\n",
              " 'pedlar’s',\n",
              " 'davy’s',\n",
              " \"gude's\",\n",
              " 'cat’ll',\n",
              " \"'always\",\n",
              " \"“'mr\",\n",
              " \"d'ye\",\n",
              " \"'sneak'\",\n",
              " 'scot’s',\n",
              " \"'bister\",\n",
              " 'watcher’s',\n",
              " 'king’s',\n",
              " 'fool’s',\n",
              " 'river’s',\n",
              " 'plotnikovs’',\n",
              " '’87',\n",
              " '“somebody’s',\n",
              " \"someone's\",\n",
              " \"stone's\",\n",
              " 'odin’s—“did',\n",
              " 'hen’s',\n",
              " \"many's\",\n",
              " 'doll’s',\n",
              " \"“'how\",\n",
              " 'additions’',\n",
              " '‘affection’s',\n",
              " '‘e’ll',\n",
              " \"'me\",\n",
              " \"fedka's\",\n",
              " \"sea's\",\n",
              " \"'hoots\",\n",
              " 'fugitive’s',\n",
              " \"“'fore\",\n",
              " \"d'andelys\",\n",
              " 'rechris’ened',\n",
              " 'annie’s',\n",
              " \"mains'l\",\n",
              " \"beast's\",\n",
              " \"'cooling\",\n",
              " 'patient’s',\n",
              " 'daughters’',\n",
              " \"'right\",\n",
              " \"river's\",\n",
              " 'jeweler’s',\n",
              " 'he’d',\n",
              " 'himsel’',\n",
              " \"'80's\",\n",
              " '“haven’t',\n",
              " 'plumber’s',\n",
              " 'purcell’s',\n",
              " 'wit’s',\n",
              " 'morcar’s',\n",
              " 'sentry’s',\n",
              " \"hingin'\",\n",
              " \"'either\",\n",
              " 'daughter’s',\n",
              " 'englishman’s',\n",
              " \"'sic\",\n",
              " \"'may\",\n",
              " '‘em’ly’s',\n",
              " \"'cold\",\n",
              " \"'lord\",\n",
              " 'that—it’s',\n",
              " 'talkin’',\n",
              " \"spectre's\",\n",
              " \"'pig's\",\n",
              " 'lookin’',\n",
              " \"folk's\",\n",
              " \"n'est\",\n",
              " 'gasfitters’',\n",
              " \"'sure\",\n",
              " 'one’s',\n",
              " \"'would\",\n",
              " 'policeman’s',\n",
              " \"steeles'\",\n",
              " 'païssy’s',\n",
              " 'wilkin’s',\n",
              " \"p'inter\",\n",
              " 'odinet’s',\n",
              " \"risingham's\",\n",
              " \"'brass\",\n",
              " 'mouth’',\n",
              " \"'twenty\",\n",
              " \"citizen's\",\n",
              " 'lise’s',\n",
              " \"'far\",\n",
              " 'them—they’re',\n",
              " \"'hey\",\n",
              " \"'boy\",\n",
              " '‘criminal’',\n",
              " 'grandpapa’s',\n",
              " \"knittin'\",\n",
              " \"'slap\",\n",
              " \"'coming\",\n",
              " 'this’',\n",
              " 'she’ll',\n",
              " 'you’ve',\n",
              " \"walter's\",\n",
              " \"gabelle's\",\n",
              " 'superior’s',\n",
              " 'wits’',\n",
              " '‘isn’t',\n",
              " 'stags’',\n",
              " \"'part\",\n",
              " \"'gentleness\",\n",
              " 'young’s',\n",
              " 'fordyce’s',\n",
              " 'major’s',\n",
              " \"forester's\",\n",
              " 'an’t',\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBbMM9Z0l1yO"
      },
      "source": [
        "train['text']=train['text'].str.replace('\\'s', '')\n",
        "train['text']=train['text'].str.replace('’s', '')\n",
        "train['text']=train['text'].str.replace('\\'ll', '')\n",
        "train['text']=train['text'].str.replace('’ll', '')\n",
        "train['text']=train['text'].str.replace(\"\\'\", '')\n",
        "train['text']=train['text'].str.replace(\"’\", '')\n",
        "\n",
        "test['text']=test['text'].str.replace(\"’s\",'')\n",
        "test['text']=test['text'].str.replace(\"\\'s\",'')\n",
        "test['text']=test['text'].str.replace('\\'ll', '')\n",
        "test['text']=test['text'].str.replace('’ll', '')\n",
        "test['text']=test['text'].str.replace(\"\\'\", '')\n",
        "test['text']=test['text'].str.replace(\"’\", '')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zOl9NoFl3E8"
      },
      "source": [
        "train['text']=train['text'].str.replace('á', ' Ascenda ')\n",
        "train['text']=train['text'].str.replace('à', ' Descenda ')\n",
        "train['text']=train['text'].str.replace('â', ' Stremama ')\n",
        "train['text']=train['text'].str.replace('ä', ' Doublea ')\n",
        "train['text']=train['text'].str.replace('é', ' Ascende ')\n",
        "train['text']=train['text'].str.replace('í', ' Justi ')\n",
        "train['text']=train['text'].str.replace('ï', ' Doublei ')\n",
        "train['text']=train['text'].str.replace('ó', ' Comao ')\n",
        "train['text']=train['text'].str.replace('ú', ' Ascendu ')\n",
        "train['text']=train['text'].str.replace('ý', ' Ascendy ')\n",
        "train['text']=train['text'].str.replace('ü', ' Umlaut ')\n",
        "train['text']=train['text'].str.replace('è', ' Descende ')\n",
        "train['text']=train['text'].str.replace('£', ' Maludf ')\n",
        "\n",
        "test['text']=test['text'].str.replace('ä', ' Doublea ')\n",
        "test['text']=test['text'].str.replace('â', ' Stremama ')\n",
        "test['text']=test['text'].str.replace('à', ' Descenda ')\n",
        "test['text']=test['text'].str.replace('á', ' Ascenda ')\n",
        "test['text']=test['text'].str.replace('é', ' Ascende ')\n",
        "test['text']=test['text'].str.replace('ï', ' Doublei ')\n",
        "test['text']=test['text'].str.replace('í', ' Justi ')\n",
        "test['text']=test['text'].str.replace('ó', ' Comao  ')\n",
        "test['text']=test['text'].str.replace('ú', ' Ascendu ')\n",
        "test['text']=test['text'].str.replace('ý', ' Ascendy ')\n",
        "test['text']=test['text'].str.replace('ü', ' Umalut ')\n",
        "test['text']=test['text'].str.replace('è', ' Descende ')\n",
        "test['text']=test['text'].str.replace('£', ' Maludf ')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CKcZ2ZilZUV"
      },
      "source": [
        "def alpha_num(text):\n",
        "    return re.sub(\"\\d+\", ' num ', text)\n",
        "\n",
        "train['text']=train['text'].apply(alpha_num)\n",
        "test['text']=test['text'].apply(alpha_num)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg13Wr41jml7"
      },
      "source": [
        "train['text']=train['text'].str.replace('\\(', ' \\( ')\n",
        "train['text']=train['text'].str.replace('\\{', ' \\{ ')\n",
        "train['text']=train['text'].str.replace('\\[', ' \\[ ')\n",
        "train['text']=train['text'].str.replace('\\)', ' \\) ')\n",
        "train['text']=train['text'].str.replace('\\}', ' \\} ')\n",
        "train['text']=train['text'].str.replace('\\]', ' \\] ')\n",
        "train['text']=train['text'].str.replace('—', '')\n",
        "train['text']=train['text'].str.replace('_', '')\n",
        "train['text']=train['text'].str.replace(':', '')\n",
        "train['text']=train['text'].str.replace(\"‘\",' ‘ ')\n",
        "train['text']=train['text'].str.replace(\"“\",' “ ')\n",
        "\n",
        "test['text']=test['text'].str.replace('\\(', ' \\( ')\n",
        "test['text']=test['text'].str.replace('\\{', ' \\{ ')\n",
        "test['text']=test['text'].str.replace('\\[', ' \\[ ')\n",
        "test['text']=test['text'].str.replace('\\)', ' \\) ')\n",
        "test['text']=test['text'].str.replace('\\}', ' \\} ')\n",
        "test['text']=test['text'].str.replace('\\]', ' \\] ')\n",
        "test['text']=test['text'].str.replace('—', '')\n",
        "test['text']=test['text'].str.replace('_', '')\n",
        "test['text']=test['text'].str.replace(':', '')\n",
        "test['text']=test['text'].str.replace(\"‘\",' ‘ ')\n",
        "test['text']=test['text'].str.replace(\"“\",' “ ')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPQ_Hm9zl6Sx",
        "outputId": "ce28a0fa-422b-4e64-ee7f-aec0283092ad"
      },
      "source": [
        "X_train = train['text'].values\n",
        "X_test = test['text'].values\n",
        "y = train['author'].values\n",
        "print(X_train.shape, X_test.shape, y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879,) (19617,) (54879,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqaiYqE4l__2"
      },
      "source": [
        "\n",
        "vocab_size = 21000\n",
        "embedding_dim = 128\n",
        "max_length = 250\n",
        "padding_type='post'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSOBSLQkmCVb"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCQNCTRomDua"
      },
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XocVc05EmF0W",
        "outputId": "278ce33f-f0b3-44f7-b321-9f282fcb98c1"
      },
      "source": [
        "trn = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
        "tst = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n",
        "print(trn.shape, tst.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879, 250) (19617, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU9Em_qomHKs"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Ys9xK7mIq7"
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "        Bidirectional(LSTM(128, return_sequences=True)),\n",
        "        Bidirectional(LSTM(128)),\n",
        "        Dense(n_class, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=.01))\n",
        "    return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5dXEkR-mKC9",
        "outputId": "b216e455-8e74-444b-dfd2-7b4beec55957"
      },
      "source": [
        "p_val = np.zeros((trn.shape[0], n_class))\n",
        "p_tst = np.zeros((tst.shape[0], n_class))\n",
        "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
        "    print(f'training model for CV #{i}')\n",
        "    clf = get_model()\n",
        "    \n",
        "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
        "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "    clf.fit(trn[i_trn], \n",
        "            to_categorical(y[i_trn]),\n",
        "            validation_data=(trn[i_val], to_categorical(y[i_val])),\n",
        "            epochs=10,\n",
        "            batch_size=256,\n",
        "            callbacks=[es])\n",
        "    p_val[i_val, :] = clf.predict(trn[i_val])\n",
        "    p_tst += clf.predict(tst) / n_fold"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model for CV #1\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 33s 192ms/step - loss: 1.0032 - val_loss: 0.7325\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.5435 - val_loss: 0.6406\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.3752 - val_loss: 0.6371\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 31s 181ms/step - loss: 0.2852 - val_loss: 0.6753\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.2272 - val_loss: 0.7381\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.1819Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.1819 - val_loss: 0.8689\n",
            "Epoch 00006: early stopping\n",
            "training model for CV #2\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 32s 189ms/step - loss: 0.9899 - val_loss: 0.7161\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 31s 180ms/step - loss: 0.5407 - val_loss: 0.6141\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.3706 - val_loss: 0.6225\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 31s 177ms/step - loss: 0.2856 - val_loss: 0.6894\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.2333Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.2333 - val_loss: 0.7768\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #3\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 32s 184ms/step - loss: 1.0196 - val_loss: 0.7574\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 31s 177ms/step - loss: 0.5550 - val_loss: 0.6381\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.3794 - val_loss: 0.6275\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.2842 - val_loss: 0.7289\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.2325 - val_loss: 0.7588\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.1915Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.1915 - val_loss: 0.8217\n",
            "Epoch 00006: early stopping\n",
            "training model for CV #4\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 32s 184ms/step - loss: 1.1609 - val_loss: 0.8342\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 31s 179ms/step - loss: 0.7684 - val_loss: 0.7060\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 30s 177ms/step - loss: 0.4673 - val_loss: 0.6394\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 31s 177ms/step - loss: 0.3457 - val_loss: 0.6953\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.2712 - val_loss: 0.7084\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.2201Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.2201 - val_loss: 0.8179\n",
            "Epoch 00006: early stopping\n",
            "training model for CV #5\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 32s 185ms/step - loss: 1.0329 - val_loss: 0.7179\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 31s 178ms/step - loss: 0.5484 - val_loss: 0.6118\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 30s 177ms/step - loss: 0.3794 - val_loss: 0.6180\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 30s 176ms/step - loss: 0.2948 - val_loss: 0.6848\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.2341Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 30s 176ms/step - loss: 0.2341 - val_loss: 0.7507\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk4cSNJnmMHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e774a79-0896-421d-8261-0a0efc63238e"
      },
      "source": [
        "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n",
        "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy (CV):  77.6946%\n",
            "Log Loss (CV):   0.6260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flM8_PzHmPuY"
      },
      "source": [
        "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
        "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wyR9Au2mUZd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "a6b97d74-0c56-43b9-8d4a-5a9cd3ee8b04"
      },
      "source": [
        "sub = pd.read_csv(sample_file, index_col=0)\n",
        "print(sub.shape)\n",
        "sub.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19617, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  1  2  3  4\n",
              "index               \n",
              "0      0  0  0  0  0\n",
              "1      0  0  0  0  0\n",
              "2      0  0  0  0  0\n",
              "3      0  0  0  0  0\n",
              "4      0  0  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvYmw0scmU5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "882d3b58-0ab3-474d-ceca-6b24d9fd933f"
      },
      "source": [
        "\n",
        "sub[sub.columns] = p_tst\n",
        "sub.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0192</td>\n",
              "      <td>0.3664</td>\n",
              "      <td>0.2969</td>\n",
              "      <td>0.3147</td>\n",
              "      <td>0.0029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.3512</td>\n",
              "      <td>0.2208</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0335</td>\n",
              "      <td>0.3749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9664</td>\n",
              "      <td>0.0248</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0011</td>\n",
              "      <td>0.0032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0053</td>\n",
              "      <td>0.0211</td>\n",
              "      <td>0.9598</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.8188</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0252</td>\n",
              "      <td>0.0605</td>\n",
              "      <td>0.0663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0       1       2       3       4\n",
              "index                                        \n",
              "0      0.0192  0.3664  0.2969  0.3147  0.0029\n",
              "1      0.3512  0.2208  0.0195  0.0335  0.3749\n",
              "2      0.9664  0.0248  0.0045  0.0011  0.0032\n",
              "3      0.0053  0.0211  0.9598  0.0076  0.0062\n",
              "4      0.8188  0.0292  0.0252  0.0605  0.0663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH04Rop5mWQs"
      },
      "source": [
        "\n",
        "sub.to_csv(sub_file)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtqhodxKmX8b"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}