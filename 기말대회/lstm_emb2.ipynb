{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm-emb2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCVLM1zGlDyT"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKXkJxtElNnC"
      },
      "source": [
        "from matplotlib import rcParams, pyplot as plt\n",
        "import numpy as np\n",
        "import string\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM,GRU, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional, concatenate\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings \n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBuoAKLAlPtX",
        "outputId": "61aa2d76-88f6-419f-a6ba-eeae7b77a4f0"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Restrict TensorFlow to only use the first GPU\n",
        "    try:\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "    except RuntimeError as e:\n",
        "        # Visible devices must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "else:\n",
        "    print('No GPU detected')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jjkmCowlUDE"
      },
      "source": [
        "rcParams['figure.figsize'] = (16, 8)\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('max_columns', 100)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozqcZT2llXxW"
      },
      "source": [
        "data_dir = Path('/content/drive/MyDrive/dacon/input')\n",
        "feature_dir = Path('../build/feature')\n",
        "val_dir = Path('/content/drive/MyDrive/dacon/build/val')\n",
        "tst_dir = Path('/content/drive/MyDrive/dacon/build/tst')\n",
        "sub_dir = Path('/content/drive/MyDrive/dacon/build/sub')\n",
        "\n",
        "trn_file = data_dir / 'train.csv'\n",
        "tst_file = data_dir / 'test_x.csv'\n",
        "sample_file = data_dir / 'sample_submission.csv'\n",
        "\n",
        "target_col = 'author'\n",
        "n_fold = 5\n",
        "n_class = 5\n",
        "seed = 42"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wedaBd8lZWp"
      },
      "source": [
        "algo_name = 'lstm'\n",
        "feature_name = 'emb'\n",
        "model_name = f'{algo_name}_{feature_name}'\n",
        "\n",
        "feature_file = feature_dir / f'{feature_name}.csv'\n",
        "p_val_file = val_dir / f'{model_name}.val.csv'\n",
        "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
        "sub_file = sub_dir / f'{model_name}.csv'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "q_ytTVt1lbmr",
        "outputId": "285f013b-521f-49f7-b91b-c635f85e46e2"
      },
      "source": [
        "train = pd.read_csv(trn_file, index_col=0)\n",
        "train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "0      He was almost choking. There was so much, so m...       3\n",
              "1                 “Your sister asked for it, I suppose?”       2\n",
              "2       She was engaged one day as she walked, in per...       1\n",
              "3      The captain was in the porch, keeping himself ...       4\n",
              "4      “Have mercy, gentlemen!” odin flung up his han...       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wT6B7qc9ldzb",
        "outputId": "b6e069b2-24e1-41d8-fb4e-366bb3dcedfa"
      },
      "source": [
        "test = pd.read_csv(tst_file, index_col=0)\n",
        "test.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Not at all. I think she is one of the most ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As the lady had stated her intention of scream...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“And then suddenly in the silence I heard a so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>His conviction remained unchanged. So far as I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "index                                                   \n",
              "0      “Not at all. I think she is one of the most ch...\n",
              "1      \"No,\" replied he, with sudden consciousness, \"...\n",
              "2      As the lady had stated her intention of scream...\n",
              "3      “And then suddenly in the silence I heard a so...\n",
              "4      His conviction remained unchanged. So far as I..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "QON0HVz9OTTb",
        "outputId": "c36a8332-2ffe-4e39-c3c7-dea2920d78e1"
      },
      "source": [
        "train[train['text'].str.contains(\"makin'\")]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47126</th>\n",
              "      <td>'We fand her in odin Bay, Rorie an' me, and a'...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "47126  'We fand her in odin Bay, Rorie an' me, and a'...       4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fynb2UDyG_5c",
        "outputId": "0bae825e-f378-452b-cf8f-d7deec25ea2d"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']',\n",
        "          '>', '%', '=', '#', '*', '+', '\\\\', '•', '~', '@', '£', '·', '_', '{', '}', '©', '^',\n",
        "          '®', '`', '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â', '█',\n",
        "          '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶',\n",
        "          '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼',\n",
        "          '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
        "          'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪',\n",
        "          '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
        "result=set()\n",
        "\n",
        "def find_puncts(text):\n",
        "    global result\n",
        "    words = text_to_word_sequence(text)\n",
        "    for word in words :\n",
        "      for character in word :\n",
        "        if character in puncts : result.add(character)\n",
        "\n",
        "    return\n",
        "\n",
        "train['text'].str.lower().apply(find_puncts)\n",
        "result"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"'\", '£', 'à', 'â', 'è', 'é', 'ï', '—', '‘', '’', '“', '”'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdXtBAEjljkq"
      },
      "source": [
        "train['text'] = train['text'].str.lower()\n",
        "test['text'] = test['text'].str.lower()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWkpSqqLTJIW"
      },
      "source": [
        "train['text'] = train['text'].str.replace('\\?',' quesmark ')\n",
        "train['text'] = train['text'].str.replace('\\!',' exclmark ')\n",
        "train['text'] = train['text'].str.replace('\\&',' empent ')\n",
        "train['text'] = train['text'].str.replace(\"\\*\",' chstar ')\n",
        "train['text'] = train['text'].str.replace(\";\",' smcolons  ')\n",
        "\n",
        "test['text'] = test['text'].str.replace('\\?',' quesmark ')\n",
        "test['text'] = test['text'].str.replace('\\!',' exclmark ')\n",
        "test['text'] = test['text'].str.replace('\\&',' empent ')\n",
        "test['text'] = test['text'].str.replace(\"\\*\",' chstar ')\n",
        "test['text'] = test['text'].str.replace(\";\",' smcolons  ')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgt31x-UOv_s",
        "outputId": "951de3b7-f1bd-4730-bf50-8d55a9cd9eeb"
      },
      "source": [
        "\n",
        "contraction = set()\n",
        "\n",
        "def find_contraction(text):\n",
        "    global contraction\n",
        "    words = text_to_word_sequence(text)\n",
        "    for word in words :\n",
        "      if \"\\'\" in word or \"’\" in word : contraction.add(word)       \n",
        "    return \n",
        "\n",
        "train['text'].str.lower().apply(find_contraction)\n",
        "contraction    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"order'\",\n",
              " \"lucy's\",\n",
              " \"'bah\",\n",
              " 'seaman’s',\n",
              " 'people’s',\n",
              " \"'ooman\",\n",
              " \"'at\",\n",
              " 'ye’ll',\n",
              " \"minutes'\",\n",
              " \"dog's\",\n",
              " \"sweetheart's\",\n",
              " \"'eccentricity\",\n",
              " \"about'\",\n",
              " \"anhalt's\",\n",
              " \"'confidentially'\",\n",
              " 'men’s',\n",
              " \"'cod\",\n",
              " 'ship’s',\n",
              " 'for’',\n",
              " 'you—there’s',\n",
              " \"bachelor's\",\n",
              " \"'twas\",\n",
              " 'again’—here',\n",
              " 'odin’d',\n",
              " \"steward's\",\n",
              " 'lawful’',\n",
              " \"'lots\",\n",
              " \"matron's\",\n",
              " \"'god\",\n",
              " 'again—that’s',\n",
              " 'ham’s',\n",
              " \"poet's\",\n",
              " \"gude's\",\n",
              " 'sentry’s',\n",
              " \"companion's\",\n",
              " \"qu'avez\",\n",
              " 'hart’',\n",
              " 'joe’s',\n",
              " \"“we're\",\n",
              " \"'eh\",\n",
              " 'companion’s',\n",
              " \"individual's\",\n",
              " \"flunkey's\",\n",
              " '‘’twas',\n",
              " \"pushkin's\",\n",
              " 'iou’s',\n",
              " \"mutineers'\",\n",
              " '‘that’s',\n",
              " \"detective's\",\n",
              " '‘tom’',\n",
              " \"b'ye\",\n",
              " \"buryin'\",\n",
              " 'doctor’s',\n",
              " '‘hosannah’',\n",
              " 'woodman’s',\n",
              " 'dog’s',\n",
              " \"neighbour's\",\n",
              " '“‘there’s',\n",
              " \"parson's\",\n",
              " '—odin’s',\n",
              " \"d'esprit\",\n",
              " \"'how's\",\n",
              " 'boys’',\n",
              " \"time's\",\n",
              " 'papa’s',\n",
              " \"'dot\",\n",
              " \"agin'\",\n",
              " \"'step\",\n",
              " \"s'appelle\",\n",
              " 'dupont’s',\n",
              " \"'toby\",\n",
              " 'conviction’',\n",
              " \"“'not\",\n",
              " 'metcalf’s',\n",
              " 'andrew’s',\n",
              " \"mornin'\",\n",
              " \"sins'\",\n",
              " 'semionovitch’s',\n",
              " \"'hah\",\n",
              " \"rollin'\",\n",
              " \"'isn't\",\n",
              " \"let's\",\n",
              " \"seneschal's\",\n",
              " 'jacob’—this',\n",
              " \"sayin'\",\n",
              " 'forgets’—an',\n",
              " \"infant's\",\n",
              " \"'whose\",\n",
              " 'translator’s',\n",
              " \"m'accompagnerez\",\n",
              " \"“'god\",\n",
              " \"'dark\",\n",
              " \"his'n\",\n",
              " \"hero's\",\n",
              " \"'through\",\n",
              " \"fellows'\",\n",
              " \"gentleman's\",\n",
              " \"grave's\",\n",
              " 'jane’',\n",
              " \"uncle's\",\n",
              " \"'may\",\n",
              " 'lad’s',\n",
              " 'children’',\n",
              " 'brig’s',\n",
              " 'caroline’s',\n",
              " 'beard’s',\n",
              " \"foeman's\",\n",
              " \"c'est\",\n",
              " \"stranger's\",\n",
              " \"we'll\",\n",
              " \"waitin'\",\n",
              " \"comin'\",\n",
              " 'meyer’s',\n",
              " '’uns',\n",
              " 'servant’s',\n",
              " \"is't\",\n",
              " 'mithers’s',\n",
              " 'hosier’s',\n",
              " \"'ruined\",\n",
              " 'platon’s',\n",
              " 'rankeillor’s',\n",
              " 'licence’',\n",
              " \"'young\",\n",
              " \"who've\",\n",
              " \"prince's\",\n",
              " \"gaoler's\",\n",
              " 'landlady’s',\n",
              " \"clerk's\",\n",
              " \"d'autre\",\n",
              " \"'peep\",\n",
              " 'ross’s',\n",
              " \"'thus\",\n",
              " 'couldn’t',\n",
              " 'russia’s',\n",
              " 'uncle’s',\n",
              " \"'they\",\n",
              " '“they’ll',\n",
              " \"colleague's\",\n",
              " 'cooper’s',\n",
              " \"court's\",\n",
              " 'man’s',\n",
              " 'baynes’s',\n",
              " \"engagement's\",\n",
              " \"shooter's\",\n",
              " \"'surly\",\n",
              " \"forester's\",\n",
              " 'porter’s',\n",
              " \"'no'\",\n",
              " \"lovers'\",\n",
              " 'hubbard’s',\n",
              " \"law's\",\n",
              " '‘won’t',\n",
              " 'health’',\n",
              " \"weren't\",\n",
              " '’ll',\n",
              " \"antonitch's\",\n",
              " 'bollamore’s',\n",
              " \"'combines\",\n",
              " 'that’s',\n",
              " '‘fatal’',\n",
              " 'hen’',\n",
              " \"aren't\",\n",
              " \"qu'un\",\n",
              " 'yourselves’',\n",
              " 'lawyer’s',\n",
              " 'mamma’s',\n",
              " 'drawing—’',\n",
              " \"expedition's\",\n",
              " 'officer’s',\n",
              " 'father’s',\n",
              " 'trevor’s',\n",
              " \"myasnitchiha's\",\n",
              " \"something's\",\n",
              " \"them'\",\n",
              " 'odin’',\n",
              " 'saviour’s',\n",
              " 'blackboy’s',\n",
              " 'harris’s',\n",
              " \"'success\",\n",
              " \"he'll\",\n",
              " \"cruncher's\",\n",
              " 'dartle’s',\n",
              " \"cookin'\",\n",
              " \"'hurrah\",\n",
              " 'd’you',\n",
              " \"'devil'\",\n",
              " '“they’ve',\n",
              " 'reade’s',\n",
              " 'æsop’s',\n",
              " \"she'd\",\n",
              " 'goodness’',\n",
              " \"wasn't\",\n",
              " \"'antimonial\",\n",
              " 'heart’s',\n",
              " \"'policeman\",\n",
              " 'milliner’s',\n",
              " '“we’ve',\n",
              " \"distiller's\",\n",
              " 'rooks’',\n",
              " 'all’',\n",
              " \"it'll\",\n",
              " \"diver's\",\n",
              " 'brother’s',\n",
              " \"'so\",\n",
              " \"'heaven\",\n",
              " \"wouldn't\",\n",
              " \"we'd\",\n",
              " \"coxswain's\",\n",
              " '—there’s',\n",
              " 'brandley’s',\n",
              " 'forrester’s',\n",
              " 'woman’s”',\n",
              " \"glowerin'\",\n",
              " '‘system’',\n",
              " \"'aha\",\n",
              " \"sabbin'\",\n",
              " 'man—’',\n",
              " '“c’est',\n",
              " '‘they’ve',\n",
              " '‘d’',\n",
              " \"mightn't\",\n",
              " \"jerry's\",\n",
              " \"'probably\",\n",
              " 'who’ll',\n",
              " \"hardcastle's\",\n",
              " \"'and\",\n",
              " 'mother’s',\n",
              " 'friend’s',\n",
              " \"'morning\",\n",
              " \"'often\",\n",
              " \"'especially\",\n",
              " \"dozin'\",\n",
              " '“mayn’t',\n",
              " \"helmsman's\",\n",
              " 'o’t',\n",
              " \"yer'd\",\n",
              " 'we’d',\n",
              " \"cat's\",\n",
              " \"dustman's\",\n",
              " \"'pester\",\n",
              " \"'died\",\n",
              " 'serious’',\n",
              " 'ilyinishna—she’s',\n",
              " 'grayper’s',\n",
              " \"ball's\",\n",
              " 'wretch’',\n",
              " \"“'gentlemen\",\n",
              " 'winter’s',\n",
              " 'rascal’s',\n",
              " 'purcell’s',\n",
              " 'shoulders—“i’ve',\n",
              " \"'queer\",\n",
              " 'willin’',\n",
              " 'lanyon’s',\n",
              " '‘babe’',\n",
              " 'side’',\n",
              " \"l'agneau\",\n",
              " \"'prenticed\",\n",
              " \"meetin'\",\n",
              " \"takin'\",\n",
              " \"bill's\",\n",
              " \"grocers'\",\n",
              " \"'change\",\n",
              " 'love’s',\n",
              " '“em’ly',\n",
              " \"'apocalypse'\",\n",
              " 'prisoner’s',\n",
              " \"'be\",\n",
              " \"'hours'\",\n",
              " \"'em\",\n",
              " \"'open\",\n",
              " \"cheek's\",\n",
              " \"'mother\",\n",
              " 'daughters’',\n",
              " \"''cause\",\n",
              " 'clarriker’s',\n",
              " \"“d'ye\",\n",
              " 'hen’s',\n",
              " \"'nobody\",\n",
              " '‘saddle’',\n",
              " \"'poor'\",\n",
              " \"tide's\",\n",
              " \"'tain't\",\n",
              " 'jeweller’s',\n",
              " '“who—who’s',\n",
              " 'jacobson’s',\n",
              " 'n’êtes',\n",
              " \"singer's\",\n",
              " \"solicitor's\",\n",
              " \"lieutenant's\",\n",
              " \"gunn's\",\n",
              " 'let’s',\n",
              " 'flopson’s',\n",
              " \"'another's\",\n",
              " \"fortun'\",\n",
              " 'needn’t',\n",
              " \"'wipes\",\n",
              " '“wouldn’t',\n",
              " '’66',\n",
              " '‘wickfield’s',\n",
              " \"'drug\",\n",
              " \"you've\",\n",
              " \"so'\",\n",
              " 'euclid’s',\n",
              " \"'ring\",\n",
              " 'american’s',\n",
              " \"'nor\",\n",
              " \"maria's\",\n",
              " \"'bill\",\n",
              " \"moriarty's\",\n",
              " \"'humph\",\n",
              " \"'great\",\n",
              " 'dacre’s',\n",
              " 'chaplain’s',\n",
              " \"'twere\",\n",
              " \"'stand\",\n",
              " \"d'or\",\n",
              " \"it's\",\n",
              " \"daren't\",\n",
              " 'ruffian’s',\n",
              " 'auntie’s',\n",
              " \"'student'\",\n",
              " \"chateau's\",\n",
              " \"'george'\",\n",
              " \"'directly\",\n",
              " \"salisbury's\",\n",
              " \"queen's\",\n",
              " '“‘what’s',\n",
              " \"man's\",\n",
              " 'brunton’s',\n",
              " 'perfec’ly',\n",
              " \"'vyek\",\n",
              " 'blessington’s',\n",
              " 'delegates’',\n",
              " \"best'\",\n",
              " 'scots’',\n",
              " \"'there'll\",\n",
              " 'sterndale’s',\n",
              " \"d'honneur\",\n",
              " 'they’d',\n",
              " \"castaway's\",\n",
              " \"'his\",\n",
              " 'sha’n’t',\n",
              " 'dead’',\n",
              " \"'did\",\n",
              " '’pology',\n",
              " \"'officers\",\n",
              " \"sawyer's\",\n",
              " '‘affection’s',\n",
              " \"'pray\",\n",
              " \"needle's\",\n",
              " \"darnay's\",\n",
              " '‘how’s',\n",
              " \"'yonder\",\n",
              " \"'silence\",\n",
              " '“everybody’s',\n",
              " 'silvester’s',\n",
              " \"'has\",\n",
              " 'marie’s',\n",
              " 'mightn’t',\n",
              " \"'now\",\n",
              " '‘she’ll',\n",
              " 'son’',\n",
              " \"'back\",\n",
              " \"'seven\",\n",
              " \"j'étais\",\n",
              " 'family’',\n",
              " \"'christopher\",\n",
              " 'statue’s',\n",
              " 'to—odin—’',\n",
              " 'he’d',\n",
              " \"'neither\",\n",
              " 'ain’t—”',\n",
              " \"d'\",\n",
              " 'sisters’',\n",
              " \"'calls\",\n",
              " 'magwitch’s',\n",
              " \"she'll\",\n",
              " \"“who's\",\n",
              " 'rope’s',\n",
              " 'miners’',\n",
              " 'babushkin’s',\n",
              " '‘creature’',\n",
              " \"“i'll\",\n",
              " \"d'aulnais\",\n",
              " 'l’inventer',\n",
              " \"'ticed\",\n",
              " \"margaret's\",\n",
              " \"'glimpse\",\n",
              " 'qu’un',\n",
              " \"couldn't\",\n",
              " 'merchant’s',\n",
              " 'hours’',\n",
              " '“aren’t',\n",
              " 'schoolfellows’',\n",
              " \"'misses\",\n",
              " 'be’ind',\n",
              " \"two's\",\n",
              " 'shipwrights’',\n",
              " \"'follow\",\n",
              " \"scoundrel's\",\n",
              " 'game’s',\n",
              " '“‘“i’m',\n",
              " 'this’',\n",
              " \"'m\",\n",
              " 'samsonov’s',\n",
              " \"gunmaker's\",\n",
              " 'ma’am',\n",
              " \"anne's\",\n",
              " \"'compose\",\n",
              " 'poe’s',\n",
              " 'gen’lm’n',\n",
              " 'lucy’s',\n",
              " 'highlandman’s',\n",
              " 'wouldn’t',\n",
              " \"han'le\",\n",
              " \"“'fore\",\n",
              " \"p'int\",\n",
              " 's’il',\n",
              " 'pursuer’s',\n",
              " \"beak's\",\n",
              " \"linkin'\",\n",
              " 'tipp’s',\n",
              " \"ghost's\",\n",
              " '“haven’t',\n",
              " \"cottager's\",\n",
              " 'murder’',\n",
              " 'pushkin’s',\n",
              " \"'close\",\n",
              " \"mustn't\",\n",
              " '‘they’',\n",
              " \"day'\",\n",
              " \"judge's\",\n",
              " \"stay'\",\n",
              " \"stirrin'\",\n",
              " 'pole’s',\n",
              " \"darya's\",\n",
              " \"money's\",\n",
              " 'l’opéra',\n",
              " 'again’—it’s',\n",
              " 'clackin’',\n",
              " \"'drive\",\n",
              " 'lawyers—it’s',\n",
              " \"l'eglise\",\n",
              " \"'cooling\",\n",
              " 'hastie’s',\n",
              " \"cabman's\",\n",
              " \"'clasp\",\n",
              " \"warrior's\",\n",
              " 'schneider’s',\n",
              " '—wouldn’t',\n",
              " '“doen’t',\n",
              " '‘perhaps’',\n",
              " \"'call\",\n",
              " \"friendship's\",\n",
              " 'beein’',\n",
              " \"goat's\",\n",
              " \"beadle's\",\n",
              " 'rascal’',\n",
              " \"'won't\",\n",
              " \"odinet's\",\n",
              " 'beach’',\n",
              " '“i’ve',\n",
              " 'orphans’',\n",
              " '’87',\n",
              " 'workmen’s',\n",
              " 'impertinence—that’s',\n",
              " \"simon's\",\n",
              " \"“'now\",\n",
              " \"vessel's\",\n",
              " \"'coals\",\n",
              " \"sailors'\",\n",
              " 'company’s',\n",
              " 'body’s',\n",
              " \"growin'\",\n",
              " \"'any\",\n",
              " 'convenience’',\n",
              " \"hersel'\",\n",
              " 'argument’s',\n",
              " 'host’s',\n",
              " 'tungay’s',\n",
              " 'giv’',\n",
              " \"'”\",\n",
              " \"capper's\",\n",
              " \"saint's\",\n",
              " \"'japanning\",\n",
              " \"where'd\",\n",
              " 'now’s',\n",
              " '“that’ll',\n",
              " 'acton’s',\n",
              " \"enemy's\",\n",
              " '——’s',\n",
              " \"'ho\",\n",
              " \"shame's\",\n",
              " 'denman’s',\n",
              " \"spaniard's\",\n",
              " 'gray’s',\n",
              " \"dishonour'\",\n",
              " 'superior’s',\n",
              " \"creature's\",\n",
              " \"seaman's\",\n",
              " \"d'angle\",\n",
              " 'dealer’s',\n",
              " \"fortin'\",\n",
              " 'minister’s',\n",
              " 'clem’s',\n",
              " 'cuthen’th',\n",
              " 'steamer’s',\n",
              " \"o'clock\",\n",
              " \"“can't\",\n",
              " \"“respectin'\",\n",
              " '‘can’t',\n",
              " \"somebody's\",\n",
              " \"tyin'\",\n",
              " 'friends—’',\n",
              " 'riggers’',\n",
              " \"'you've\",\n",
              " 'trevelyan’s',\n",
              " \"'\",\n",
              " \"'blood\",\n",
              " \"'recalled\",\n",
              " \"child's\",\n",
              " 'capacity—’',\n",
              " 'odin’s—“did',\n",
              " \"'coachman\",\n",
              " \"leave'\",\n",
              " 'perezvon’s',\n",
              " \"'respect\",\n",
              " '’—as',\n",
              " 'nature’s',\n",
              " \"'gold\",\n",
              " \"verhishins'\",\n",
              " \"partic'lar\",\n",
              " 'hopkins’',\n",
              " 'water’s',\n",
              " 'sorrow’s',\n",
              " '‘annie’s',\n",
              " 'master’s',\n",
              " \"'harry\",\n",
              " 'business’',\n",
              " \"'wot's\",\n",
              " \"'though\",\n",
              " \"bragge's\",\n",
              " 'bottle’s',\n",
              " \"betty's\",\n",
              " \"'aye\",\n",
              " \"as'll\",\n",
              " \"'light\",\n",
              " \"mischief's\",\n",
              " '‘star’',\n",
              " \"'blown\",\n",
              " 'major’s',\n",
              " 'podincutor’s',\n",
              " \"country's\",\n",
              " \"ye're\",\n",
              " \"more's\",\n",
              " \"'carry\",\n",
              " '‘i’m',\n",
              " \"men'll\",\n",
              " \"hasn't\",\n",
              " '“you’re',\n",
              " \"her's\",\n",
              " 'lyagavy’s',\n",
              " '‘ma’am',\n",
              " 'beatin’',\n",
              " \"'from\",\n",
              " \"children's\",\n",
              " \"moments'\",\n",
              " \"i'b\",\n",
              " \"soulis's\",\n",
              " 'alexander’s',\n",
              " 'moment’s',\n",
              " 'lieutenant’s',\n",
              " \"spear's\",\n",
              " 'memory’s',\n",
              " '‘drove’',\n",
              " \"'look\",\n",
              " \"'on\",\n",
              " 'country’s',\n",
              " '“they’re',\n",
              " \"death's\",\n",
              " \"yegorytch's\",\n",
              " \"count's\",\n",
              " '“oughtn’t',\n",
              " 'clickett’',\n",
              " \"they're\",\n",
              " \"'ave\",\n",
              " \"'we'll\",\n",
              " '‘nothink’s',\n",
              " \"coffin's\",\n",
              " \"meesion'\",\n",
              " \"squire's\",\n",
              " \"m'lellan\",\n",
              " 'it’s',\n",
              " 'pony’s',\n",
              " 'known—’',\n",
              " 'gulpidge’s',\n",
              " 'animal’s',\n",
              " 'minute’s',\n",
              " \"southerton's\",\n",
              " 'madding’s',\n",
              " '—“i’m',\n",
              " \"p'raps\",\n",
              " \"mysel'\",\n",
              " 'harlamov’s',\n",
              " \"nobility's\",\n",
              " \"harm's\",\n",
              " 'pawnbroker’s',\n",
              " \"“we'd\",\n",
              " \"better'\",\n",
              " '—couldn’t',\n",
              " \"'wheesht\",\n",
              " 'wenches—don’t',\n",
              " \"housekeeper's\",\n",
              " 'yourself’',\n",
              " 'warn’t',\n",
              " \"'right\",\n",
              " 'dora’s',\n",
              " 'shan’t',\n",
              " 'mealy’s',\n",
              " \"'shut\",\n",
              " 'vanka’s',\n",
              " 'condition’',\n",
              " \"“god's\",\n",
              " \"t's\",\n",
              " \"fellow's\",\n",
              " \"everyone's\",\n",
              " \"'women\",\n",
              " \"annamaria's\",\n",
              " 'neill’s',\n",
              " 'husband’s',\n",
              " \"'extraordinary\",\n",
              " \"'wretched\",\n",
              " \"'murrain\",\n",
              " 'adult’',\n",
              " \"tentaillon's\",\n",
              " \"town's\",\n",
              " \"'calendars\",\n",
              " \"hermit's\",\n",
              " \"invadin'\",\n",
              " 'i’ll',\n",
              " \"supernat'ral\",\n",
              " '“there’s',\n",
              " \"'put\",\n",
              " 'soul’s',\n",
              " 'wench’s',\n",
              " \"'miss\",\n",
              " \"'wait\",\n",
              " \"'hell's\",\n",
              " 'beauty’s',\n",
              " 'bull’s',\n",
              " 'pierrot’s',\n",
              " \"'upon\",\n",
              " 'latter’s',\n",
              " \"nigel's\",\n",
              " \"grandmother's\",\n",
              " 'pheasant’',\n",
              " \"notary's\",\n",
              " \"'eight\",\n",
              " 'burnin’',\n",
              " 'tradesmen’s',\n",
              " \"sir'\",\n",
              " \"night's\",\n",
              " 'emily’s',\n",
              " \"statue's\",\n",
              " \"'gather\",\n",
              " 'curtains—that’s',\n",
              " 'thought—i’ve',\n",
              " 'jack’s',\n",
              " 'miller’s',\n",
              " \"'maybe\",\n",
              " '‘ain’t',\n",
              " \"slangin'\",\n",
              " '‘gregara’',\n",
              " 'athlete’s',\n",
              " \"'of\",\n",
              " 'confession’s',\n",
              " 'word—i’ll',\n",
              " 'bahd’s',\n",
              " 'dear’',\n",
              " \"erkel's\",\n",
              " \"thing's\",\n",
              " \"'clever\",\n",
              " \"'he'd\",\n",
              " 'time’s',\n",
              " \"'do\",\n",
              " 'an’t',\n",
              " \"marshal's\",\n",
              " \"'steady\",\n",
              " \"'an'\",\n",
              " '‘hudson’',\n",
              " 'waitin’',\n",
              " '“didn’t',\n",
              " \"yourself'\",\n",
              " 'here’s',\n",
              " \"'yours\",\n",
              " 'object—that’s',\n",
              " \"'one\",\n",
              " 'silkworms’',\n",
              " '‘we’ll',\n",
              " \"'e\",\n",
              " 'boar’s',\n",
              " \"'plummy\",\n",
              " \"'wherever\",\n",
              " 'ivan’s',\n",
              " \"'seized\",\n",
              " \"'my\",\n",
              " '‘business’',\n",
              " '“whaur’s',\n",
              " \"deer's\",\n",
              " \"sittin'\",\n",
              " 'boy’',\n",
              " \"upo'\",\n",
              " 'holy’',\n",
              " 'l’heure',\n",
              " 'crushed’',\n",
              " \"poulterer's\",\n",
              " \"animal's\",\n",
              " \"bolter's\",\n",
              " 'dominick’s',\n",
              " \"herd's\",\n",
              " 'great’s',\n",
              " \"'dearer\",\n",
              " \"fuller's\",\n",
              " \"moulton's\",\n",
              " \"croft's\",\n",
              " 'dealers’',\n",
              " 'd’état',\n",
              " 'that’ll',\n",
              " \"carr's\",\n",
              " \"there's\",\n",
              " 'trabb’s',\n",
              " 'th’',\n",
              " \"'such\",\n",
              " '‘what’',\n",
              " \"calf's\",\n",
              " \"'fine\",\n",
              " \"“i've\",\n",
              " \"'these\",\n",
              " \"scheherazade's\",\n",
              " 'morning’',\n",
              " \"pheasants'\",\n",
              " \"'yes\",\n",
              " 'plotnikovs’',\n",
              " \"everybody's\",\n",
              " 'many’s',\n",
              " 'aunt’s',\n",
              " \"makin'\",\n",
              " \"captive's\",\n",
              " 'foxe’s',\n",
              " \"'brittles\",\n",
              " 'life’s',\n",
              " 'heep’s',\n",
              " 'dictator’s',\n",
              " '“i’m',\n",
              " '‘you’d',\n",
              " \"journey's\",\n",
              " 'odin—that’s',\n",
              " 'afanasy’s',\n",
              " '“what’s',\n",
              " \"me's\",\n",
              " \"musgroves'\",\n",
              " 'beaulieu’s',\n",
              " 'point’',\n",
              " 'sylvester’s',\n",
              " \"'cut\",\n",
              " \"servants'\",\n",
              " \"weeks'\",\n",
              " \"'betsy's\",\n",
              " 'annie’s',\n",
              " '‘nobody’s',\n",
              " \"son's\",\n",
              " \"artful's\",\n",
              " \"'remember\",\n",
              " 'father—that’s',\n",
              " \"lookin'\",\n",
              " \"'press\",\n",
              " \"lover's\",\n",
              " 'abroad’',\n",
              " 'what’',\n",
              " 'scarlet’',\n",
              " 'an’',\n",
              " 'wickfield’s',\n",
              " \"'angel'\",\n",
              " 'ones’',\n",
              " \"'blowed\",\n",
              " \"'prove\",\n",
              " \"don't\",\n",
              " \"'break\",\n",
              " '‘dan’l',\n",
              " \"else's\",\n",
              " '‘told’',\n",
              " \"'this\",\n",
              " 'murcher’s',\n",
              " \"paul's\",\n",
              " '“somebody’s',\n",
              " \"steeles'\",\n",
              " \"bollamore's\",\n",
              " \"'affect\",\n",
              " \"'mouton\",\n",
              " 'purchaser—’',\n",
              " \"'but\",\n",
              " 'trouser’s',\n",
              " \"'much\",\n",
              " \"charger's\",\n",
              " \"miles'\",\n",
              " \"boy'\",\n",
              " \"grandmama's\",\n",
              " 'jealousy’s',\n",
              " '“‘i’m',\n",
              " '“it’ll',\n",
              " \"mistress's\",\n",
              " 'heather’s',\n",
              " 'cruiser’s',\n",
              " \"'juries\",\n",
              " 'trotwood’s',\n",
              " \"robber's\",\n",
              " 'jewellers’',\n",
              " \"“'he\",\n",
              " 'fenya’s',\n",
              " \"fortnight's\",\n",
              " \"“'dead\",\n",
              " 'kupferof’s',\n",
              " \"'turn\",\n",
              " 'ivolgin’s',\n",
              " 'daughter’s',\n",
              " 'mannering’s',\n",
              " \"'ugh\",\n",
              " \"'she's\",\n",
              " 'folks’',\n",
              " 'joy’—a',\n",
              " \"'it'll\",\n",
              " \"farmer's\",\n",
              " '‘she’s',\n",
              " 'rival’s',\n",
              " \"sike's\",\n",
              " \"'he'\",\n",
              " \"'three\",\n",
              " '—that’s',\n",
              " 'years’',\n",
              " \"lacquey's\",\n",
              " 'awa’',\n",
              " 'hag’s',\n",
              " \"bird's\",\n",
              " 'plover’s',\n",
              " \"'come\",\n",
              " \"suitor's\",\n",
              " 'admit’',\n",
              " 'life’',\n",
              " \"'forties\",\n",
              " 'sh’',\n",
              " \"huntin'\",\n",
              " '“don’t',\n",
              " \"leadin'\",\n",
              " \"butter's\",\n",
              " \"kinsman's\",\n",
              " \"connor's\",\n",
              " 'jessie’s',\n",
              " 'mell’s',\n",
              " 'knight’s',\n",
              " 'hadn’t',\n",
              " \"river's\",\n",
              " 'statesman’s',\n",
              " \"n'en\",\n",
              " 'fishermen’s',\n",
              " 'aged’s',\n",
              " 'woman’s',\n",
              " 'away’',\n",
              " 'birds’',\n",
              " \"vegetation's\",\n",
              " 'watchman’s',\n",
              " \"tailor's\",\n",
              " 'cruelty’s',\n",
              " 'mas’r’s',\n",
              " \"freeman's\",\n",
              " \"'think\",\n",
              " 'talkin’',\n",
              " \"work'us\",\n",
              " \"fagid's\",\n",
              " \"crawin'\",\n",
              " 'opponent’s',\n",
              " \"shouldn't\",\n",
              " \"pearson's\",\n",
              " 'first—he’d',\n",
              " \"like'\",\n",
              " \"gogol's\",\n",
              " 'law’s',\n",
              " 'jezebel’s',\n",
              " '—supposin’',\n",
              " \"'as\",\n",
              " \"for't\",\n",
              " \"mann'\",\n",
              " 'said’',\n",
              " 'sow’s',\n",
              " \"'set\",\n",
              " \"earth's\",\n",
              " 'too’',\n",
              " '‘leavings’',\n",
              " 'chopin’s',\n",
              " \"'who's\",\n",
              " \"'ours\",\n",
              " \"februar'\",\n",
              " \"nothin'\",\n",
              " 'o’er',\n",
              " \"d'errien\",\n",
              " \"shipman's\",\n",
              " 'hamlet’s',\n",
              " \"'better\",\n",
              " 'sister’s',\n",
              " \"'hold\",\n",
              " 'missy’s',\n",
              " 'brothers’',\n",
              " \"cur'osity\",\n",
              " \"experiment'\",\n",
              " 'gen’l’m’n’s',\n",
              " \"'always\",\n",
              " \"gamfield's\",\n",
              " \"party's\",\n",
              " \"patron's\",\n",
              " \"'you'll\",\n",
              " \"brittle's\",\n",
              " 'jenkinson’s',\n",
              " \"'s\",\n",
              " \"'h'm\",\n",
              " 'stan’ning',\n",
              " 'moscow’s',\n",
              " 'her’',\n",
              " \"solomon's\",\n",
              " \"t'other\",\n",
              " 'god—that’s',\n",
              " 'steps’',\n",
              " \"'st\",\n",
              " 'now’',\n",
              " \"'under\",\n",
              " \"'enough\",\n",
              " \"foot's\",\n",
              " 'cabowner’s',\n",
              " \"beast's\",\n",
              " \"'horrible'\",\n",
              " 'prince’s',\n",
              " 'profession’',\n",
              " '‘tan’t',\n",
              " \"m'clour\",\n",
              " \"himself'\",\n",
              " \"“'pray\",\n",
              " \"'liberté\",\n",
              " \"'whining\",\n",
              " 'gridyenko’s',\n",
              " 'forster’s',\n",
              " '20’',\n",
              " \"prisoner's\",\n",
              " 'zimmerman’s',\n",
              " \"trees'”\",\n",
              " 'see’ere',\n",
              " '’m',\n",
              " '‘criminal’',\n",
              " 'tiffey’s',\n",
              " \"jew's\",\n",
              " \"'r\",\n",
              " \"drum's\",\n",
              " \"cook's\",\n",
              " 'harry’s',\n",
              " \"him'\",\n",
              " \"ignaty's\",\n",
              " 'patterson’s',\n",
              " \"outrages'\",\n",
              " 'neezing’',\n",
              " 'creature’s',\n",
              " 'conduct’s',\n",
              " 'd’un',\n",
              " '‘is—‘adn’t',\n",
              " \"“she'll\",\n",
              " 'maiden’s',\n",
              " \"d'armagnac\",\n",
              " 'worth—that’s',\n",
              " 'tenants’',\n",
              " \"bein'\",\n",
              " '’86',\n",
              " 'hope’s',\n",
              " 'savage’s',\n",
              " 'cat’ll',\n",
              " \"martyr's\",\n",
              " 'lucases’',\n",
              " 'villon’s',\n",
              " 'semyonova’s',\n",
              " 'form’s',\n",
              " 'look’ee',\n",
              " \"'jem\",\n",
              " 'exercise’',\n",
              " 'skeleton’s',\n",
              " \"salesman's\",\n",
              " \"diggin'\",\n",
              " 'roy’s',\n",
              " \"'frob\",\n",
              " \"officer's\",\n",
              " 'minute—i’ve',\n",
              " 'grow’d',\n",
              " 'negro’s',\n",
              " 'physician’s',\n",
              " 'dawson’s',\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBbMM9Z0l1yO"
      },
      "source": [
        "train['text']=train['text'].str.replace('\\'s', '')\n",
        "train['text']=train['text'].str.replace('’s', '')\n",
        "train['text']=train['text'].str.replace('\\'ll', '')\n",
        "train['text']=train['text'].str.replace('’ll', '')\n",
        "train['text']=train['text'].str.replace(\"\\'\", '')\n",
        "train['text']=train['text'].str.replace(\"’\", '')\n",
        "\n",
        "test['text']=test['text'].str.replace(\"’s\",'')\n",
        "test['text']=test['text'].str.replace(\"\\'s\",'')\n",
        "test['text']=test['text'].str.replace('\\'ll', '')\n",
        "test['text']=test['text'].str.replace('’ll', '')\n",
        "test['text']=test['text'].str.replace(\"\\'\", '')\n",
        "test['text']=test['text'].str.replace(\"’\", '')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zOl9NoFl3E8"
      },
      "source": [
        "train['text']=train['text'].str.replace('á', '')\n",
        "train['text']=train['text'].str.replace('à', '')\n",
        "train['text']=train['text'].str.replace('â', '')\n",
        "train['text']=train['text'].str.replace('ä', '')\n",
        "train['text']=train['text'].str.replace('é', '')\n",
        "train['text']=train['text'].str.replace('í', '')\n",
        "train['text']=train['text'].str.replace('ï', '')\n",
        "train['text']=train['text'].str.replace('ó', '')\n",
        "train['text']=train['text'].str.replace('ú', '')\n",
        "train['text']=train['text'].str.replace('ý', '')\n",
        "train['text']=train['text'].str.replace('ü', '')\n",
        "train['text']=train['text'].str.replace('è', '')\n",
        "train['text']=train['text'].str.replace('£', '')\n",
        "\n",
        "test['text']=test['text'].str.replace('ä', '')\n",
        "test['text']=test['text'].str.replace('â', '')\n",
        "test['text']=test['text'].str.replace('à', '')\n",
        "test['text']=test['text'].str.replace('á', '')\n",
        "test['text']=test['text'].str.replace('é', '')\n",
        "test['text']=test['text'].str.replace('ï', '')\n",
        "test['text']=test['text'].str.replace('í', '')\n",
        "test['text']=test['text'].str.replace('ó', '')\n",
        "test['text']=test['text'].str.replace('ú', '')\n",
        "test['text']=test['text'].str.replace('ý', '')\n",
        "test['text']=test['text'].str.replace('ü', '')\n",
        "test['text']=test['text'].str.replace('è', '')\n",
        "test['text']=test['text'].str.replace('£', '')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CKcZ2ZilZUV"
      },
      "source": [
        "def alpha_num(text):\n",
        "    return re.sub(\"\\d+\", ' num ', text)\n",
        "\n",
        "train['text']=train['text'].apply(alpha_num)\n",
        "test['text']=test['text'].apply(alpha_num)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg13Wr41jml7"
      },
      "source": [
        "train['text']=train['text'].str.replace('\\(', ' \\( ')\n",
        "train['text']=train['text'].str.replace('\\{', ' \\{ ')\n",
        "train['text']=train['text'].str.replace('\\[', ' \\[ ')\n",
        "train['text']=train['text'].str.replace('\\)', ' \\) ')\n",
        "train['text']=train['text'].str.replace('\\}', ' \\} ')\n",
        "train['text']=train['text'].str.replace('\\]', ' \\] ')\n",
        "train['text']=train['text'].str.replace('—', '')\n",
        "train['text']=train['text'].str.replace('_', '')\n",
        "train['text']=train['text'].str.replace(':', '')\n",
        "train['text']=train['text'].str.replace(\"‘\",' ‘ ')\n",
        "train['text']=train['text'].str.replace(\"“\",' “ ')\n",
        "\n",
        "test['text']=test['text'].str.replace('\\(', ' \\( ')\n",
        "test['text']=test['text'].str.replace('\\{', ' \\{ ')\n",
        "test['text']=test['text'].str.replace('\\[', ' \\[ ')\n",
        "test['text']=test['text'].str.replace('\\)', ' \\) ')\n",
        "test['text']=test['text'].str.replace('\\}', ' \\} ')\n",
        "test['text']=test['text'].str.replace('\\]', ' \\] ')\n",
        "test['text']=test['text'].str.replace('—', '')\n",
        "test['text']=test['text'].str.replace('_', '')\n",
        "test['text']=test['text'].str.replace(':', '')\n",
        "test['text']=test['text'].str.replace(\"‘\",' ‘ ')\n",
        "test['text']=test['text'].str.replace(\"“\",' “ ')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy3DRwTD1-Ou",
        "outputId": "a4b0a609-811e-41de-a07e-5d5cd3579423"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxlPk8yq2G-P"
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer \n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "def lemma_text(text):\n",
        "    tokenizer=TweetTokenizer()\n",
        "    words=tokenizer.tokenize(text)\n",
        "    lem = WordNetLemmatizer()\n",
        "    words=[lem.lemmatize(word, \"v\") for word in words]\n",
        "    \n",
        "    clean_sent=\" \".join(words)\n",
        "    \n",
        "    return clean_sent\n",
        "\n",
        "train['text'] = train['text'].str.lower().apply(lemma_text)\n",
        "test['text'] = test['text'].str.lower().apply(lemma_text)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPQ_Hm9zl6Sx",
        "outputId": "af849b04-284f-4a4b-c204-2a3c88d5f691"
      },
      "source": [
        "X_train = train['text'].values\n",
        "X_test = test['text'].values\n",
        "y = train['author'].values\n",
        "print(X_train.shape, X_test.shape, y.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879,) (19617,) (54879,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqaiYqE4l__2"
      },
      "source": [
        "\n",
        "vocab_size = 21000\n",
        "embedding_dim = 128\n",
        "max_length = 300\n",
        "padding_type='post'"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSOBSLQkmCVb"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCQNCTRomDua"
      },
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XocVc05EmF0W",
        "outputId": "ebf83261-a11a-481c-fc96-5a0197127d54"
      },
      "source": [
        "trn = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
        "tst = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n",
        "print(trn.shape, tst.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54879, 300) (19617, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU9Em_qomHKs"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Ys9xK7mIq7"
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "        Bidirectional(LSTM(128, return_sequences=True)),\n",
        "        Bidirectional(LSTM(128)),\n",
        "        Dense(n_class, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=.01))\n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5dXEkR-mKC9",
        "outputId": "6eeba797-fa24-4f6b-8d2c-e7e9c4a753b4"
      },
      "source": [
        "p_val = np.zeros((trn.shape[0], n_class))\n",
        "p_tst = np.zeros((tst.shape[0], n_class))\n",
        "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
        "    print(f'training model for CV #{i}')\n",
        "    clf = get_model()\n",
        "    \n",
        "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
        "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "    clf.fit(trn[i_trn], \n",
        "            to_categorical(y[i_trn]),\n",
        "            validation_data=(trn[i_val], to_categorical(y[i_val])),\n",
        "            epochs=10,\n",
        "            batch_size=256,\n",
        "            callbacks=[es])\n",
        "    p_val[i_val, :] = clf.predict(trn[i_val])\n",
        "    p_tst += clf.predict(tst) / n_fold"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model for CV #1\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 37s 214ms/step - loss: 1.0604 - val_loss: 0.7176\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 36s 212ms/step - loss: 0.5665 - val_loss: 0.6222\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 36s 209ms/step - loss: 0.4157 - val_loss: 0.5916\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 36s 210ms/step - loss: 0.3253 - val_loss: 0.6413\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 36s 209ms/step - loss: 0.2685 - val_loss: 0.7328\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.2236Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 36s 210ms/step - loss: 0.2236 - val_loss: 0.7825\n",
            "Epoch 00006: early stopping\n",
            "training model for CV #2\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 37s 215ms/step - loss: 1.0257 - val_loss: 0.7104\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 36s 208ms/step - loss: 0.5494 - val_loss: 0.6087\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 36s 208ms/step - loss: 0.3981 - val_loss: 0.6299\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 36s 208ms/step - loss: 0.3062 - val_loss: 0.6632\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.2504Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 36s 208ms/step - loss: 0.2504 - val_loss: 0.7229\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #3\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 37s 215ms/step - loss: 0.9944 - val_loss: 0.7156\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 36s 208ms/step - loss: 0.5489 - val_loss: 0.5998\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 36s 209ms/step - loss: 0.3935 - val_loss: 0.6358\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 36s 210ms/step - loss: 0.3066 - val_loss: 0.6661\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.2542Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 36s 209ms/step - loss: 0.2542 - val_loss: 0.7348\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #4\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 37s 216ms/step - loss: 1.0421 - val_loss: 0.7378\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 36s 210ms/step - loss: 0.5670 - val_loss: 0.6306\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 36s 210ms/step - loss: 0.4115 - val_loss: 0.6312\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 36s 210ms/step - loss: 0.3272 - val_loss: 0.6546\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.2700Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 36s 210ms/step - loss: 0.2700 - val_loss: 0.6999\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #5\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 37s 215ms/step - loss: 1.1095 - val_loss: 0.7107\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 37s 212ms/step - loss: 0.5622 - val_loss: 0.5957\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 36s 209ms/step - loss: 0.3952 - val_loss: 0.6170\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 36s 209ms/step - loss: 0.3082 - val_loss: 0.6406\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - ETA: 0s - loss: 0.2533Restoring model weights from the end of the best epoch.\n",
            "172/172 [==============================] - 36s 209ms/step - loss: 0.2533 - val_loss: 0.7278\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk4cSNJnmMHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819d1fe9-4317-48a8-dcdc-b5806cfc4de6"
      },
      "source": [
        "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n",
        "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy (CV):  77.9570%\n",
            "Log Loss (CV):   0.6053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flM8_PzHmPuY"
      },
      "source": [
        "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
        "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wyR9Au2mUZd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "a8ec6c2c-5462-4e3d-e7a0-3f119518fed2"
      },
      "source": [
        "sub = pd.read_csv(sample_file, index_col=0)\n",
        "print(sub.shape)\n",
        "sub.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19617, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  1  2  3  4\n",
              "index               \n",
              "0      0  0  0  0  0\n",
              "1      0  0  0  0  0\n",
              "2      0  0  0  0  0\n",
              "3      0  0  0  0  0\n",
              "4      0  0  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvYmw0scmU5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "5cffecda-00ce-46cc-862a-89b287c5fe42"
      },
      "source": [
        "\n",
        "sub[sub.columns] = p_tst\n",
        "sub.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0305</td>\n",
              "      <td>0.4482</td>\n",
              "      <td>0.4279</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.0065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4240</td>\n",
              "      <td>0.2200</td>\n",
              "      <td>0.0225</td>\n",
              "      <td>0.1035</td>\n",
              "      <td>0.2301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9835</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.0037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0043</td>\n",
              "      <td>0.0081</td>\n",
              "      <td>0.9763</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>0.0056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7613</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0305</td>\n",
              "      <td>0.0686</td>\n",
              "      <td>0.1225</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0       1       2       3       4\n",
              "index                                        \n",
              "0      0.0305  0.4482  0.4279  0.0869  0.0065\n",
              "1      0.4240  0.2200  0.0225  0.1035  0.2301\n",
              "2      0.9835  0.0101  0.0014  0.0013  0.0037\n",
              "3      0.0043  0.0081  0.9763  0.0058  0.0056\n",
              "4      0.7613  0.0171  0.0305  0.0686  0.1225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH04Rop5mWQs"
      },
      "source": [
        "\n",
        "sub.to_csv(sub_file)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtqhodxKmX8b"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}
